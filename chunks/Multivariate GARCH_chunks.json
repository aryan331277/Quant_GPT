[
  "\n\n--- Page 1 ---\narXiv:2506.02796v1  [q-fin.CP]  3 Jun 2025\nDeep Learning Enhanced Multivariate\nGARCH\nHaoyuan Wang, Chen Liu, Minh-Ngoc Tran, and Chao Wang\u2217\nDiscipline of Business Analytics, The University of Sydney Business School\nAbstract\nThis paper introduces a novel multivariate volatility modeling framework, named\nLong Short-Term Memory enhanced BEKK (LSTM-BEKK), that integrates deep\nlearning into multivariate GARCH processes. By combining the flexibility of recur-\nrent neural networks with the econometric structure of BEKK models, our approach\nis designed to better capture nonlinear, dynamic, and high-dimensional dependence\nstructures in financial return data. The proposed model addresses key limitations\nof traditional multivariate GARCH-based methods, particularly in capturing per-\nsistent volatility clustering and asymmetric co-movement across assets. Leveraging\nthe data-driven nature of LSTMs, the framework adapts effectively to time-varying\nmarket conditions, offering improved robustness and forecasting performance. Em-\npirical results across multiple equity markets confirm that the LSTM-BEKK model\nachieves superior performance in terms of out-of-sample portfolio risk forecast, while\nmaintaining the interpretability from the BEKK models. These findings highlight\nthe potential of hybrid econometric-deep learning models in advancing financial risk\nmanagement and multivariate volatility forecasting. Keywords: multivariate volatility modeling, Long Short-Term Memory, portfolio opti-\nmization, high-dimensional finance. \u2217Corresponding author: chao.wang@sydney.edu.au. 1\n\n\n--- Page 2 ---\n1\nIntroduction\nModeling financial market volatility has long been a central topic in econometrics due\nto its critical role in risk management, asset pricing, and portfolio optimization. Engle\n(1982) pioneered this line of research with the introduction of the Autoregressive Condi-\ntional Heteroskedasticity model, which characterizes time-varying volatility as a function\nof past shocks. This foundational framework was later generalized by Bollerslev (1986)\nthrough the GARCH model, which incorporated both lagged innovations and past vari-\nances, enabling improved modeling of persistent volatility behavior.",
  "Keywords: multivariate volatility modeling, Long Short-Term Memory, portfolio opti-\nmization, high-dimensional finance. \u2217Corresponding author: chao.wang@sydney.edu.au. 1\n\n\n--- Page 2 ---\n1\nIntroduction\nModeling financial market volatility has long been a central topic in econometrics due\nto its critical role in risk management, asset pricing, and portfolio optimization. Engle\n(1982) pioneered this line of research with the introduction of the Autoregressive Condi-\ntional Heteroskedasticity model, which characterizes time-varying volatility as a function\nof past shocks. This foundational framework was later generalized by Bollerslev (1986)\nthrough the GARCH model, which incorporated both lagged innovations and past vari-\nances, enabling improved modeling of persistent volatility behavior. In parallel to the\nGARCH family, stochastic volatility (SV) models emerged as an important alternative,\nmodeling volatility as an unobserved latent process governed by its own stochastic dy-\nnamics. This latent-state formulation allows SV models to capture the stylized facts often\nobserved in financial time series (Taylor, 1994; Asai et al., 2006). While univariate volatility models are effective in capturing the dynamics of individual\nasset volatility, financial markets are inherently multivariate, with assets exhibiting strong\ncomovements and spillovers. Accurate modeling of such joint dynamics is essential for\nsystemic risk monitoring, portfolio allocation, and derivative pricing. In this context,\nthe conditional covariance matrix plays a central role by describing the time-varying co-\nmovement among asset returns. As highlighted in Bollerslev et al. (1988), Engle (2002)\nand Bauwens et al. (2006), multivariate volatility modeling enables the quantification of\ninterdependencies across assets and enhances the effectiveness of financial decision-making\nunder uncertainty. To extend volatility modeling to multivariate settings,\nmultivariate GARCH\n(MGARCH) models have been proposed as natural generalizations of the univariate frame-\nwork. Among these, the BEKK model introduced by Engle and Kroner (1995) stands out\ndue to its flexible parameterization and being a direct extension of univariate GARCH.",
  "(1988), Engle (2002)\nand Bauwens et al. (2006), multivariate volatility modeling enables the quantification of\ninterdependencies across assets and enhances the effectiveness of financial decision-making\nunder uncertainty. To extend volatility modeling to multivariate settings,\nmultivariate GARCH\n(MGARCH) models have been proposed as natural generalizations of the univariate frame-\nwork. Among these, the BEKK model introduced by Engle and Kroner (1995) stands out\ndue to its flexible parameterization and being a direct extension of univariate GARCH. The BEKK specification guarantees the positive definiteness of the conditional covariance\nmatrix by construction and can capture dynamic spillovers between asset returns. This\nstructural advantage makes it particularly appealing for applications requiring robust co-\nvariance estimation in financial risk modeling and forecasting. Empirical studies (see, e.g.,\nSilvennoinen and Ter\u00e4svirta, 2009; Fang et al., 2015) have demonstrated the adaptabil-\nity of MGARCH frameworks in capturing time-varying correlations and volatilities under\nextreme events, reinforcing their relevance in financial risk management. Traditional MGARCH formulations such as BEKK encounter severe computational\nbottlenecks in high-dimensional settings due to the rapidly expanding parameter space\n(Ledoit and Wolf, 2012, 2015). To address this scalability issue, Engle (2002) proposed\nthe Dynamic Conditional Correlation (DCC) model, which simplifies estimation by decou-\npling univariate volatility and correlation dynamics. This reduction in complexity allows\nDCC to accommodate a larger number of assets while still capturing time-varying depen-\ndencies. Extensions such as the Student-t DCC (Ku, 2008) and Asymmetric DCC (Lai\nand Sheu, 2011) further enhance the modeling robustness under heavy tails and asym-\nmetric shocks, while the Dynamic Equicorrelation model (Engle and Kelly, 2012) further\n2\n\n\n--- Page 3 ---\nimproves computational tractability for the DCC framework. These methodological contributions collectively underpin the development of modern\nmultivariate volatility modeling, which is central to understanding the dynamic behavior\nof financial markets and the evolving interdependencies among assets.",
  "Traditional MGARCH formulations such as BEKK encounter severe computational\nbottlenecks in high-dimensional settings due to the rapidly expanding parameter space\n(Ledoit and Wolf, 2012, 2015). To address this scalability issue, Engle (2002) proposed\nthe Dynamic Conditional Correlation (DCC) model, which simplifies estimation by decou-\npling univariate volatility and correlation dynamics. This reduction in complexity allows\nDCC to accommodate a larger number of assets while still capturing time-varying depen-\ndencies. Extensions such as the Student-t DCC (Ku, 2008) and Asymmetric DCC (Lai\nand Sheu, 2011) further enhance the modeling robustness under heavy tails and asym-\nmetric shocks, while the Dynamic Equicorrelation model (Engle and Kelly, 2012) further\n2\n\n\n--- Page 3 ---\nimproves computational tractability for the DCC framework. These methodological contributions collectively underpin the development of modern\nmultivariate volatility modeling, which is central to understanding the dynamic behavior\nof financial markets and the evolving interdependencies among assets. While models such\nas BEKK, DCC and their extensions have significantly advanced the multivariate volatility\nmodeling, their reliance on the simple summation of lagged covariance matrices and outer\nproducts of return vectors limits their adaptability to complicated patterns and structural\nshifts often observed during periods of financial stress. These limitations motivate the\nintegration of more expressive modeling techniques, such as deep learning models, into\nmultivariate volatility modeling, offering potential new directions for advancing volatility\nmodeling in high-dimensional financial applications. Recent advances in deep learning provide compelling techniques for modeling com-\nplicated and high dimensional sequential data. Recurrent Neural Networks (RNNs), and\nLong Short-Term Memory (LSTM) networks in particular, offer a powerful mechanism for\nlearning temporal and comovement dependencies in sequential multivariate data. Their\nability to capture long-range interactions and nonlinear patterns has led to various success-\nful applications across a range of large-scale industry level tasks (Goodfellow et al., 2016).",
  "While models such\nas BEKK, DCC and their extensions have significantly advanced the multivariate volatility\nmodeling, their reliance on the simple summation of lagged covariance matrices and outer\nproducts of return vectors limits their adaptability to complicated patterns and structural\nshifts often observed during periods of financial stress. These limitations motivate the\nintegration of more expressive modeling techniques, such as deep learning models, into\nmultivariate volatility modeling, offering potential new directions for advancing volatility\nmodeling in high-dimensional financial applications. Recent advances in deep learning provide compelling techniques for modeling com-\nplicated and high dimensional sequential data. Recurrent Neural Networks (RNNs), and\nLong Short-Term Memory (LSTM) networks in particular, offer a powerful mechanism for\nlearning temporal and comovement dependencies in sequential multivariate data. Their\nability to capture long-range interactions and nonlinear patterns has led to various success-\nful applications across a range of large-scale industry level tasks (Goodfellow et al., 2016). This paper proposes a novel hybrid model, the LSTM-BEKK, which combines the econo-\nmetric rigor of the BEKK model with the adaptive capabilities of LSTMs. The LSTM-\nBEKK model leverages the structural strengths of BEKK while enhancing it with LSTM\u2019s\nability to capture nonlinear and long-term dynamics. By allowing LSTM-generated com-\nponents to directly influence the time-varying covariance matrix, this framework provides\na highly flexible tool for analyzing the evolving relationships among financial assets, par-\nticularly in high-dimensional contexts. The design of the LSTM-BEKK model is inspired by recent advancements in inte-\ngrating deep learning with univariate volatility models, which have demonstrated superior\npredictive accuracy and the ability to capture nonlinearities in volatility. For example,\nthe work by Nguyen et al. (2022) explored the effectiveness of deep learning in enhancing\nGARCH-based volatility modeling.",
  "The LSTM-\nBEKK model leverages the structural strengths of BEKK while enhancing it with LSTM\u2019s\nability to capture nonlinear and long-term dynamics. By allowing LSTM-generated com-\nponents to directly influence the time-varying covariance matrix, this framework provides\na highly flexible tool for analyzing the evolving relationships among financial assets, par-\nticularly in high-dimensional contexts. The design of the LSTM-BEKK model is inspired by recent advancements in inte-\ngrating deep learning with univariate volatility models, which have demonstrated superior\npredictive accuracy and the ability to capture nonlinearities in volatility. For example,\nthe work by Nguyen et al. (2022) explored the effectiveness of deep learning in enhancing\nGARCH-based volatility modeling. These studies highlight the advantages of incorporat-\ning neural networks into traditional econometric frameworks, improving the adaptability\nand forecasting performance of volatility models. Extending this approach to a multi-\nvariate setting introduces unique challenges, such as ensuring positive definiteness of the\ncovariance matrix and managing the curse of dimensionality (Ledoit and Wolf, 2012). The primary innovation of the LSTM-BEKK model lies in its ability to utilize economic\ninformation instruments and adapt to changing market conditions. Unlike traditional\nBEKK models constrained by their inflexible parametric structure, the LSTM-BEKK\nmodel dynamically adjusts itself to capture evolving market relationships. Furthermore,\nthe LSTM\u2019s capacity to learn complex patterns enhances the model\u2019s responsiveness to\nturbulent market periods, improving the accuracy of volatility forecasts. Substantial empirical results demonstrate that the LSTM-BEKK model outperforms\ntraditional BEKK and DCC models in terms of predictive accuracy, as measured by\nstandard evaluation metrics such as out-of-sample negative log-likelihood and annualized\n3\n\n\n--- Page 4 ---\nvolatility of global minimum variance portfolio.",
  "Extending this approach to a multi-\nvariate setting introduces unique challenges, such as ensuring positive definiteness of the\ncovariance matrix and managing the curse of dimensionality (Ledoit and Wolf, 2012). The primary innovation of the LSTM-BEKK model lies in its ability to utilize economic\ninformation instruments and adapt to changing market conditions. Unlike traditional\nBEKK models constrained by their inflexible parametric structure, the LSTM-BEKK\nmodel dynamically adjusts itself to capture evolving market relationships. Furthermore,\nthe LSTM\u2019s capacity to learn complex patterns enhances the model\u2019s responsiveness to\nturbulent market periods, improving the accuracy of volatility forecasts. Substantial empirical results demonstrate that the LSTM-BEKK model outperforms\ntraditional BEKK and DCC models in terms of predictive accuracy, as measured by\nstandard evaluation metrics such as out-of-sample negative log-likelihood and annualized\n3\n\n\n--- Page 4 ---\nvolatility of global minimum variance portfolio. These findings are robust across datasets\ncovering portfolios constructed from the top companies by market capitalization in Japan,\nthe U.S., and the U.K., reflecting the model\u2019s strong generalization capability across dif-\nferent market environments. Moreover, in low-dimensional settings, the interpretability of\nthe LSTM-BEKK framework is enhanced by visualizing individual variance and covariance\ntrajectories, which reveal the model\u2019s ability to capture both abrupt volatility spikes and\ndirectional shifts in inter-asset correlations\u2014especially during periods of market stress. These insights affirm not only its predictive power but also its value in understanding the\nevolving structure of financial return dynamics. The paper is organized as follows. In Section 2, we review the relevant literature on\nMGARCH models and machine learning techniques, then detail the structure and the-\noretical foundations of the proposed LSTM-BEKK model. The estimation procedure of\nthe LSTM-BEKK is detailed in Section 3. Section 4 evaluates the empirical performance\nof LSTM-BEKK on high-dimensional datasets across multiple settings, comparing it with\nestablished benchmarks.",
  "These insights affirm not only its predictive power but also its value in understanding the\nevolving structure of financial return dynamics. The paper is organized as follows. In Section 2, we review the relevant literature on\nMGARCH models and machine learning techniques, then detail the structure and the-\noretical foundations of the proposed LSTM-BEKK model. The estimation procedure of\nthe LSTM-BEKK is detailed in Section 3. Section 4 evaluates the empirical performance\nof LSTM-BEKK on high-dimensional datasets across multiple settings, comparing it with\nestablished benchmarks. A study focusing on global minimum variance portfolio is con-\nducted in Section 5. Section 6 concludes the paper and discusses future work. Technical\ndetails and further empirical study of LSTM-BEKK are included in the Appendix. 2\nModeling Frameworks\n2.1\nFoundation Models\nThis section presents the foundation models from econometrics and machine learning\nthat form the building blocks for our proposed LSTM-BEKK model. We also present\nseveral benchmark multivariate volatility models that will be used to compare against\nLSTM-BEKK. 2.1.1\nBEKK Models\nThe BEKK model is a representative within the MGARCH framework, designed to guar-\nantee the positive definiteness of the conditional covariance matrix while preserving flex-\nibility in modeling dynamic dependencies across financial assets. Let rt = (rt,1, . . . , rt,n)\u2032 denote the vector of de-meaned returns for n portfolio assets at\ntime t. The returns are assumed to follow a multivariate normal distribution conditional\non past information Ft\u22121:\nrt|Ft\u22121 \u223cN(0, Ht),\n(1)\nwhere Ht = cov(rt|Ft\u22121) represents the conditional covariance matrix of returns. While\nit is possible to consider more flat-tailed distributions such as a multivariate Student\u2019s t,\nwe use the multivariate normal distribution in this paper to facilitate exposition.",
  ". . , rt,n)\u2032 denote the vector of de-meaned returns for n portfolio assets at\ntime t. The returns are assumed to follow a multivariate normal distribution conditional\non past information Ft\u22121:\nrt|Ft\u22121 \u223cN(0, Ht),\n(1)\nwhere Ht = cov(rt|Ft\u22121) represents the conditional covariance matrix of returns. While\nit is possible to consider more flat-tailed distributions such as a multivariate Student\u2019s t,\nwe use the multivariate normal distribution in this paper to facilitate exposition. This\n4\n\n\n--- Page 5 ---\ncovariance matrix Ht captures time-varying dependencies among portfolio assets, a crit-\nical element for financial applications, such as risk management and portfolio allocation\n(Bollerslev et al., 1988; Bauwens et al., 2006; McAleer et al., 2008). The general BEKK(p, q) model specifies Ht as:\nHt = \u2126+\np\nX\ni=1\nAirt\u2212ir\u2032\nt\u2212iA\u2032\ni +\nq\nX\nj=1\nBjHt\u2212jB\u2032\nj,\n(2)\nwhere \u2126is a symmetric positive definite matrix, and Ai and Bj are n \u00d7 n coefficient\nmatrices capturing the effects of past shocks and past covariances, and p and q represent\nthe orders of the process (Francq and Zako\u00efan, 2012; Scherrer and Ribarits, 2007). To\nreduce complexity, the BEKK(1,1) model is commonly used, which assumes p = q = 1,\nleading to the formulation:\nHt = \u2126+ A1rt\u22121r\u2032\nt\u22121A\u2032\n1 + B1Ht\u22121B\u2032\n1. (3)\nA further simplification of the BEKK model is the Scalar BEKK specification, which\nsimplifies the parameterization by imposing the following constraints: \u2126= CC\u2032, A1 =\n\u221aaI, and B1 =\n\u221a\nbI, where C is a lower triangular matrix and I denotes the identity\nmatrix. This results in the more compact form Ht as:\nHt = CC\u2032 + art\u22121r\u2032\nt\u22121 + bHt\u22121. (4)\nHere, a, b \u22650 are scalar parameters representing the effects of past shocks and lagged\ncovariances, respectively.",
  "The general BEKK(p, q) model specifies Ht as:\nHt = \u2126+\np\nX\ni=1\nAirt\u2212ir\u2032\nt\u2212iA\u2032\ni +\nq\nX\nj=1\nBjHt\u2212jB\u2032\nj,\n(2)\nwhere \u2126is a symmetric positive definite matrix, and Ai and Bj are n \u00d7 n coefficient\nmatrices capturing the effects of past shocks and past covariances, and p and q represent\nthe orders of the process (Francq and Zako\u00efan, 2012; Scherrer and Ribarits, 2007). To\nreduce complexity, the BEKK(1,1) model is commonly used, which assumes p = q = 1,\nleading to the formulation:\nHt = \u2126+ A1rt\u22121r\u2032\nt\u22121A\u2032\n1 + B1Ht\u22121B\u2032\n1. (3)\nA further simplification of the BEKK model is the Scalar BEKK specification, which\nsimplifies the parameterization by imposing the following constraints: \u2126= CC\u2032, A1 =\n\u221aaI, and B1 =\n\u221a\nbI, where C is a lower triangular matrix and I denotes the identity\nmatrix. This results in the more compact form Ht as:\nHt = CC\u2032 + art\u22121r\u2032\nt\u22121 + bHt\u22121. (4)\nHere, a, b \u22650 are scalar parameters representing the effects of past shocks and lagged\ncovariances, respectively. The diagonal elements of C are assumed to be strictly non-zero,\nguaranteeing the positive definiteness of \u2126= CC\u2032, hence Ht (Francq and Zakoian, 2019;\nMatsui and Pedersen, 2022; Hafner and Preminger, 2009). Moreover, the stationarity\ncondition a + b < 1 ensures the decay of volatility over time, preserving the long-run sta-\nbility of the process (Scherrer and Ribarits, 2007; Hafner et al., 2017). This parsimonious\nstructure drastically reduces the number of parameters in full BEKK models. From an econometric perspective, the parameters a and b have intuitive interpreta-\ntions. The parameter a measures the sensitivity of the conditional covariance matrix to\nthe past shocks, capturing the immediate effect of return innovations on volatility.",
  "The diagonal elements of C are assumed to be strictly non-zero,\nguaranteeing the positive definiteness of \u2126= CC\u2032, hence Ht (Francq and Zakoian, 2019;\nMatsui and Pedersen, 2022; Hafner and Preminger, 2009). Moreover, the stationarity\ncondition a + b < 1 ensures the decay of volatility over time, preserving the long-run sta-\nbility of the process (Scherrer and Ribarits, 2007; Hafner et al., 2017). This parsimonious\nstructure drastically reduces the number of parameters in full BEKK models. From an econometric perspective, the parameters a and b have intuitive interpreta-\ntions. The parameter a measures the sensitivity of the conditional covariance matrix to\nthe past shocks, capturing the immediate effect of return innovations on volatility. Mean-\nwhile, b reflects the persistence of volatility over time, characterizing how past volatilities\ninfluence future dynamics. Together, these parameters provide a framework for under-\nstanding how risk propagates through time in financial markets. The Scalar BEKK model postulates the conditional covariance matrix as a simple\nlinear summation between its lagged value and the outer product of the past shock vec-\ntor. While this assumption facilitates estimation and ensures computational tractability,\nit limits the model\u2019s ability to capture more complex, nonlinear relationships among as-\nsets (Caporin and McAleer, 2008; Hafner and Rombouts, 2007; Scherrer and Ribarits,\n2007). These limitations inspire the development of our LSTM-BEKK model, presented\n5\n\n\n--- Page 6 ---\nin Section 2.2, which integrates machine learning techniques into Scalar BEKK to en-\nhance its adaptability and ability to capture richer dynamics, while still maintaining its\neconometric interpretability. In summary, the Scalar BEKK model strikes a balance between simplicity and efficacy,\nmaking it an essential tool for modeling multivariate volatility in financial markets.",
  "Together, these parameters provide a framework for under-\nstanding how risk propagates through time in financial markets. The Scalar BEKK model postulates the conditional covariance matrix as a simple\nlinear summation between its lagged value and the outer product of the past shock vec-\ntor. While this assumption facilitates estimation and ensures computational tractability,\nit limits the model\u2019s ability to capture more complex, nonlinear relationships among as-\nsets (Caporin and McAleer, 2008; Hafner and Rombouts, 2007; Scherrer and Ribarits,\n2007). These limitations inspire the development of our LSTM-BEKK model, presented\n5\n\n\n--- Page 6 ---\nin Section 2.2, which integrates machine learning techniques into Scalar BEKK to en-\nhance its adaptability and ability to capture richer dynamics, while still maintaining its\neconometric interpretability. In summary, the Scalar BEKK model strikes a balance between simplicity and efficacy,\nmaking it an essential tool for modeling multivariate volatility in financial markets. Its\nparsimonious structure and intuitive economic interpretation make it particularly suitable\nfor applications such as portfolio risk management, systemic risk analysis, and stress\ntesting. However, its reliance on over-parsimonious parameterization necessitates further\nextensions, to address the complexities of real-world financial data. 2.1.2\nDynamic Conditional Correlation (DCC) Model\nThe DCC model, introduced by Engle (2002), represents a major advancement in mul-\ntivariate volatility modeling by efficiently capturing time-varying correlations in high-\ndimensional datasets. Unlike the full BEKK model, which suffers from parameter prolif-\neration in large systems, the DCC model decomposes the conditional covariance matrix\ninto conditional variances and correlations, enabling a computationally efficient estimation\nframework. The DCC model decomposes Ht as:\nHt = DtRtDt,\n(5)\nwhere Dt = diag(\np\nht,1, . . . ,\np\nht,n) is a diagonal matrix of conditional standard devia-\ntions, and Rt is the conditional correlation matrix.",
  "The DCC model decomposes Ht as:\nHt = DtRtDt,\n(5)\nwhere Dt = diag(\np\nht,1, . . . ,\np\nht,n) is a diagonal matrix of conditional standard devia-\ntions, and Rt is the conditional correlation matrix. The diagonal elements of Dt are modeled as univariate GARCH processes:\nhi,t = \u03c9i + \u03b1ir2\ni,t\u22121 + \u03b2ihi,t\u22121,\ni = 1, . . . , n,\n(6)\nwhere \u03c9i > 0, \u03b1i \u22650, and \u03b2i \u22650 and \u03b1i + \u03b2i < 1 ensure positivity and stationarity of the\nconditional variances. The correlation dynamics are governed by the intermediate matrix\nQt, updated recursively as:\nQt = (1 \u2212a \u2212b)S + azt\u22121z\u2032\nt\u22121 + bQt\u22121,\n(7)\nwhere zt = D\u22121\nt rt is the vector of standardized residuals, and S is the unconditional\ncovariance matrix of zt. In this formulation, the parameters a and b play central roles in\ndetermining the dynamics of the conditional correlation matrix. Specifically, a governs\nthe sensitivity of correlations to recent shocks in the standardized residuals (i.e., the\ninnovation effect), while b controls the persistence of past correlations. The sum a+b < 1\nis imposed to ensure stationarity and to guarantee that the conditional correlation matrix\nremains well-defined over time. Together, these parameters dictate the responsiveness and\nmemory of the correlation dynamics, with higher values indicating stronger persistence\nand slower adaptation to new information. The matrix S is typically estimated as the\nsample covariance of the standardized residuals during the initial estimation stage:\nS = 1\nT\nT\nX\nt=1\nztz\u2032\nt,\n(8)\n6\n\n\n--- Page 7 ---\nwhere T is the sample size. The conditional correlation matrix Rt is obtained by stan-\ndardizing Qt:\nRt = diag(Qt)\u22121/2Qtdiag(Qt)\u22121/2. (9)\nThis ensures that Rt is symmetric, positive definite, and has unit diagonal elements.",
  "Together, these parameters dictate the responsiveness and\nmemory of the correlation dynamics, with higher values indicating stronger persistence\nand slower adaptation to new information. The matrix S is typically estimated as the\nsample covariance of the standardized residuals during the initial estimation stage:\nS = 1\nT\nT\nX\nt=1\nztz\u2032\nt,\n(8)\n6\n\n\n--- Page 7 ---\nwhere T is the sample size. The conditional correlation matrix Rt is obtained by stan-\ndardizing Qt:\nRt = diag(Qt)\u22121/2Qtdiag(Qt)\u22121/2. (9)\nThis ensures that Rt is symmetric, positive definite, and has unit diagonal elements. The modular structure of the DCC model facilitates efficient estimation. In the first\nstep, univariate GARCH models are estimated to compute Dt. In the second step, the\ncorrelation dynamics are estimated using the standardized residuals zt. This separation\nreduces computational complexity compared to fully parameterized MGARCH models\n(Francq and Zako\u00efan, 2012; Bauwens et al., 2006), making the DCC model scalable to\nhigh-dimensional datasets. The DCC model has been widely adopted in applications\nsuch as portfolio optimization, risk management, and systemic risk evaluation (Bauwens\net al., 2006; Engle and Kelly, 2012). Extensions such as the corrected DCC model of\nAielli (2013) and regime-switching DCC variants of Bauwens and Otranto (2020) further\nimprove the adaptability of DCC in different application contexts. Overall, the DCC model represents a foundational tool in multivariate volatility\nmodeling due to its balance between parsimony and effectiveness. However, evolving\nmarket complexity increasingly demands more expressive models. Innovations such as\ndeep learning-augmented structures offer promising pathways to improve upon traditional\nframeworks and better accommodate the intricacies of modern asset return dynamics. 2.1.3\nLSTM Model\nDeep learning methods, particularly RNNs, have proven to be powerful tools for modeling\nsequential multivariate data.",
  "Overall, the DCC model represents a foundational tool in multivariate volatility\nmodeling due to its balance between parsimony and effectiveness. However, evolving\nmarket complexity increasingly demands more expressive models. Innovations such as\ndeep learning-augmented structures offer promising pathways to improve upon traditional\nframeworks and better accommodate the intricacies of modern asset return dynamics. 2.1.3\nLSTM Model\nDeep learning methods, particularly RNNs, have proven to be powerful tools for modeling\nsequential multivariate data. Among these, the LSTM network, introduced by Hochreiter\nand Schmidhuber (1997), stands out to be one of the most commonly used and effective\nRNN models. Its gating mechanism enables the selective retention of long-term depen-\ndencies, making it particularly suitable for applications in time series analysis, including\nfinancial volatility modeling (Goodfellow et al., 2016). The architecture of LSTM net-\nworks comprises three primary gates: the input gate (git), forget gate (gft), and output\ngate (got). These gates regulate the flow of information, dynamically updating the cell\nstate (ct) and hidden state (ht) to capture long-term and short-term patterns. Let xt be\nthe input vector at time t, and yt be the forecast variable of interest. The evolution of\nthese components can be described by the following equations:\ngit = \u03c3 (Wi[ht\u22121, xt] + bi) ,\n(10a)\ngft = \u03c3 (Wf[ht\u22121, xt] + bf) ,\n(10b)\ngot = \u03c3 (Wo[ht\u22121, xt] + bo) ,\n(10c)\n\u02dcct = tanh (Wc[ht\u22121, xt] + bc) ,\n(10d)\nct = gft \u2299ct\u22121 + git \u2299\u02dcct,\n(10e)\nht = got \u2299tanh(ct),\n(10f)\n7\n\n\n--- Page 8 ---\nwhere \u03c3(\u00b7) is the sigmoid activation function, tanh(\u00b7) is the hyperbolic tangent function,\nand \u2299denotes element-wise multiplication. The hidden state ht is then linked to the\nforecast variable yt by a measurement equation specified depending on the application\ncontext.",
  "The architecture of LSTM net-\nworks comprises three primary gates: the input gate (git), forget gate (gft), and output\ngate (got). These gates regulate the flow of information, dynamically updating the cell\nstate (ct) and hidden state (ht) to capture long-term and short-term patterns. Let xt be\nthe input vector at time t, and yt be the forecast variable of interest. The evolution of\nthese components can be described by the following equations:\ngit = \u03c3 (Wi[ht\u22121, xt] + bi) ,\n(10a)\ngft = \u03c3 (Wf[ht\u22121, xt] + bf) ,\n(10b)\ngot = \u03c3 (Wo[ht\u22121, xt] + bo) ,\n(10c)\n\u02dcct = tanh (Wc[ht\u22121, xt] + bc) ,\n(10d)\nct = gft \u2299ct\u22121 + git \u2299\u02dcct,\n(10e)\nht = got \u2299tanh(ct),\n(10f)\n7\n\n\n--- Page 8 ---\nwhere \u03c3(\u00b7) is the sigmoid activation function, tanh(\u00b7) is the hyperbolic tangent function,\nand \u2299denotes element-wise multiplication. The hidden state ht is then linked to the\nforecast variable yt by a measurement equation specified depending on the application\ncontext. These equations allow the LSTM network to adaptively learn from sequential\ndata by managing the flow of information across time steps. The reader is referred to\nGoodfellow et al. (2016) for a more detailed introduction of RNN models. The primary properties of the LSTM network include its ability to capture nonlin-\near relationships and long-term dependencies, which are crucial for financial time series\nexhibiting volatility clustering and structural breaks. Additionally, its architecture is\nrobust to noise, allowing it to generalize well across varied datasets. These properties\nmake LSTM networks an ideal choice for modeling financial volatility, complementing\ntraditional econometric models. 2.2\nThe LSTM-BEKK Model\nThe proposed LSTM-BEKK model represents a novel hybrid framework that integrates\nthe econometric structure of the Scalar BEKK model with the adaptive learning capa-\nbilities of LSTM neural networks.",
  "(2016) for a more detailed introduction of RNN models. The primary properties of the LSTM network include its ability to capture nonlin-\near relationships and long-term dependencies, which are crucial for financial time series\nexhibiting volatility clustering and structural breaks. Additionally, its architecture is\nrobust to noise, allowing it to generalize well across varied datasets. These properties\nmake LSTM networks an ideal choice for modeling financial volatility, complementing\ntraditional econometric models. 2.2\nThe LSTM-BEKK Model\nThe proposed LSTM-BEKK model represents a novel hybrid framework that integrates\nthe econometric structure of the Scalar BEKK model with the adaptive learning capa-\nbilities of LSTM neural networks. This approach enhances the traditional MGARCH\nframework by addressing its inherent linear assumptions and introducing the ability to\ncapture complex, nonlinear dynamics and temporal dependencies in financial volatility. Such a framework is particularly suited for high-dimensional datasets and volatile market\nconditions, where conventional models often struggle to balance flexibility and computa-\ntional feasibility. The LSTM-BEKK model extends the Scalar BEKK framework by incorporating a\ndynamic component, Ct, generated by a LSTM network. The conditional covariance\nmatrix Ht is expressed as:\nHt = CC\u2032 + CtC\u2032\nt + art\u22121r\u2032\nt\u22121 + bHt\u22121,\n(11)\nwhere C is a static lower triangular matrix with suitable constraints ensuring the positive\ndefiniteness of Ht, and a, b \u22650 are scalar parameters capturing the impact of past shocks\nand volatilities. The LSTM-generated lower-triangular matrix Ct dynamically adapts to\nchanging market conditions, introducing flexibility to model nonlinear dependencies and\nevolving relationships among financial assets. The dynamic update of Ct is modeled through an LSTM network, which takes the\nmost recent return vector rt\u22121 as the input,\n\u02dcCt = LSTM(ht\u22121, rt\u22121),\n(12)\nwith the output vector \u02dcCt reshaped to form the lower-triangular matrix Ct.",
  "Such a framework is particularly suited for high-dimensional datasets and volatile market\nconditions, where conventional models often struggle to balance flexibility and computa-\ntional feasibility. The LSTM-BEKK model extends the Scalar BEKK framework by incorporating a\ndynamic component, Ct, generated by a LSTM network. The conditional covariance\nmatrix Ht is expressed as:\nHt = CC\u2032 + CtC\u2032\nt + art\u22121r\u2032\nt\u22121 + bHt\u22121,\n(11)\nwhere C is a static lower triangular matrix with suitable constraints ensuring the positive\ndefiniteness of Ht, and a, b \u22650 are scalar parameters capturing the impact of past shocks\nand volatilities. The LSTM-generated lower-triangular matrix Ct dynamically adapts to\nchanging market conditions, introducing flexibility to model nonlinear dependencies and\nevolving relationships among financial assets. The dynamic update of Ct is modeled through an LSTM network, which takes the\nmost recent return vector rt\u22121 as the input,\n\u02dcCt = LSTM(ht\u22121, rt\u22121),\n(12)\nwith the output vector \u02dcCt reshaped to form the lower-triangular matrix Ct. The vector\n\u02dcCt serves as an intermediate latent representation that captures both short-term and\nlong-term dependencies in return series via the recurrent structure of LSTM. The LSTM\n8\n\n\n--- Page 9 ---\nunit utilizes gating mechanisms\u2014specifically, input, forget, and output gates\u2014to regulate\ninformation flow dynamically. At each time step t, the LSTM processes rt\u22121 and the\nprevious hidden state ht\u22121 to generate an updated hidden state ht, which encodes the\ninformation from past observations, before outputting \u02dcCt. More specifically, we compute\nCt as\nCt = LowerTriangular\n\u0010\n\u02dcCt\n\u0011\n,\nCt,ii \u2190Ct,ii \u00b7 \u03c3(\u03b2Ct,ii). (13)\nThe diagonal elements are regularized via the Swish activation function x \u00b7 \u03c3(\u03b2x), with\n\u03b2 being a learnable parameter. We observe empirically that its smooth, non-monotonic\nshape helps stabilize the learning process during covariance matrix construction.",
  "The LSTM\n8\n\n\n--- Page 9 ---\nunit utilizes gating mechanisms\u2014specifically, input, forget, and output gates\u2014to regulate\ninformation flow dynamically. At each time step t, the LSTM processes rt\u22121 and the\nprevious hidden state ht\u22121 to generate an updated hidden state ht, which encodes the\ninformation from past observations, before outputting \u02dcCt. More specifically, we compute\nCt as\nCt = LowerTriangular\n\u0010\n\u02dcCt\n\u0011\n,\nCt,ii \u2190Ct,ii \u00b7 \u03c3(\u03b2Ct,ii). (13)\nThe diagonal elements are regularized via the Swish activation function x \u00b7 \u03c3(\u03b2x), with\n\u03b2 being a learnable parameter. We observe empirically that its smooth, non-monotonic\nshape helps stabilize the learning process during covariance matrix construction. The covariance structure in the LSTM-BEKK framework consists of two key compo-\nnents: the static matrix C and the dynamic component Ct. The static matrix C captures\nlong-term covariance structures, reflecting stable interdependencies among assets over ex-\ntended periods, while the dynamic component Ct adapts to short-term fluctuations and\nnonlinear relationships in asset correlations. This dynamic adaptation is particularly cru-\ncial during periods of financial stress when correlations between assets exhibit abrupt\nshifts. The LSTM\u2019s ability to update Ct in near real-time ensures that the model can\naccount for such changes effectively. The BEKK component, art\u22121r\u2032\nt\u22121 + bHt\u22121, helps stabilize the modeling of the covari-\nance matrix Ht, while retaining the economic interpretability. The parameter a reflects\nthe immediate impact of past shocks, and b represents the persistence of volatility. This\ncombination enables the LSTM-BEKK framework to offer nuanced insights into both\nshort-term and long-term market dynamics, providing a more robust approach to model-\ning financial volatility and correlation structures (Engle, 2002; Nguyen et al., 2022; Liu,\n2019). Compared to traditional models, the LSTM-BEKK framework offers significant im-\nprovements.",
  "The BEKK component, art\u22121r\u2032\nt\u22121 + bHt\u22121, helps stabilize the modeling of the covari-\nance matrix Ht, while retaining the economic interpretability. The parameter a reflects\nthe immediate impact of past shocks, and b represents the persistence of volatility. This\ncombination enables the LSTM-BEKK framework to offer nuanced insights into both\nshort-term and long-term market dynamics, providing a more robust approach to model-\ning financial volatility and correlation structures (Engle, 2002; Nguyen et al., 2022; Liu,\n2019). Compared to traditional models, the LSTM-BEKK framework offers significant im-\nprovements. While the Scalar BEKK model is parsimonious and computationally efficient,\nit relies on linear relationships and fixed parameters, limiting its ability to capture evolv-\ning dynamics in financial markets. Similarly, the DCC model introduces flexibility in\nmodeling time-varying correlations but assumes constant dynamics for conditional vari-\nances, which may overlook nonlinear patterns and structural breaks. By contrast, the\nLSTM-BEKK model combines the strengths of both approaches while addressing their\nlimitations. Its integration of LSTM networks enables it to capture the complex, nonlinear\ndependencies that characterize modern financial systems. Given the recursive nature in the construction (11) of the matrix Ht, its dynamics\nmight explode in terms of a matrix norm. Theorem 1 below studies sufficient conditions\nto prevent this issue. To impose these conditions in practice, apart from the condition\na, b \u22650, a + b < 1, it suffices to bound the maximum eigenvalue of CtC\u2032\nt.\nTheorem 1 Fix some matrix norm \u2225\u00b7\u2225and assume that \u2225CtC\u2032\nt\u2225is bounded almost surely\nfor all t. Furthermore, assume that a, b \u22650 and a + b < 1. Then, for any fixed, initial\n9\n\n\n--- Page 10 ---\nH0,\n\u2225E(Hk)\u2225\u22641 \u2212(a + b)k\n1 \u2212a \u2212b M + (a + b)k\u2225H0\u2225,\n(14)\nwhere M > 0 is a finite constant.",
  "Its integration of LSTM networks enables it to capture the complex, nonlinear\ndependencies that characterize modern financial systems. Given the recursive nature in the construction (11) of the matrix Ht, its dynamics\nmight explode in terms of a matrix norm. Theorem 1 below studies sufficient conditions\nto prevent this issue. To impose these conditions in practice, apart from the condition\na, b \u22650, a + b < 1, it suffices to bound the maximum eigenvalue of CtC\u2032\nt.\nTheorem 1 Fix some matrix norm \u2225\u00b7\u2225and assume that \u2225CtC\u2032\nt\u2225is bounded almost surely\nfor all t. Furthermore, assume that a, b \u22650 and a + b < 1. Then, for any fixed, initial\n9\n\n\n--- Page 10 ---\nH0,\n\u2225E(Hk)\u2225\u22641 \u2212(a + b)k\n1 \u2212a \u2212b M + (a + b)k\u2225H0\u2225,\n(14)\nwhere M > 0 is a finite constant. The proof can be found in the Appendix. In summary, the LSTM-BEKK model represents a significant advancement in multi-\nvariate volatility modeling. By embedding long-term stability through C and introducing\nshort-term flexibility via Ct, the model offers a robust and flexible framework for capturing\npersistent and transitory volatility dynamics. Its capacity to adapt to market conditions\ndynamically positions it as an invaluable tool for applications such as portfolio optimiza-\ntion, systemic risk analysis, and stress testing, paving the way for further innovations in\nfinancial econometrics. 3\nEstimation Procedure\n3.1\nLikelihood-Based Estimation\nThe LSTM-BEKK model parameters are estimated by minimizing the Negative Log-\nLikelihood (NLL) function, a standard approach in multivariate volatility modeling.",
  "The proof can be found in the Appendix. In summary, the LSTM-BEKK model represents a significant advancement in multi-\nvariate volatility modeling. By embedding long-term stability through C and introducing\nshort-term flexibility via Ct, the model offers a robust and flexible framework for capturing\npersistent and transitory volatility dynamics. Its capacity to adapt to market conditions\ndynamically positions it as an invaluable tool for applications such as portfolio optimiza-\ntion, systemic risk analysis, and stress testing, paving the way for further innovations in\nfinancial econometrics. 3\nEstimation Procedure\n3.1\nLikelihood-Based Estimation\nThe LSTM-BEKK model parameters are estimated by minimizing the Negative Log-\nLikelihood (NLL) function, a standard approach in multivariate volatility modeling. As-\nsuming that the de-meaned return vector rt follows a multivariate normal distribution,\nthe log-likelihood based on a training data set of T observations is:\n\u2113(\u03b8) =\nT\nX\nt=1\nlog Lt = \u22121\n2\nT\nX\nt=1\n\u0000n log(2\u03c0) + log |Ht| + r\u2032\ntH\u22121\nt rt\n\u0001\n. (15)\nThe parameter set \u03b8 to be estimated includes the lower-triangular matrix C, the scalar\nparameters a and b, and the parameters of the LSTM network. Following Theorem 1, we impose the constraints a, b \u22650, a + b < 1; we observe that\nthis also promotes numerical stability during estimation. This condition ensures that\nthe effects of past shocks and volatilities decay over time, preventing divergence of the\ncovariance matrix Ht.",
  "Its capacity to adapt to market conditions\ndynamically positions it as an invaluable tool for applications such as portfolio optimiza-\ntion, systemic risk analysis, and stress testing, paving the way for further innovations in\nfinancial econometrics. 3\nEstimation Procedure\n3.1\nLikelihood-Based Estimation\nThe LSTM-BEKK model parameters are estimated by minimizing the Negative Log-\nLikelihood (NLL) function, a standard approach in multivariate volatility modeling. As-\nsuming that the de-meaned return vector rt follows a multivariate normal distribution,\nthe log-likelihood based on a training data set of T observations is:\n\u2113(\u03b8) =\nT\nX\nt=1\nlog Lt = \u22121\n2\nT\nX\nt=1\n\u0000n log(2\u03c0) + log |Ht| + r\u2032\ntH\u22121\nt rt\n\u0001\n. (15)\nThe parameter set \u03b8 to be estimated includes the lower-triangular matrix C, the scalar\nparameters a and b, and the parameters of the LSTM network. Following Theorem 1, we impose the constraints a, b \u22650, a + b < 1; we observe that\nthis also promotes numerical stability during estimation. This condition ensures that\nthe effects of past shocks and volatilities decay over time, preventing divergence of the\ncovariance matrix Ht. Additionally, the diagonal elements of C are ensured to be strictly\nnon-zero values to guarantee the positive definiteness of the static component CC\u2032, hence\nHt for all t. We found empirically that it was unnecessary to bound the norm of CtC\u2032\nt.\n3.2\nOptimization Techniques\nGiven the high-dimensional nature of the model and the presence of both static (BEKK)\nand dynamic (LSTM) parameters, efficient optimization techniques are critical to ensure\nnumerical stability and convergence. 10\n\n\n--- Page 11 ---\nRMSprop Optimization Algorithm. To minimize the NLL function, this study em-\nploys the RMSprop optimizer, a popular choice in deep learning due to its adaptability\nand numerical stability in high-dimensional problems.",
  "(15)\nThe parameter set \u03b8 to be estimated includes the lower-triangular matrix C, the scalar\nparameters a and b, and the parameters of the LSTM network. Following Theorem 1, we impose the constraints a, b \u22650, a + b < 1; we observe that\nthis also promotes numerical stability during estimation. This condition ensures that\nthe effects of past shocks and volatilities decay over time, preventing divergence of the\ncovariance matrix Ht. Additionally, the diagonal elements of C are ensured to be strictly\nnon-zero values to guarantee the positive definiteness of the static component CC\u2032, hence\nHt for all t. We found empirically that it was unnecessary to bound the norm of CtC\u2032\nt.\n3.2\nOptimization Techniques\nGiven the high-dimensional nature of the model and the presence of both static (BEKK)\nand dynamic (LSTM) parameters, efficient optimization techniques are critical to ensure\nnumerical stability and convergence. 10\n\n\n--- Page 11 ---\nRMSprop Optimization Algorithm. To minimize the NLL function, this study em-\nploys the RMSprop optimizer, a popular choice in deep learning due to its adaptability\nand numerical stability in high-dimensional problems. The update rule for parameter \u03b8\nat iteration k is given by:\n\u03b8k+1 = \u03b8k \u2212\u03b7\ngk\np\nE[g2\nk] + \u03f5\n,\n(16)\nwhere:\n\u2022 \u03b7 is the learning rate,\n\u2022 gk = \u2207\u03b8\u2113(\u03b8k) is the gradient of the NLL function with respect to \u03b8,\n\u2022 E[g2\nk] is the exponentially weighted moving average of the squared gradients,\n\u2022 \u03f5 is a small constant to ensure numerical stability, typically set to 10\u22128. Initialization and Hyperparameter Tuning. Proper initialization of the parameters\nis essential for the stability and convergence of the optimization process. The static matrix\nC is initialized as a lower triangular matrix with non-zero values on the diagonal to ensure\nthe positive definiteness of Ht.",
  "To minimize the NLL function, this study em-\nploys the RMSprop optimizer, a popular choice in deep learning due to its adaptability\nand numerical stability in high-dimensional problems. The update rule for parameter \u03b8\nat iteration k is given by:\n\u03b8k+1 = \u03b8k \u2212\u03b7\ngk\np\nE[g2\nk] + \u03f5\n,\n(16)\nwhere:\n\u2022 \u03b7 is the learning rate,\n\u2022 gk = \u2207\u03b8\u2113(\u03b8k) is the gradient of the NLL function with respect to \u03b8,\n\u2022 E[g2\nk] is the exponentially weighted moving average of the squared gradients,\n\u2022 \u03f5 is a small constant to ensure numerical stability, typically set to 10\u22128. Initialization and Hyperparameter Tuning. Proper initialization of the parameters\nis essential for the stability and convergence of the optimization process. The static matrix\nC is initialized as a lower triangular matrix with non-zero values on the diagonal to ensure\nthe positive definiteness of Ht. The LSTM weights are initialized using standard methods\nsuch as Xavier initialization or He initialization to balance the scale of the input and\noutput gradients. The architecture of the LSTM network is designed to adapt to the complexity of\nthe portfolio, with the hidden size set equal to the input size to maintain consistency in\nfeature representation. The number of hidden layers ranges from three to five, increasing\nas the number of assets in the portfolio grows. To prevent overfitting, dropout rates are\nset between 0.1 and 0.2, with higher values applied in more complex models. To mitigate potential numerical instability arising from computing the determinant\n|Ht| and the inverse H\u22121\nt \u2014especially in high-dimensional settings\u2014the model employs\nCholesky decomposition, which enables more efficient and stable evaluation of the likeli-\nhood function. Furthermore, to avoid issues such as exploding gradients during training,\nregularization techniques including gradient clipping are incorporated into the optimiza-\ntion routine.",
  "The architecture of the LSTM network is designed to adapt to the complexity of\nthe portfolio, with the hidden size set equal to the input size to maintain consistency in\nfeature representation. The number of hidden layers ranges from three to five, increasing\nas the number of assets in the portfolio grows. To prevent overfitting, dropout rates are\nset between 0.1 and 0.2, with higher values applied in more complex models. To mitigate potential numerical instability arising from computing the determinant\n|Ht| and the inverse H\u22121\nt \u2014especially in high-dimensional settings\u2014the model employs\nCholesky decomposition, which enables more efficient and stable evaluation of the likeli-\nhood function. Furthermore, to avoid issues such as exploding gradients during training,\nregularization techniques including gradient clipping are incorporated into the optimiza-\ntion routine. The convergence of the training process is determined by monitoring the\nrelative change in the negative log-likelihood (NLL) between successive iterations, with\ntermination occurring once the change falls below a predefined threshold (typically 10\u22126). Additionally, early stopping is implemented based on validation performance to guard\nagainst overfitting and promote generalizability. The pseudocode describes the estima-\ntion procedure for LSTM-BEKK is provided in the Appendix. In summary, by leveraging the RMSprop optimizer and employing advanced numer-\nical techniques, the LSTM-BEKK model achieves efficient and stable convergence, even\nin high-dimensional settings. The combination of dynamic learning rates, robust gradi-\nent computation, and careful parameter initialization ensures that the model effectively\ncaptures the complex temporal and nonlinear dependencies inherent in financial markets. 11\n\n\n--- Page 12 ---\n4\nEmpirical Study\n4.1\nData and Descriptive Statistics\nThe data employed in this study comprises daily log returns for the top 250 publicly\ntraded equities from the United States (U.S.), the United Kingdom (U.K.), and Japan,\nselected based on market capitalization.",
  "Additionally, early stopping is implemented based on validation performance to guard\nagainst overfitting and promote generalizability. The pseudocode describes the estima-\ntion procedure for LSTM-BEKK is provided in the Appendix. In summary, by leveraging the RMSprop optimizer and employing advanced numer-\nical techniques, the LSTM-BEKK model achieves efficient and stable convergence, even\nin high-dimensional settings. The combination of dynamic learning rates, robust gradi-\nent computation, and careful parameter initialization ensures that the model effectively\ncaptures the complex temporal and nonlinear dependencies inherent in financial markets. 11\n\n\n--- Page 12 ---\n4\nEmpirical Study\n4.1\nData and Descriptive Statistics\nThe data employed in this study comprises daily log returns for the top 250 publicly\ntraded equities from the United States (U.S.), the United Kingdom (U.K.), and Japan,\nselected based on market capitalization. The data is sourced from Refinitiv data platform:\nhttps://www.refinitiv.com, which aggregates information from key exchanges includ-\ning NASDAQ OMX \u2013 NASDAQ BASIC, the New York Stock Exchange (NYSE), the\nLondon Stock Exchange (LSE), and the Tokyo Stock Exchange (TSE), thereby ensuring\ncomprehensive and high-quality market coverage across major global financial centers. This diversified selection provides a robust basis for evaluating the proposed volatility\nmodeling framework across heterogeneous market environments. The time coverage for each market differs slightly due to variations in trading calen-\ndars and data availability. Specifically, the U.S. dataset spans from March 2014 to De-\ncember 2023, the U.K. dataset from July 2014 to December 2023, and the Japan dataset\nfrom January 2014 to December 2023. All returns are computed as daily log returns and\nthen scaled by 100 to express them in percentage terms.",
  "The data is sourced from Refinitiv data platform:\nhttps://www.refinitiv.com, which aggregates information from key exchanges includ-\ning NASDAQ OMX \u2013 NASDAQ BASIC, the New York Stock Exchange (NYSE), the\nLondon Stock Exchange (LSE), and the Tokyo Stock Exchange (TSE), thereby ensuring\ncomprehensive and high-quality market coverage across major global financial centers. This diversified selection provides a robust basis for evaluating the proposed volatility\nmodeling framework across heterogeneous market environments. The time coverage for each market differs slightly due to variations in trading calen-\ndars and data availability. Specifically, the U.S. dataset spans from March 2014 to De-\ncember 2023, the U.K. dataset from July 2014 to December 2023, and the Japan dataset\nfrom January 2014 to December 2023. All returns are computed as daily log returns and\nthen scaled by 100 to express them in percentage terms. The total number of observations per asset reflects the respective market\u2019s trading\nactivity: the U.S. dataset contains 2,464 observations per stock, the U.K. dataset includes\n2,035 observations, and the Japan dataset provides 2433 observations. To facilitate rigor-\nous model training and evaluation, each return dataset is partitioned into 70% for training,\n15% for validation, and 15% for testing. 4.1.1\nDescriptive Statistics\nTables 1, 2, and 3 summarize the key characteristics of daily log returns for the three mar-\nkets, including the mean, standard deviation, minimum and maximum values, skewness,\nand kurtosis. The descriptive statistics in Table 1 reveal several important characteristics of the\nU.S. equity market. The average daily return across all assets is effectively zero, reflect-\ning the de-meaned nature of the log return series. The minimum and maximum daily\nreturns\u2014ranging from as low as \u221276.39% to as high as 55.76%\u2014indicate the presence of\nsubstantial market shocks and extreme events during the sample period.",
  "To facilitate rigor-\nous model training and evaluation, each return dataset is partitioned into 70% for training,\n15% for validation, and 15% for testing. 4.1.1\nDescriptive Statistics\nTables 1, 2, and 3 summarize the key characteristics of daily log returns for the three mar-\nkets, including the mean, standard deviation, minimum and maximum values, skewness,\nand kurtosis. The descriptive statistics in Table 1 reveal several important characteristics of the\nU.S. equity market. The average daily return across all assets is effectively zero, reflect-\ning the de-meaned nature of the log return series. The minimum and maximum daily\nreturns\u2014ranging from as low as \u221276.39% to as high as 55.76%\u2014indicate the presence of\nsubstantial market shocks and extreme events during the sample period. The standard\ndeviation of daily returns spans a wide range, with an average of approximately 1.85%,\nand reaching a maximum of 3.82%. These figures suggest considerable variation in risk\nacross different assets. The skewness values range from \u221211.67 to 1.51, with an average\nof \u22120.52, indicating that negative returns tend to occur more frequently than positive\nones\u2014a common characteristic in equity markets. Additionally, the kurtosis values, with\na mean of 16.23 and a maximum as high as 359.77, highlight the presence of heavy tails\n12\n\n\n--- Page 13 ---\nand extreme return distributions. These distributional features emphasize the necessity\nof adopting volatility modeling frameworks that can effectively capture such non-normal\nbehavior in financial time series. Table 1: Aggregated Descriptive Statistics of Daily Log Returns (%) for the Top 250 U.S.\nEquities.",
  "These figures suggest considerable variation in risk\nacross different assets. The skewness values range from \u221211.67 to 1.51, with an average\nof \u22120.52, indicating that negative returns tend to occur more frequently than positive\nones\u2014a common characteristic in equity markets. Additionally, the kurtosis values, with\na mean of 16.23 and a maximum as high as 359.77, highlight the presence of heavy tails\n12\n\n\n--- Page 13 ---\nand extreme return distributions. These distributional features emphasize the necessity\nof adopting volatility modeling frameworks that can effectively capture such non-normal\nbehavior in financial time series. Table 1: Aggregated Descriptive Statistics of Daily Log Returns (%) for the Top 250 U.S.\nEquities. Statistic\nMinimum\nAverage\nMaximum\nMean Return (%)\n-0.006\n-0.000\n0.006\nStandard Deviation (%)\n1.142\n1.849\n3.821\nMinimum Return (%)\n-76.394\n-18.406\n-7.783\nMaximum Return (%)\n6.137\n15.135\n55.761\nSkewness (log returns)\n-11.672\n-0.515\n1.510\nKurtosis (log returns)\n3.544\n16.234\n359.772\nNote: The table summarizes key statistics of daily log returns, expressed as percentages,\nfor the top 250 U.S. equities from March 2014 to December 2023. The statistics are\naggregated across all assets. The descriptive statistics for the U.K. equity market in Table 2 reveal several no-\ntable features that distinguish it from the U.S. market. The mean daily return across\nassets remains near zero, as expected for de-meaned log returns. However, the range of\nobserved returns is significantly wider, with the most extreme negative daily return reach-\ning \u221283.97% and the highest positive return peaking at 87.39%, reflecting the presence\nof substantial outliers and episodic market shocks. Volatility, as indicated by the stan-\ndard deviation, shows an average of 1.94% and a maximum of 4.88%, slightly exceeding\nthose observed in the U.S. dataset.",
  "The statistics are\naggregated across all assets. The descriptive statistics for the U.K. equity market in Table 2 reveal several no-\ntable features that distinguish it from the U.S. market. The mean daily return across\nassets remains near zero, as expected for de-meaned log returns. However, the range of\nobserved returns is significantly wider, with the most extreme negative daily return reach-\ning \u221283.97% and the highest positive return peaking at 87.39%, reflecting the presence\nof substantial outliers and episodic market shocks. Volatility, as indicated by the stan-\ndard deviation, shows an average of 1.94% and a maximum of 4.88%, slightly exceeding\nthose observed in the U.S. dataset. These values suggest that the U.K. market exhibits\nmarginally greater dispersion in daily returns across its top 50 equities. Skewness values\nrange from \u22124.90 to 3.86, with an average of \u22120.38, indicating a tendency for negative\nreturn asymmetry among U.K. equities. More strikingly, the kurtosis statistics are highly\nelevated, with a mean of 19.15 and a maximum of 552.30, far exceeding the Gaussian\nbenchmark of 3. This pronounced leptokurtosis points to the presence of extreme tail\nrisks and emphasizes the importance of adopting volatility models capable of capturing\nheavy-tailed behavior in return distributions. 13\n\n\n--- Page 14 ---\nTable 2: Aggregated Descriptive Statistics of Daily Log Returns (%) for the Top 250 U.K.\nEquities. Statistic\nMinimum\nAverage\nMaximum\nMean Return (%)\n-0.068\n0.000\n0.045\nStandard Deviation (%)\n0.509\n1.937\n4.881\nMinimum Return (%)\n-83.974\n-18.412\n-4.292\nMaximum Return (%)\n3.897\n16.081\n87.385\nSkewness (log returns)\n-4.899\n-0.380\n3.856\nKurtosis (log returns)\n2.465\n19.151\n552.298\nNote: The table summarizes key statistics of daily log returns, expressed as percentages,\nfor the top 250 U.K. equities from January 2014 to December 2023. The statistics are\naggregated across all assets.",
  "More strikingly, the kurtosis statistics are highly\nelevated, with a mean of 19.15 and a maximum of 552.30, far exceeding the Gaussian\nbenchmark of 3. This pronounced leptokurtosis points to the presence of extreme tail\nrisks and emphasizes the importance of adopting volatility models capable of capturing\nheavy-tailed behavior in return distributions. 13\n\n\n--- Page 14 ---\nTable 2: Aggregated Descriptive Statistics of Daily Log Returns (%) for the Top 250 U.K.\nEquities. Statistic\nMinimum\nAverage\nMaximum\nMean Return (%)\n-0.068\n0.000\n0.045\nStandard Deviation (%)\n0.509\n1.937\n4.881\nMinimum Return (%)\n-83.974\n-18.412\n-4.292\nMaximum Return (%)\n3.897\n16.081\n87.385\nSkewness (log returns)\n-4.899\n-0.380\n3.856\nKurtosis (log returns)\n2.465\n19.151\n552.298\nNote: The table summarizes key statistics of daily log returns, expressed as percentages,\nfor the top 250 U.K. equities from January 2014 to December 2023. The statistics are\naggregated across all assets. The descriptive statistics for the Japan equity market as shown in Table 3 reveal a\nmore stable return structure relative to the U.S. and U.K. counterparts. The average daily\nreturn across the top 250 equities is 0.003%, indicating a slightly positive drift in returns\nover the sample period. The observed minimum and maximum returns, at \u221230.54% and\n23.16% respectively, are less extreme than those in the U.K. market, reflecting compara-\ntively lower frequency of outlier events. The average standard deviation of daily returns\nis 1.94%, with a maximum of 3.01%, placing the Japan market in a similar volatility\nrange as the U.K. but slightly above that of the U.S. This suggests a moderate level of\ndaily fluctuations in asset prices, with sufficient variability to warrant dynamic volatility\nmodeling. In terms of distributional asymmetry, the skewness ranges from \u22121.11 to 0.86,\nwith a near-zero average of \u22120.01, implying a more balanced return distribution overall.",
  "The average daily\nreturn across the top 250 equities is 0.003%, indicating a slightly positive drift in returns\nover the sample period. The observed minimum and maximum returns, at \u221230.54% and\n23.16% respectively, are less extreme than those in the U.K. market, reflecting compara-\ntively lower frequency of outlier events. The average standard deviation of daily returns\nis 1.94%, with a maximum of 3.01%, placing the Japan market in a similar volatility\nrange as the U.K. but slightly above that of the U.S. This suggests a moderate level of\ndaily fluctuations in asset prices, with sufficient variability to warrant dynamic volatility\nmodeling. In terms of distributional asymmetry, the skewness ranges from \u22121.11 to 0.86,\nwith a near-zero average of \u22120.01, implying a more balanced return distribution overall. The kurtosis statistics, with an average of 5.69 and a maximum of 56.40, indicate the\npresence of heavy tails and occasional extreme movements, though less pronounced than\nin the U.K. market. These findings support the need for flexible, heavy-tail-aware volatil-\nity models that can accommodate both moderate skewness and leptokurtic behavior in\nJapan financial data. 14\n\n\n--- Page 15 ---\nTable 3: Aggregated Descriptive Statistics of Daily Log Returns (%) for the Top 250\nJapan Equities. Statistic\nMinimum\nAverage\nMaximum\nMean Return (%)\n-0.004\n0.003\n0.010\nStandard Deviation (%)\n1.333\n1.939\n3.010\nMinimum Return (%)\n-30.544\n-13.010\n-7.085\nMaximum Return (%)\n6.971\n13.008\n23.159\nSkewness (log returns)\n-1.110\n-0.010\n0.856\nKurtosis (log returns)\n1.640\n5.693\n56.401\nNote: The table summarizes key statistics of daily log returns, expressed as percentages,\nfor the top 250 Japan equities from March 2014 to December 2023. The statistics are\naggregated across all assets.",
  "The kurtosis statistics, with an average of 5.69 and a maximum of 56.40, indicate the\npresence of heavy tails and occasional extreme movements, though less pronounced than\nin the U.K. market. These findings support the need for flexible, heavy-tail-aware volatil-\nity models that can accommodate both moderate skewness and leptokurtic behavior in\nJapan financial data. 14\n\n\n--- Page 15 ---\nTable 3: Aggregated Descriptive Statistics of Daily Log Returns (%) for the Top 250\nJapan Equities. Statistic\nMinimum\nAverage\nMaximum\nMean Return (%)\n-0.004\n0.003\n0.010\nStandard Deviation (%)\n1.333\n1.939\n3.010\nMinimum Return (%)\n-30.544\n-13.010\n-7.085\nMaximum Return (%)\n6.971\n13.008\n23.159\nSkewness (log returns)\n-1.110\n-0.010\n0.856\nKurtosis (log returns)\n1.640\n5.693\n56.401\nNote: The table summarizes key statistics of daily log returns, expressed as percentages,\nfor the top 250 Japan equities from March 2014 to December 2023. The statistics are\naggregated across all assets. 4.1.2\nImplications for Model Selection\nThese descriptive statistics offer valuable insights into the distributional properties and\nrisk profiles of equity returns across the U.S., U.K., and Japan markets. Although all\nthree markets exhibit near-zero average daily returns, they differ significantly in their\nvolatility levels, skewness, and kurtosis. Notably, the Japan market demonstrates the\nmost balanced return distribution with relatively lower skewness and moderate kurtosis,\nwhereas the U.K. market exhibits the most extreme tail behavior, with exceptionally high\nmaximum kurtosis and skewness values. The U.S. market falls between these two in terms\nof both volatility and tail risk. These differences have important implications for volatility modeling. The presence of\nleptokurtic behavior and negative skewness across all markets signals a departure from the\nnormality assumption. Furthermore, the cross-market variation in volatility magnitudes\nand distributional shapes suggests that a single, rigid modeling framework may not be\nequally effective across different financial environments.",
  "Notably, the Japan market demonstrates the\nmost balanced return distribution with relatively lower skewness and moderate kurtosis,\nwhereas the U.K. market exhibits the most extreme tail behavior, with exceptionally high\nmaximum kurtosis and skewness values. The U.S. market falls between these two in terms\nof both volatility and tail risk. These differences have important implications for volatility modeling. The presence of\nleptokurtic behavior and negative skewness across all markets signals a departure from the\nnormality assumption. Furthermore, the cross-market variation in volatility magnitudes\nand distributional shapes suggests that a single, rigid modeling framework may not be\nequally effective across different financial environments. Consequently, flexible and data-adaptive models, such as the proposed LSTM-BEKK,\nwhich integrate deep learning architectures with econometric structures, are better po-\nsitioned to capture the nonlinearities and heteroscedasticity inherent in global equity\nmarkets. Their capacity to adjust dynamically to distinct distributional patterns and\nstructural complexities makes them particularly well-suited for international applications\nwhere market characteristics vary substantially. 4.2\nEmpirical Evaluation Framework\nBuilding on the dataset and market characteristics discussed in Section 4.1, this subsection\noutlines the empirical framework employed to evaluate the performance of the proposed\n15\n\n\n--- Page 16 ---\nLSTM-BEKK model. Our objective is to examine the model\u2019s capability to capture\nthe dynamics of financial return volatility, both qualitatively and quantitatively, across\nvarying portfolio dimensions and market environments. The empirical strategy consists of two key components. First, we conduct an in-\nsample analysis using low-dimensional portfolios to visualize and compare the time-\nvarying covariance structures estimated by different models. This allows for intuitive\nobservation of how LSTM-BEKK captures diagonal (variance) and off-diagonal (covari-\nance) dynamics relative to traditional approaches. Second, we implement a comprehensive out-of-sample evaluation based on NLL, aim-\ning to rigorously assess the robustness and generalizability of each model.",
  "The empirical strategy consists of two key components. First, we conduct an in-\nsample analysis using low-dimensional portfolios to visualize and compare the time-\nvarying covariance structures estimated by different models. This allows for intuitive\nobservation of how LSTM-BEKK captures diagonal (variance) and off-diagonal (covari-\nance) dynamics relative to traditional approaches. Second, we implement a comprehensive out-of-sample evaluation based on NLL, aim-\ning to rigorously assess the robustness and generalizability of each model. For robust-\nness checks, we construct 500 randomly selected 50-asset portfolios for each market and\nconduct repeated experiments to compare the performance. We apply paired t-tests to\nevaluate the statistical significance of the differences in out-of-sample NLL values between\nLSTM-BEKK and the competing models. To investigate scalability and practical relevance, we further test the models\u2019 perfor-\nmance on the top 100, 175, and 250 equities by market capitalization in each market. These single-run experiments are complemented by Global Minimum Variance (GMV)\nportfolio backtests to assess real-world risk control and capital allocation efficacy. Ad-\nditionally, we apply the Model Confidence Set (MCS) of Hansen et al. (2011) to the\nout-of-sample NLL results, identifying statistically superior models under different confi-\ndence thresholds. This two-stage empirical setup enables us to evaluate the LSTM-BEKK model across\nmultiple dimensions\u2014visual interpretability, statistical robustness, and portfolio-level per-\nformance\u2014thereby offering a comprehensive view of its modeling advantages and practical\nviability. 4.3\nIn-Sample Visualization: Low-Dimensional Covariance Dy-\nnamics\nTo better understand the in-sample behavior of different multivariate volatility models,\nwe begin our empirical evaluation with a low-dimensional case. Specifically, we construct\na 4-asset portfolio using U.S. equities to visualize the time-varying covariance dynamics\ncaptured by each model.",
  "(2011) to the\nout-of-sample NLL results, identifying statistically superior models under different confi-\ndence thresholds. This two-stage empirical setup enables us to evaluate the LSTM-BEKK model across\nmultiple dimensions\u2014visual interpretability, statistical robustness, and portfolio-level per-\nformance\u2014thereby offering a comprehensive view of its modeling advantages and practical\nviability. 4.3\nIn-Sample Visualization: Low-Dimensional Covariance Dy-\nnamics\nTo better understand the in-sample behavior of different multivariate volatility models,\nwe begin our empirical evaluation with a low-dimensional case. Specifically, we construct\na 4-asset portfolio using U.S. equities to visualize the time-varying covariance dynamics\ncaptured by each model. The selected stocks include the two largest U.S. firms by mar-\nket capitalization\u2014MSFT.NB (Microsoft) and AAPL.NB (Apple)\u2014along with two stocks\n(SCHW.N and NEM.N) chosen to exhibit negative pairwise correlations with the market\nleaders. This selection allows us to examine both the variance structure of dominant mar-\nket assets and the model\u2019s ability to capture asymmetric dependence in the off-diagonal\nelements of the covariance matrix. 16\n\n\n--- Page 17 ---\n4.3.1\nDiagonal Elements: Variance Dynamics\nFigures 1a and 1b compare the estimated variances (i.e., the diagonal elements of the con-\nditional covariance matrix) for MSFT.NB and AAPL.NB, respectively, across the Scalar\nBEKK, DCC, and LSTM-BEKK models. In both cases, all models exhibit broadly similar\nvolatility patterns during tranquil market periods, validating the baseline consistency of\neach specification. It is important to note that in the DCC model, the diagonal elements of the condi-\ntional covariance matrix correspond directly to univariate GARCH(1,1) estimates for each\nasset. As such, these trajectories provide a standard benchmark for marginal volatility\ndynamics. Significant divergence among the models emerges during episodes of market turbu-\nlence. In early 2020, corresponding to the outbreak of the COVID-19 pandemic, volatility\nsurged dramatically across both MSFT.NB and AAPL.NB.",
  "In both cases, all models exhibit broadly similar\nvolatility patterns during tranquil market periods, validating the baseline consistency of\neach specification. It is important to note that in the DCC model, the diagonal elements of the condi-\ntional covariance matrix correspond directly to univariate GARCH(1,1) estimates for each\nasset. As such, these trajectories provide a standard benchmark for marginal volatility\ndynamics. Significant divergence among the models emerges during episodes of market turbu-\nlence. In early 2020, corresponding to the outbreak of the COVID-19 pandemic, volatility\nsurged dramatically across both MSFT.NB and AAPL.NB. During this regime shift, the\nDCC model displays an exaggerated overshooting behavior in variance estimation, sug-\ngesting a delayed and unstable response to sudden structural changes. Unlike full BEKK\nor more adaptive structures, the Scalar BEKK model enforces homogeneity by applying\nthe same a and b parameters across all asset pairs. This design restricts its flexibility and\nessentially imposes a global GARCH-like volatility dynamic on the entire portfolio, which\ncan hinder its ability to capture heterogeneous shock responses across assets. As a result,\nthe model tends to produce smoothed volatility paths that may underreact to localized\nor asset-specific structural shifts. The LSTM-BEKK model, by contrast, demonstrates a desirable combination of\nsmoothness and responsiveness. It aligns closely with Scalar BEKK during normal peri-\nods but adjusts more quickly and moderately to crisis-induced volatility spikes, providing\nmore balanced variance estimates. This behavior highlights the strength of the LSTM\narchitecture in extracting relevant temporal patterns while suppressing short-term noise. (a)\nIn-Sample\nVariance\nEstimation\nfor\nMSFT.NB Across Models. (b)\nIn-Sample\nVariance\nEstimation\nfor\nAAPL.NB Across Models. Figure 1: Volatility dynamics (i.e, the diagonal elements of the covariance matrix) across\nmodels.",
  "This behavior highlights the strength of the LSTM\narchitecture in extracting relevant temporal patterns while suppressing short-term noise. (a)\nIn-Sample\nVariance\nEstimation\nfor\nMSFT.NB Across Models. (b)\nIn-Sample\nVariance\nEstimation\nfor\nAAPL.NB Across Models. Figure 1: Volatility dynamics (i.e, the diagonal elements of the covariance matrix) across\nmodels. To better understand these dynamics, Table 4 presents the estimated parameters for\n17\n\n\n--- Page 18 ---\neach model in the four-asset portfolio setting. In particular, the sum a + b serves as\na common proxy for volatility persistence. For Scalar BEKK, the sum reaches 0.984,\nsuggesting a highly persistent volatility process that may lead to sluggish updates in\nrapidly changing environments. The LSTM-BEKK model, by contrast, yields a slightly\nlower persistence at 0.968, striking a balance between flexibility and memory. This subtle\ndifference becomes crucial in capturing abrupt regime shifts such as the COVID-19 shock. In this setting, excessive persistence\u2014as in Scalar BEKK\u2014can hinder the model\u2019s ability\nto respond swiftly, whereas overly reactive models may introduce instability. LSTM-\nBEKK thus offers a middle ground, adapting promptly without overfitting to transitory\nnoise. It is worth noting that, while the parameters a and b appear across all three models,\ntheir interpretations differ across modeling frameworks. In the BEKK-type models, a\ngoverns the response to past shocks, and b controls the persistence of past covariances. In the DCC model, the a and b terms govern the evolution of standardized conditional\ncorrelations, rather than the conditional covariances. Table 4: U.S.: Parameter Estimates and Persistence for DCC, Scalar BEKK, and LSTM-\nBEKK Models (4 Assets).",
  "It is worth noting that, while the parameters a and b appear across all three models,\ntheir interpretations differ across modeling frameworks. In the BEKK-type models, a\ngoverns the response to past shocks, and b controls the persistence of past covariances. In the DCC model, the a and b terms govern the evolution of standardized conditional\ncorrelations, rather than the conditional covariances. Table 4: U.S.: Parameter Estimates and Persistence for DCC, Scalar BEKK, and LSTM-\nBEKK Models (4 Assets). Portfolio Size\nModel\na\nb\na + b\n4\nDCC\n0.042\n0.871\n0.913\nScalar BEKK\n0.033\n0.952\n0.984\nLSTM-BEKK\n0.038\n0.930\n0.968\n4.3.2\nOff-Diagonal Elements: Covariance Dynamics\nFigures 2a and 2b illustrate the estimated covariances for two representative asset pairs:\nMSFT.NB & AAPL.NB and SCHW.N & NEM.N. These pairs are selected based on their\nhistorical sample covariances computed from the training set. Specifically, MSFT.NB\n& AAPL.NB exhibit persistently positive covariance, while SCHW.N & NEM.N display\npredominantly negative covariance values, making them suitable for evaluating the mod-\nels\u2019 ability to capture both positive and negative co-movement patterns. These results\nemphasize the LSTM-BEKK model\u2019s ability to flexibly learn and replicate different types\nof co-movement patterns. For the MSFT-AAPL pair, LSTM-BEKK captures the upward trending correlation\nstructure during bullish markets and the sharp co-movement under crisis conditions (e.g.,\nCOVID-19), consistent with DCC. However, it demonstrates enhanced numerical stabil-\nity and smoother transitions compared to DCC, which again tends to generate extreme\nfluctuations. More importantly, for the SCHW-NEM pair, which shows a structurally negative\ncorrelation, LSTM-BEKK successfully tracks the time-varying negative covariance. Com-\n18\n\n\n--- Page 19 ---\npared to Scalar BEKK and DCC, the LSTM-based model is better able to model the\nreturn divergence during market shocks, without flipping signs or generating erratic out-\nliers.",
  "These results\nemphasize the LSTM-BEKK model\u2019s ability to flexibly learn and replicate different types\nof co-movement patterns. For the MSFT-AAPL pair, LSTM-BEKK captures the upward trending correlation\nstructure during bullish markets and the sharp co-movement under crisis conditions (e.g.,\nCOVID-19), consistent with DCC. However, it demonstrates enhanced numerical stabil-\nity and smoother transitions compared to DCC, which again tends to generate extreme\nfluctuations. More importantly, for the SCHW-NEM pair, which shows a structurally negative\ncorrelation, LSTM-BEKK successfully tracks the time-varying negative covariance. Com-\n18\n\n\n--- Page 19 ---\npared to Scalar BEKK and DCC, the LSTM-based model is better able to model the\nreturn divergence during market shocks, without flipping signs or generating erratic out-\nliers. This highlights the flexibility of LSTM-BEKK in accommodating both positive and\nnegative dependencies in multivariate financial data. (a) MSFT.NB & AAPL.NB (predominantly\npositive covariance). (b) SCHW.N & NEM.N (predominantly neg-\native covariance with occasional reversals). Figure 2: Covariance dynamics comparison across models for asset pairs with differing\ncorrelation structures. Overall, these low-dimensional visualizations provide compelling empirical evidence\nthat the LSTM-BEKK model not only replicates the well-established volatility dynam-\nics of traditional MGARCH models but also offers greater adaptability to complex and\nheterogeneous covariance structures, particularly under market stress conditions. 4.4\nAssessing Model Generalization: Out-of-Sample Tests on 50-\nAsset Portfolios\n4.4.1\nExperimental Design and Objective\nThis subsection investigates the out-of-sample performance of the multivariate volatility\nmodels through repeated experiments on medium-sized portfolios. Specifically, we evalu-\nate their generalization and robustness by applying them to randomly generated 50-asset\nportfolios across the three equity markets: the U.S., the U.K., and Japan. For each market, we construct 500 distinct portfolios, each consisting of 50 assets\nchosen randomly.",
  "Overall, these low-dimensional visualizations provide compelling empirical evidence\nthat the LSTM-BEKK model not only replicates the well-established volatility dynam-\nics of traditional MGARCH models but also offers greater adaptability to complex and\nheterogeneous covariance structures, particularly under market stress conditions. 4.4\nAssessing Model Generalization: Out-of-Sample Tests on 50-\nAsset Portfolios\n4.4.1\nExperimental Design and Objective\nThis subsection investigates the out-of-sample performance of the multivariate volatility\nmodels through repeated experiments on medium-sized portfolios. Specifically, we evalu-\nate their generalization and robustness by applying them to randomly generated 50-asset\nportfolios across the three equity markets: the U.S., the U.K., and Japan. For each market, we construct 500 distinct portfolios, each consisting of 50 assets\nchosen randomly. This setting is designed to capture diverse correlation structures and\nvolatility regimes within each market, thereby enabling a thorough assessment of the mod-\nels\u2019 adaptability. All experiments are conducted using the out-of-sample data, ensuring a\nfair evaluation of predictive performance under realistic conditions. We adopt a fixed-parameter evaluation scheme: model parameters are estimated once\nusing the training and validation data and then held fixed throughout the test period. The\ntest performance is measured using NLL, which captures the accuracy of the predicted\ncovariance matrix in explaining the realized return series. To ensure statistical credibility,\n19\n\n\n--- Page 20 ---\nwe conduct 500 runs per market and aggregate the results to analyze mean performance\nand variability across random samples. The same expanding window strategy and test NLL metric are employed in the subse-\nquent high-dimensional evaluation in Section 4.5, where we compare model performance\nacross larger portfolio sizes of 100, 175, and 250 assets. This consistency ensures that\ninsights obtained from the medium-scale experiments generalize meaningfully to more\ncomplex portfolio settings.",
  "We adopt a fixed-parameter evaluation scheme: model parameters are estimated once\nusing the training and validation data and then held fixed throughout the test period. The\ntest performance is measured using NLL, which captures the accuracy of the predicted\ncovariance matrix in explaining the realized return series. To ensure statistical credibility,\n19\n\n\n--- Page 20 ---\nwe conduct 500 runs per market and aggregate the results to analyze mean performance\nand variability across random samples. The same expanding window strategy and test NLL metric are employed in the subse-\nquent high-dimensional evaluation in Section 4.5, where we compare model performance\nacross larger portfolio sizes of 100, 175, and 250 assets. This consistency ensures that\ninsights obtained from the medium-scale experiments generalize meaningfully to more\ncomplex portfolio settings. 4.4.2\nModel Performance Across Random Portfolios\nTable 5 presents the aggregated out-of-sample NLL values and estimated model parame-\nters for the DCC, Scalar BEKK, and LSTM-BEKK models across 500 randomly selected\n50-asset portfolios in the U.S., U.K., and Japan equity markets. The reported NLL values\nreflect average performance over 500 independent test sets, while the values in parentheses\nrepresent the corresponding standard deviations. Across all three markets, the LSTM-BEKK model consistently achieves the lowest\naverage NLL, indicating superior ability to capture dynamic covariance structures in\nout-of-sample scenarios. In the U.S. market, the LSTM-BEKK model attains a mean\nNLL of 85.031, with the lowest standard deviation of 1.484\u2014outperforming both Scalar\nBEKK (85.278, 1.535) and DCC (86.549, 1.644). This suggests that in addition to better\nin-sample fit, LSTM-BEKK exhibits greater forecast accuracy across varying portfolio\ncompositions. In the Japan market, a similar trend is observed: LSTM-BEKK achieves the best\naverage NLL of 86.832 with a standard deviation of 1.707, again surpassing Scalar BEKK\n(87.214, 1.746) and DCC (87.254, 1.752).",
  "The reported NLL values\nreflect average performance over 500 independent test sets, while the values in parentheses\nrepresent the corresponding standard deviations. Across all three markets, the LSTM-BEKK model consistently achieves the lowest\naverage NLL, indicating superior ability to capture dynamic covariance structures in\nout-of-sample scenarios. In the U.S. market, the LSTM-BEKK model attains a mean\nNLL of 85.031, with the lowest standard deviation of 1.484\u2014outperforming both Scalar\nBEKK (85.278, 1.535) and DCC (86.549, 1.644). This suggests that in addition to better\nin-sample fit, LSTM-BEKK exhibits greater forecast accuracy across varying portfolio\ncompositions. In the Japan market, a similar trend is observed: LSTM-BEKK achieves the best\naverage NLL of 86.832 with a standard deviation of 1.707, again surpassing Scalar BEKK\n(87.214, 1.746) and DCC (87.254, 1.752). These results confirm the model\u2019s robustness in\ncapturing return dynamics even under differing volatility regimes and correlation struc-\ntures. The U.K. market presents a more nuanced case. While LSTM-BEKK still achieves\nthe best mean NLL of 93.328, its standard deviation of 2.479 is marginally higher than\nthat of Scalar BEKK (2.408). This suggests that although LSTM-BEKK performs better\non average, Scalar BEKK may yield more consistent results under certain U.K. specific\nmarket conditions. Nevertheless, the gap in mean NLL remains notable, underscoring\nLSTM-BEKK\u2019s enhanced capacity for learning complex cross-asset relationships. Taken together, these findings provide compelling evidence of the generalizability\nand robustness of the LSTM-BEKK model. The model not only delivers the best average\nfit across all markets but also maintains competitive\u2014if not superior\u2014stability across\nrepeated portfolio simulations. This provides strong evidence that LSTM-enhanced co-\nvariance structures can effectively generalize to unseen data, validating their applicability\nin practical financial risk modeling contexts.",
  "Nevertheless, the gap in mean NLL remains notable, underscoring\nLSTM-BEKK\u2019s enhanced capacity for learning complex cross-asset relationships. Taken together, these findings provide compelling evidence of the generalizability\nand robustness of the LSTM-BEKK model. The model not only delivers the best average\nfit across all markets but also maintains competitive\u2014if not superior\u2014stability across\nrepeated portfolio simulations. This provides strong evidence that LSTM-enhanced co-\nvariance structures can effectively generalize to unseen data, validating their applicability\nin practical financial risk modeling contexts. 20\n\n\n--- Page 21 ---\nTable 5: Parameter Estimates and NLL for DCC, Scalar BEKK, and LSTM-BEKK Mod-\nels (Portfolio Size = 50). Market\nModel\nNLL\na\nb\nU.S.\nDCC\n86.549\n(1.644)\n0.023\n0.704\nScalar BEKK\n85.278\n(1.535)\n0.008\n0.975\nLSTM-BEKK\n85.031\n(1.484)\n0.008\n0.974\nU.K.\nDCC\n93.758\n(3.005)\n0.013\n0.699\nScalar BEKK\n93.587\n(2.408)\n0.009\n0.971\nLSTM-BEKK\n93.328\n(2.479)\n0.008\n0.978\nJapan\nDCC\n87.254\n(1.752)\n0.010\n0.710\nScalar BEKK\n87.214\n(1.746)\n0.011\n0.934\nLSTM-BEKK\n86.832\n(1.707)\n0.004\n0.991\nNote: Values in parentheses denote standard deviations across 500 portfolios. 4.4.3\nStatistical Significance Tests\nTo further assess whether the observed improvements in out-of-sample NLL by the LSTM-\nBEKK model are statistically significant, we conduct paired t-tests between LSTM-BEKK\nand the two benchmark models (DCC and Scalar BEKK) across the 500 randomly gen-\nerated 50-asset portfolios for each market. The results are reported in Table 6. In the U.S. market, the LSTM-BEKK model significantly outperforms both bench-\nmarks. The average NLL improvement over DCC is substantial (\u22121.518), with a highly\nsignificant t-statistic of \u221215.326 (p < 0.001), confirming consistent superiority. The im-\nprovement over Scalar BEKK is more modest (\u22120.247) but still statistically significant\n(p = 0.009). In the U.K. market, the difference between LSTM-BEKK and DCC remains signif-\nicant (p = 0.014), albeit at a smaller magnitude (\u22120.430).",
  "The results are reported in Table 6. In the U.S. market, the LSTM-BEKK model significantly outperforms both bench-\nmarks. The average NLL improvement over DCC is substantial (\u22121.518), with a highly\nsignificant t-statistic of \u221215.326 (p < 0.001), confirming consistent superiority. The im-\nprovement over Scalar BEKK is more modest (\u22120.247) but still statistically significant\n(p = 0.009). In the U.K. market, the difference between LSTM-BEKK and DCC remains signif-\nicant (p = 0.014), albeit at a smaller magnitude (\u22120.430). The comparison with Scalar\nBEKK yields a p-value of 0.094, indicating marginal significance at the 10% level. This\nsuggests that while LSTM-BEKK still shows performance gains, the statistical strength is\nweaker compared to the U.S. case, potentially reflecting heavier tails and increased model\n21\n\n\n--- Page 22 ---\nuncertainty in the U.K. equity returns. For the Japan market, both tests produce highly significant results: LSTM-BEKK\noutperforms DCC and Scalar BEKK with mean NLL improvements of \u22120.422 and \u22120.383,\nrespectively, both with p < 0.01. These results reinforce the robustness of the proposed\nmodel across distinct market environments. Overall, the paired t-test analysis confirms that the LSTM-BEKK model\u2019s perfor-\nmance improvements are not only economically meaningful but also statistically signifi-\ncant across most comparisons. This provides strong evidence in favor of its generalization\ncapability and robustness in capturing return dynamics across diverse asset universes. Table 6: Paired t-test Results on Test NLL Differences Across 500 Portfolios. Comparison\nMean NLL Difference\nt-statistic\np-value\nU.S. Market\nLSTM-BEKK \u2212DCC\n-1.518\n-15.326\n<0.000***\nLSTM-BEKK \u2212Scalar BEKK\n-0.247\n-2.587\n0.009***\nU.K. Market\nLSTM-BEKK \u2212DCC\n-0.430\n-2.468\n0.014**\nLSTM-BEKK \u2212Scalar BEKK\n-0.259\n-1.676\n0.094*\nJapan Market\nLSTM-BEKK \u2212DCC\n-0.422\n-3.856\n<0.001***\nLSTM-BEKK \u2212Scalar BEKK\n-0.383\n-3.498\n0.001***\nNote: Negative values indicate LSTM-BEKK achieves lower NLL. Significance levels: *p < 0.1, **p <\n0.05, ***p < 0.01.",
  "This provides strong evidence in favor of its generalization\ncapability and robustness in capturing return dynamics across diverse asset universes. Table 6: Paired t-test Results on Test NLL Differences Across 500 Portfolios. Comparison\nMean NLL Difference\nt-statistic\np-value\nU.S. Market\nLSTM-BEKK \u2212DCC\n-1.518\n-15.326\n<0.000***\nLSTM-BEKK \u2212Scalar BEKK\n-0.247\n-2.587\n0.009***\nU.K. Market\nLSTM-BEKK \u2212DCC\n-0.430\n-2.468\n0.014**\nLSTM-BEKK \u2212Scalar BEKK\n-0.259\n-1.676\n0.094*\nJapan Market\nLSTM-BEKK \u2212DCC\n-0.422\n-3.856\n<0.001***\nLSTM-BEKK \u2212Scalar BEKK\n-0.383\n-3.498\n0.001***\nNote: Negative values indicate LSTM-BEKK achieves lower NLL. Significance levels: *p < 0.1, **p <\n0.05, ***p < 0.01. 4.4.4\nCross-Market Robustness Analysis\nThe previous analyses across the U.S., U.K., and Japan markets offer a compelling basis to\nevaluate the cross-market robustness of the LSTM-BEKK model. Although the magnitude\nof performance gains varies across markets, the model consistently demonstrates improved\nout-of-sample performance over both the DCC and Scalar BEKK models, as evidenced\nby lower average test NLL values across all 500 portfolio replications. In the U.S. market, where return distributions are relatively less heavy-tailed, the\nLSTM-BEKK model achieves the most pronounced gains, with statistically significant\nimprovements over both benchmarks. In contrast, the U.K. market presents greater mod-\neling challenges due to more extreme kurtosis and skewness, leading to comparatively\nsmaller and less statistically robust gains, particularly against Scalar BEKK. The Japan\nmarket offers a middle ground, where LSTM-BEKK again achieves consistent and statis-\ntically significant outperformance. 22\n\n\n--- Page 23 ---\nImportantly, these findings highlight the model\u2019s adaptability across heterogeneous\nfinancial environments. Despite differences in market structures, volatility regimes, and re-\nturn characteristics, the LSTM-BEKK model maintains its relative advantage in volatility\nforecasting. This cross-market consistency underscores its potential utility as a general-\npurpose volatility modeling framework for global asset allocation and risk management\napplications.",
  "In contrast, the U.K. market presents greater mod-\neling challenges due to more extreme kurtosis and skewness, leading to comparatively\nsmaller and less statistically robust gains, particularly against Scalar BEKK. The Japan\nmarket offers a middle ground, where LSTM-BEKK again achieves consistent and statis-\ntically significant outperformance. 22\n\n\n--- Page 23 ---\nImportantly, these findings highlight the model\u2019s adaptability across heterogeneous\nfinancial environments. Despite differences in market structures, volatility regimes, and re-\nturn characteristics, the LSTM-BEKK model maintains its relative advantage in volatility\nforecasting. This cross-market consistency underscores its potential utility as a general-\npurpose volatility modeling framework for global asset allocation and risk management\napplications. 4.5\nOut-of-Sample Evaluation on High-Dimensional Portfolios\nTo further evaluate the scalability and generalizability of the proposed LSTM-BEKK\nmodel, this section conducts an out-of-sample assessment on high-dimensional portfolios\nconstructed from the top 100, 175, and 250 equities by market capitalization in each of\nthe three markets: the United States, the United Kingdom, and Japan. These selections\nreflect increasingly complex asset universes and serve as representative high-dimensional\nsettings commonly encountered in institutional portfolio management. Unlike Section 4.4\nwhere repeated sampling of 50-asset portfolios was employed to evaluate robustness and\nconduct t-tests, to reduce computation in the high-dimensional setting, we opt to report\nthe results for a single representative portfolio at each dimensional level. By increasing the portfolio dimension, we aim to assess each model\u2019s ability to scale\nunder rising parameter complexity and intensified correlation structure. The following\nsubsections present a comparative analysis of test NLL values across different dimensional\ntiers and markets, followed by risk-aware backtesting (GMV portfolios) and formal model\nconfidence set (MCS) inference.",
  "4.5\nOut-of-Sample Evaluation on High-Dimensional Portfolios\nTo further evaluate the scalability and generalizability of the proposed LSTM-BEKK\nmodel, this section conducts an out-of-sample assessment on high-dimensional portfolios\nconstructed from the top 100, 175, and 250 equities by market capitalization in each of\nthe three markets: the United States, the United Kingdom, and Japan. These selections\nreflect increasingly complex asset universes and serve as representative high-dimensional\nsettings commonly encountered in institutional portfolio management. Unlike Section 4.4\nwhere repeated sampling of 50-asset portfolios was employed to evaluate robustness and\nconduct t-tests, to reduce computation in the high-dimensional setting, we opt to report\nthe results for a single representative portfolio at each dimensional level. By increasing the portfolio dimension, we aim to assess each model\u2019s ability to scale\nunder rising parameter complexity and intensified correlation structure. The following\nsubsections present a comparative analysis of test NLL values across different dimensional\ntiers and markets, followed by risk-aware backtesting (GMV portfolios) and formal model\nconfidence set (MCS) inference. 4.5.1\nEmpirical Results for the U.S. Market\nTable 7 reports the out-of-sample NLL values and corresponding parameter estimates for\nthe DCC, Scalar BEKK, and LSTM-BEKK models across high-dimensional U.S. equity\nportfolios with 100, 175, and 250 assets. The results show a clear and consistent advantage\nof the LSTM-BEKK model in terms of model fit. Across all three portfolio sizes, the LSTM-BEKK model achieves the lowest NLL\nvalues: 166.090 (100 assets), 285.557 (175 assets), and 417.614 (250 assets), outperforming\nboth Scalar BEKK and DCC. The margin of improvement becomes more pronounced as\nportfolio dimensionality increases. This trend underscores the ability of the LSTM-BEKK\nframework to scale effectively in high-dimensional. 23\n\n\n--- Page 24 ---\nTable 7: U.S.: Parameter Estimates and NLL for DCC, Scalar BEKK, and LSTM-BEKK\nModels.",
  "The results show a clear and consistent advantage\nof the LSTM-BEKK model in terms of model fit. Across all three portfolio sizes, the LSTM-BEKK model achieves the lowest NLL\nvalues: 166.090 (100 assets), 285.557 (175 assets), and 417.614 (250 assets), outperforming\nboth Scalar BEKK and DCC. The margin of improvement becomes more pronounced as\nportfolio dimensionality increases. This trend underscores the ability of the LSTM-BEKK\nframework to scale effectively in high-dimensional. 23\n\n\n--- Page 24 ---\nTable 7: U.S.: Parameter Estimates and NLL for DCC, Scalar BEKK, and LSTM-BEKK\nModels. Portfolio Size\nNLL\na\nb\n100\nDCC\n169.119\n0.019\n0.691\nScalar BEKK\n166.325\n0.011\n0.886\nLSTM-BEKK\n166.090\n0.005\n0.975\n175\nDCC\n291.569\n0.013\n0.700\nScalar BEKK\n288.875\n0.010\n0.891\nLSTM-BEKK\n285.557\n0.003\n0.980\n250\nDCC\n423.776\n0.010\n0.698\nScalar BEKK\n419.853\n0.002\n0.993\nLSTM-BEKK\n417.614\n0.007\n0.980\nThe parameter estimates provide insights into how each model captures volatility\ndynamics. The DCC model consistently yields the highest a values among the three\nmodels across all portfolio sizes, suggesting that it places greater weight on immediate\nreturn shocks when updating its correlation dynamics. However, its b values remain\nmoderate (around 0.69\u20130.70), reflecting limited persistence relative to the BEKK-type\nmodels. In contrast, the LSTM-BEKK model consistently achieves a desirable balance: it\nexhibits the lower a values (indicating lower sensitivity to noise) and the higher b values\n(reflecting strong volatility persistence), with values close to or exceeding those of Scalar\nBEKK. This highlights the role of the LSTM in capturing nonlinear dependencies and\nlong-memory behavior more effectively than its counterparts. Overall, the LSTM-BEKK model demonstrates strong generalization capabilities and\nscalability in high-dimensional settings, providing more stable and accurate volatility\nestimates than traditional econometric models.",
  "The DCC model consistently yields the highest a values among the three\nmodels across all portfolio sizes, suggesting that it places greater weight on immediate\nreturn shocks when updating its correlation dynamics. However, its b values remain\nmoderate (around 0.69\u20130.70), reflecting limited persistence relative to the BEKK-type\nmodels. In contrast, the LSTM-BEKK model consistently achieves a desirable balance: it\nexhibits the lower a values (indicating lower sensitivity to noise) and the higher b values\n(reflecting strong volatility persistence), with values close to or exceeding those of Scalar\nBEKK. This highlights the role of the LSTM in capturing nonlinear dependencies and\nlong-memory behavior more effectively than its counterparts. Overall, the LSTM-BEKK model demonstrates strong generalization capabilities and\nscalability in high-dimensional settings, providing more stable and accurate volatility\nestimates than traditional econometric models. 4.5.2\nEmpirical Results for the U.K. Market\nTable 8 presents the out-of-sample NLL values and estimated parameters for the DCC,\nScalar BEKK, and LSTM-BEKK models applied to high-dimensional U.K. equity portfo-\nlios. As in the U.S. market, the LSTM-BEKK model consistently attains the lowest NLL\nvalues across all three portfolio sizes\u2014182.545 (100 assets), 324.577 (175 assets), and\n467.977 (250 assets)\u2014demonstrating its strong generalization capacity and adaptability\nto a different market environment. 24\n\n\n--- Page 25 ---\nTable 8: U.K.: Parameter Estimates and NLL for DCC, Scalar BEKK, and LSTM-BEKK\nModels. Portfolio Size\nNLL\na\nb\n100\nDCC\n184.649\n0.013\n0.669\nScalar BEKK\n183.450\n0.008\n0.932\nLSTM-BEKK\n182.545\n0.008\n0.948\n175\nDCC\n328.327\n0.007\n0.690\nScalar BEKK\n326.875\n0.009\n0.890\nLSTM-BEKK\n324.577\n0.003\n0.984\n250\nDCC\n472.528\n0.007\n0.697\nScalar BEKK\n471.964\n0.004\n0.952\nLSTM-BEKK\n467.977\n0.006\n0.942\nThe parameter patterns echo those observed in the U.S. market, with LSTM-BEKK\nmaintaining relatively low a values and consistently high b values across all dimensions.",
  "This highlights the role of the LSTM in capturing nonlinear dependencies and\nlong-memory behavior more effectively than its counterparts. Overall, the LSTM-BEKK model demonstrates strong generalization capabilities and\nscalability in high-dimensional settings, providing more stable and accurate volatility\nestimates than traditional econometric models. 4.5.2\nEmpirical Results for the U.K. Market\nTable 8 presents the out-of-sample NLL values and estimated parameters for the DCC,\nScalar BEKK, and LSTM-BEKK models applied to high-dimensional U.K. equity portfo-\nlios. As in the U.S. market, the LSTM-BEKK model consistently attains the lowest NLL\nvalues across all three portfolio sizes\u2014182.545 (100 assets), 324.577 (175 assets), and\n467.977 (250 assets)\u2014demonstrating its strong generalization capacity and adaptability\nto a different market environment. 24\n\n\n--- Page 25 ---\nTable 8: U.K.: Parameter Estimates and NLL for DCC, Scalar BEKK, and LSTM-BEKK\nModels. Portfolio Size\nNLL\na\nb\n100\nDCC\n184.649\n0.013\n0.669\nScalar BEKK\n183.450\n0.008\n0.932\nLSTM-BEKK\n182.545\n0.008\n0.948\n175\nDCC\n328.327\n0.007\n0.690\nScalar BEKK\n326.875\n0.009\n0.890\nLSTM-BEKK\n324.577\n0.003\n0.984\n250\nDCC\n472.528\n0.007\n0.697\nScalar BEKK\n471.964\n0.004\n0.952\nLSTM-BEKK\n467.977\n0.006\n0.942\nThe parameter patterns echo those observed in the U.S. market, with LSTM-BEKK\nmaintaining relatively low a values and consistently high b values across all dimensions. These estimates reflect the model\u2019s capacity to capture persistent volatility clustering. Unlike the U.S. market, however, the U.K. equity return distribution exhibits heavier\ntails and higher kurtosis, increasing the likelihood of extreme return events. This feature\nposes significant challenges to conventional models such as DCC and Scalar BEKK, which\nare grounded in conditional normality assumptions. The LSTM-BEKK model, benefiting\nfrom its deep learning structure and Swish activation dynamics, offers additional flex-\nibility to accommodate these non-Gaussian features, as evidenced by its superior NLL\nperformance.",
  "Portfolio Size\nNLL\na\nb\n100\nDCC\n184.649\n0.013\n0.669\nScalar BEKK\n183.450\n0.008\n0.932\nLSTM-BEKK\n182.545\n0.008\n0.948\n175\nDCC\n328.327\n0.007\n0.690\nScalar BEKK\n326.875\n0.009\n0.890\nLSTM-BEKK\n324.577\n0.003\n0.984\n250\nDCC\n472.528\n0.007\n0.697\nScalar BEKK\n471.964\n0.004\n0.952\nLSTM-BEKK\n467.977\n0.006\n0.942\nThe parameter patterns echo those observed in the U.S. market, with LSTM-BEKK\nmaintaining relatively low a values and consistently high b values across all dimensions. These estimates reflect the model\u2019s capacity to capture persistent volatility clustering. Unlike the U.S. market, however, the U.K. equity return distribution exhibits heavier\ntails and higher kurtosis, increasing the likelihood of extreme return events. This feature\nposes significant challenges to conventional models such as DCC and Scalar BEKK, which\nare grounded in conditional normality assumptions. The LSTM-BEKK model, benefiting\nfrom its deep learning structure and Swish activation dynamics, offers additional flex-\nibility to accommodate these non-Gaussian features, as evidenced by its superior NLL\nperformance. Interestingly, the gap between Scalar BEKK and LSTM-BEKK narrows in this mar-\nket, particularly at 250 dimensions. This reflects the relatively strong performance of\nScalar BEKK in moderately heavy-tailed environments, though the LSTM-BEKK model\nstill prevails overall. These results reaffirm the robustness of LSTM-BEKK across both\nmarket regimes and portfolio complexities. 4.5.3\nEmpirical Results for the Japan Market\nTable 9 presents the parameter estimates and NLL values for the Japan equity market. In line with the results observed in the U.S. and U.K. markets, the LSTM-BEKK model\nconsistently achieves the lowest NLL values across all portfolio sizes. Specifically, for 100,\n175, and 250-asset portfolios, the LSTM-BEKK records NLLs of 162.731, 285.631, and\n417.788, respectively\u2014outperforming both DCC and Scalar BEKK models. 25\n\n\n--- Page 26 ---\nTable 9: Japan: Parameter Estimates and NLL for DCC, Scalar BEKK, and LSTM-\nBEKK Models.",
  "These results reaffirm the robustness of LSTM-BEKK across both\nmarket regimes and portfolio complexities. 4.5.3\nEmpirical Results for the Japan Market\nTable 9 presents the parameter estimates and NLL values for the Japan equity market. In line with the results observed in the U.S. and U.K. markets, the LSTM-BEKK model\nconsistently achieves the lowest NLL values across all portfolio sizes. Specifically, for 100,\n175, and 250-asset portfolios, the LSTM-BEKK records NLLs of 162.731, 285.631, and\n417.788, respectively\u2014outperforming both DCC and Scalar BEKK models. 25\n\n\n--- Page 26 ---\nTable 9: Japan: Parameter Estimates and NLL for DCC, Scalar BEKK, and LSTM-\nBEKK Models. Portfolio Size\nNLL\na\nb\n100\nDCC\n164.067\n0.009\n0.697\nScalar BEKK\n163.322\n0.007\n0.931\nLSTM-BEKK\n162.731\n0.002\n0.998\n175\nDCC\n289.456\n0.005\n0.696\nScalar BEKK\n289.320\n0.006\n0.945\nLSTM-BEKK\n285.631\n0.002\n0.993\n250\nDCC\n423.885\n0.004\n0.698\nScalar BEKK\n421.414\n0.003\n0.971\nLSTM-BEKK\n417.788\n0.002\n0.997\nThe Japan market is characterized by moderate volatility persistence and relatively\nlower short-term shock sensitivity compared to the U.K. and U.S. markets. Across all\nportfolio sizes, although the DCC model exhibits the hightest a values, it maintains the\nleast persistence in volatility, with b values around 0.69. The Scalar BEKK model improves\nupon this by increasing both a and b, reflecting a stronger response to market conditions. However, the LSTM-BEKK model achieves the best balance: it maintains the lowest\na values\u2014indicating robustness to short-term noise\u2014while consistently exhibiting the\nhighest b values, approaching unity. This suggests that LSTM-BEKK excels at capturing\nlong-range dependencies and volatility clustering. Overall, the results reaffirm the LSTM-BEKK model\u2019s superior adaptability and mod-\neling capacity, even in markets with more muted short-term volatility shocks but persistent\nstructural dynamics.",
  "Across all\nportfolio sizes, although the DCC model exhibits the hightest a values, it maintains the\nleast persistence in volatility, with b values around 0.69. The Scalar BEKK model improves\nupon this by increasing both a and b, reflecting a stronger response to market conditions. However, the LSTM-BEKK model achieves the best balance: it maintains the lowest\na values\u2014indicating robustness to short-term noise\u2014while consistently exhibiting the\nhighest b values, approaching unity. This suggests that LSTM-BEKK excels at capturing\nlong-range dependencies and volatility clustering. Overall, the results reaffirm the LSTM-BEKK model\u2019s superior adaptability and mod-\neling capacity, even in markets with more muted short-term volatility shocks but persistent\nstructural dynamics. 4.5.4\nModel Confidence Set Analysis\nTo evaluate the statistical significance of the observed model performance differences\nacross markets and portfolio sizes, we employ the Model Confidence Set (MCS) procedure\nproposed by Hansen et al. (2011). The MCS framework identifies a set of superior models\n(SSM) from a pool of competing models based on their predictive performance, while\naccounting for sampling uncertainty. Let M denote the set of all candidate models. For each model i \u2208M, we define the\nloss function Li,t (in our case, the test negative log-likelihood, NLL) at time t. The loss\ndifferential between models i and j is defined as:\ndi,j,t = Li,t \u2212Lj,t. (17)\n26\n\n\n--- Page 27 ---\nThe null hypothesis of equal predictive ability across all models is:\nH0 : \u00b5i,j = E[di,j,t] = 0,\n\u2200i, j \u2208M. (18)\nThe MCS procedure performs a sequence of hypothesis tests to iteratively eliminate\nthe worst-performing model until the null hypothesis of equal predictive accuracy can no\nlonger be rejected. At a chosen confidence level (90% in this paper), the surviving models\nconstitute the SSM.",
  "For each model i \u2208M, we define the\nloss function Li,t (in our case, the test negative log-likelihood, NLL) at time t. The loss\ndifferential between models i and j is defined as:\ndi,j,t = Li,t \u2212Lj,t. (17)\n26\n\n\n--- Page 27 ---\nThe null hypothesis of equal predictive ability across all models is:\nH0 : \u00b5i,j = E[di,j,t] = 0,\n\u2200i, j \u2208M. (18)\nThe MCS procedure performs a sequence of hypothesis tests to iteratively eliminate\nthe worst-performing model until the null hypothesis of equal predictive accuracy can no\nlonger be rejected. At a chosen confidence level (90% in this paper), the surviving models\nconstitute the SSM. Each model is associated with a p-value indicating the probability\nthat it belongs to the set of superior models. Lower p-values reflect weaker statistical\nsupport. Table 10 reports the p-values and inclusion indicators of each model across all combi-\nnations of market (U.S., U.K., and Japan) and portfolio dimensions (N = 100, 175, 250). A model is included in the 90% MCS if its p-value exceeds 0.10. The results reveal that the LSTM-BEKK model is consistently included in the MCS\nacross all nine experimental settings, with a p-value of 1.000 in every case. This strongly\nsupports its status as the most robust and statistically superior model. In contrast, the\nDCC and Scalar BEKK models are excluded in the majority of settings due to low p-\nvalues. Notably, DCC is only retained once (U.K., N = 250), and Scalar BEKK is never\nretained, highlighting its instability under the MCS test. These findings validate the empirical advantage of the LSTM-BEKK model not only\nin terms of raw performance (e.g., lower NLL) but also under formal statistical scrutiny.",
  "This strongly\nsupports its status as the most robust and statistically superior model. In contrast, the\nDCC and Scalar BEKK models are excluded in the majority of settings due to low p-\nvalues. Notably, DCC is only retained once (U.K., N = 250), and Scalar BEKK is never\nretained, highlighting its instability under the MCS test. These findings validate the empirical advantage of the LSTM-BEKK model not only\nin terms of raw performance (e.g., lower NLL) but also under formal statistical scrutiny. The consistent MCS inclusion underscores the reliability and generalizability of its su-\nperior forecasting performance across high-dimensional and heterogeneous financial envi-\nronments. 27\n\n\n--- Page 28 ---\nTable 10: Model Confidence Set (MCS) Inclusion Based on Test NLL p-values. Market\nPortfolio Size\nModel\np-value\nMCS (90%)\nU.S.\nDCC\n0.031\n\u2717\n100\nScalar BEKK\n0.031\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nU.S.\nDCC\n0.000\n\u2717\n175\nScalar BEKK\n0.000\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nU.S.\nDCC\n0.019\n\u2717\n250\nScalar BEKK\n0.030\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nU.K.\nDCC\n0.032\n\u2717\n100\nScalar BEKK\n0.032\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nU.K.\nDCC\n0.000\n\u2717\n175\nScalar BEKK\n0.000\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nU.K.\nDCC\n0.184\n\u2713\n250\nScalar BEKK\n0.001\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nJapan\nDCC\n0.095\n\u2717\n100\nScalar BEKK\n0.095\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nJapan\nDCC\n0.098\n\u2717\n175\nScalar BEKK\n0.000\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nJapan\nDCC\n0.005\n\u2717\n250\nScalar BEKK\n0.005\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nNote: Models with p-value > 0.10 are retained in the 90% Model Confidence Set (MCS). \u2713denotes inclusion, \u2717denotes exclusion. 4.5.5\nSummary of High-Dimensional Evaluation\nThe high-dimensional out-of-sample evaluation across the U.S., U.K., and Japan markets\nprovides strong evidence of the robustness and adaptability of the LSTM-BEKK model\nin modeling complex volatility structures.",
  "These findings validate the empirical advantage of the LSTM-BEKK model not only\nin terms of raw performance (e.g., lower NLL) but also under formal statistical scrutiny. The consistent MCS inclusion underscores the reliability and generalizability of its su-\nperior forecasting performance across high-dimensional and heterogeneous financial envi-\nronments. 27\n\n\n--- Page 28 ---\nTable 10: Model Confidence Set (MCS) Inclusion Based on Test NLL p-values. Market\nPortfolio Size\nModel\np-value\nMCS (90%)\nU.S.\nDCC\n0.031\n\u2717\n100\nScalar BEKK\n0.031\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nU.S.\nDCC\n0.000\n\u2717\n175\nScalar BEKK\n0.000\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nU.S.\nDCC\n0.019\n\u2717\n250\nScalar BEKK\n0.030\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nU.K.\nDCC\n0.032\n\u2717\n100\nScalar BEKK\n0.032\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nU.K.\nDCC\n0.000\n\u2717\n175\nScalar BEKK\n0.000\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nU.K.\nDCC\n0.184\n\u2713\n250\nScalar BEKK\n0.001\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nJapan\nDCC\n0.095\n\u2717\n100\nScalar BEKK\n0.095\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nJapan\nDCC\n0.098\n\u2717\n175\nScalar BEKK\n0.000\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nJapan\nDCC\n0.005\n\u2717\n250\nScalar BEKK\n0.005\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nNote: Models with p-value > 0.10 are retained in the 90% Model Confidence Set (MCS). \u2713denotes inclusion, \u2717denotes exclusion. 4.5.5\nSummary of High-Dimensional Evaluation\nThe high-dimensional out-of-sample evaluation across the U.S., U.K., and Japan markets\nprovides strong evidence of the robustness and adaptability of the LSTM-BEKK model\nin modeling complex volatility structures. Across all three markets and all portfolio sizes\n(N = 100, 175, 250), the LSTM-BEKK model consistently achieves the lowest or near-\n28\n\n\n--- Page 29 ---\nlowest NLL values, demonstrating superior predictive performance relative to the DCC\nand Scalar BEKK models. This advantage becomes increasingly pronounced as portfolio dimensionality in-\ncreases.",
  "The consistent MCS inclusion underscores the reliability and generalizability of its su-\nperior forecasting performance across high-dimensional and heterogeneous financial envi-\nronments. 27\n\n\n--- Page 28 ---\nTable 10: Model Confidence Set (MCS) Inclusion Based on Test NLL p-values. Market\nPortfolio Size\nModel\np-value\nMCS (90%)\nU.S.\nDCC\n0.031\n\u2717\n100\nScalar BEKK\n0.031\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nU.S.\nDCC\n0.000\n\u2717\n175\nScalar BEKK\n0.000\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nU.S.\nDCC\n0.019\n\u2717\n250\nScalar BEKK\n0.030\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nU.K.\nDCC\n0.032\n\u2717\n100\nScalar BEKK\n0.032\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nU.K.\nDCC\n0.000\n\u2717\n175\nScalar BEKK\n0.000\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nU.K.\nDCC\n0.184\n\u2713\n250\nScalar BEKK\n0.001\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nJapan\nDCC\n0.095\n\u2717\n100\nScalar BEKK\n0.095\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nJapan\nDCC\n0.098\n\u2717\n175\nScalar BEKK\n0.000\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nJapan\nDCC\n0.005\n\u2717\n250\nScalar BEKK\n0.005\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nNote: Models with p-value > 0.10 are retained in the 90% Model Confidence Set (MCS). \u2713denotes inclusion, \u2717denotes exclusion. 4.5.5\nSummary of High-Dimensional Evaluation\nThe high-dimensional out-of-sample evaluation across the U.S., U.K., and Japan markets\nprovides strong evidence of the robustness and adaptability of the LSTM-BEKK model\nin modeling complex volatility structures. Across all three markets and all portfolio sizes\n(N = 100, 175, 250), the LSTM-BEKK model consistently achieves the lowest or near-\n28\n\n\n--- Page 29 ---\nlowest NLL values, demonstrating superior predictive performance relative to the DCC\nand Scalar BEKK models. This advantage becomes increasingly pronounced as portfolio dimensionality in-\ncreases. In particular, the gap between LSTM-BEKK and the traditional models widens\nin the 175- and 250-asset portfolios, indicating that the deep learning-based architecture\nis particularly well-suited to capturing the nonlinearities and higher-order dependencies\npresent in large asset spaces.",
  "27\n\n\n--- Page 28 ---\nTable 10: Model Confidence Set (MCS) Inclusion Based on Test NLL p-values. Market\nPortfolio Size\nModel\np-value\nMCS (90%)\nU.S.\nDCC\n0.031\n\u2717\n100\nScalar BEKK\n0.031\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nU.S.\nDCC\n0.000\n\u2717\n175\nScalar BEKK\n0.000\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nU.S.\nDCC\n0.019\n\u2717\n250\nScalar BEKK\n0.030\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nU.K.\nDCC\n0.032\n\u2717\n100\nScalar BEKK\n0.032\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nU.K.\nDCC\n0.000\n\u2717\n175\nScalar BEKK\n0.000\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nU.K.\nDCC\n0.184\n\u2713\n250\nScalar BEKK\n0.001\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nJapan\nDCC\n0.095\n\u2717\n100\nScalar BEKK\n0.095\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nJapan\nDCC\n0.098\n\u2717\n175\nScalar BEKK\n0.000\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nJapan\nDCC\n0.005\n\u2717\n250\nScalar BEKK\n0.005\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nNote: Models with p-value > 0.10 are retained in the 90% Model Confidence Set (MCS). \u2713denotes inclusion, \u2717denotes exclusion. 4.5.5\nSummary of High-Dimensional Evaluation\nThe high-dimensional out-of-sample evaluation across the U.S., U.K., and Japan markets\nprovides strong evidence of the robustness and adaptability of the LSTM-BEKK model\nin modeling complex volatility structures. Across all three markets and all portfolio sizes\n(N = 100, 175, 250), the LSTM-BEKK model consistently achieves the lowest or near-\n28\n\n\n--- Page 29 ---\nlowest NLL values, demonstrating superior predictive performance relative to the DCC\nand Scalar BEKK models. This advantage becomes increasingly pronounced as portfolio dimensionality in-\ncreases. In particular, the gap between LSTM-BEKK and the traditional models widens\nin the 175- and 250-asset portfolios, indicating that the deep learning-based architecture\nis particularly well-suited to capturing the nonlinearities and higher-order dependencies\npresent in large asset spaces. Complementing the NLL results, the Model Confidence Set analysis further reinforces\nthe statistical significance of these findings.",
  "Market\nPortfolio Size\nModel\np-value\nMCS (90%)\nU.S.\nDCC\n0.031\n\u2717\n100\nScalar BEKK\n0.031\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nU.S.\nDCC\n0.000\n\u2717\n175\nScalar BEKK\n0.000\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nU.S.\nDCC\n0.019\n\u2717\n250\nScalar BEKK\n0.030\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nU.K.\nDCC\n0.032\n\u2717\n100\nScalar BEKK\n0.032\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nU.K.\nDCC\n0.000\n\u2717\n175\nScalar BEKK\n0.000\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nU.K.\nDCC\n0.184\n\u2713\n250\nScalar BEKK\n0.001\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nJapan\nDCC\n0.095\n\u2717\n100\nScalar BEKK\n0.095\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nJapan\nDCC\n0.098\n\u2717\n175\nScalar BEKK\n0.000\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nJapan\nDCC\n0.005\n\u2717\n250\nScalar BEKK\n0.005\n\u2717\nLSTM-BEKK\n1.000\n\u2713\nNote: Models with p-value > 0.10 are retained in the 90% Model Confidence Set (MCS). \u2713denotes inclusion, \u2717denotes exclusion. 4.5.5\nSummary of High-Dimensional Evaluation\nThe high-dimensional out-of-sample evaluation across the U.S., U.K., and Japan markets\nprovides strong evidence of the robustness and adaptability of the LSTM-BEKK model\nin modeling complex volatility structures. Across all three markets and all portfolio sizes\n(N = 100, 175, 250), the LSTM-BEKK model consistently achieves the lowest or near-\n28\n\n\n--- Page 29 ---\nlowest NLL values, demonstrating superior predictive performance relative to the DCC\nand Scalar BEKK models. This advantage becomes increasingly pronounced as portfolio dimensionality in-\ncreases. In particular, the gap between LSTM-BEKK and the traditional models widens\nin the 175- and 250-asset portfolios, indicating that the deep learning-based architecture\nis particularly well-suited to capturing the nonlinearities and higher-order dependencies\npresent in large asset spaces. Complementing the NLL results, the Model Confidence Set analysis further reinforces\nthe statistical significance of these findings. At the 90% confidence level, LSTM-BEKK\nis retained in the MCS in all nine experimental configurations, with p-values equal to 1\nthroughout.",
  "\u2713denotes inclusion, \u2717denotes exclusion. 4.5.5\nSummary of High-Dimensional Evaluation\nThe high-dimensional out-of-sample evaluation across the U.S., U.K., and Japan markets\nprovides strong evidence of the robustness and adaptability of the LSTM-BEKK model\nin modeling complex volatility structures. Across all three markets and all portfolio sizes\n(N = 100, 175, 250), the LSTM-BEKK model consistently achieves the lowest or near-\n28\n\n\n--- Page 29 ---\nlowest NLL values, demonstrating superior predictive performance relative to the DCC\nand Scalar BEKK models. This advantage becomes increasingly pronounced as portfolio dimensionality in-\ncreases. In particular, the gap between LSTM-BEKK and the traditional models widens\nin the 175- and 250-asset portfolios, indicating that the deep learning-based architecture\nis particularly well-suited to capturing the nonlinearities and higher-order dependencies\npresent in large asset spaces. Complementing the NLL results, the Model Confidence Set analysis further reinforces\nthe statistical significance of these findings. At the 90% confidence level, LSTM-BEKK\nis retained in the MCS in all nine experimental configurations, with p-values equal to 1\nthroughout. In contrast, Scalar BEKK and DCC are frequently excluded from the MCS,\nhighlighting their relative instability and inferior forecasting accuracy. This result affirms\nthat the performance gains achieved by LSTM-BEKK are not attributable to chance, but\nreflect meaningful improvements in modeling efficacy. In summary, the empirical and statistical evidence confirm that LSTM-BEKK gener-\nalizes well across markets and scales effectively with portfolio dimensionality. These prop-\nerties make it a compelling alternative to conventional MGARCH models, especially in\nmodern financial applications requiring accurate, stable, and scalable multivariate volatil-\nity estimation. 5\nGlobal Minimum Variance Portfolio\n5.1\nTheoretical Background\nThe Global Minimum Variance (GMV) portfolio aims to construct a portfolio that mini-\nmizes the overall risk, as measured by the portfolio variance, without considering expected\nreturns.",
  "In contrast, Scalar BEKK and DCC are frequently excluded from the MCS,\nhighlighting their relative instability and inferior forecasting accuracy. This result affirms\nthat the performance gains achieved by LSTM-BEKK are not attributable to chance, but\nreflect meaningful improvements in modeling efficacy. In summary, the empirical and statistical evidence confirm that LSTM-BEKK gener-\nalizes well across markets and scales effectively with portfolio dimensionality. These prop-\nerties make it a compelling alternative to conventional MGARCH models, especially in\nmodern financial applications requiring accurate, stable, and scalable multivariate volatil-\nity estimation. 5\nGlobal Minimum Variance Portfolio\n5.1\nTheoretical Background\nThe Global Minimum Variance (GMV) portfolio aims to construct a portfolio that mini-\nmizes the overall risk, as measured by the portfolio variance, without considering expected\nreturns. This approach is particularly relevant in volatile financial markets, where accu-\nrate estimation of expected returns can be challenging. The GMV portfolio is defined as\nthe solution to the following optimization problem:\nmin\nw w\u2032Htw,\nsubject to\nw\u20321 = 1,\n(19)\nwhere w is the vector of portfolio weights, Ht is the conditional covariance matrix of asset\nreturns at time t, and 1 is a vector of ones ensuring that the portfolio is fully invested. The optimal weights for the GMV portfolio can be derived as:\nwGMV\nt\n= H\u22121\nt 1\n1\u2032H\u22121\nt 1. (20)\nHere, the inverse of the covariance matrix H\u22121\nt\nplays a critical role in determining the\nportfolio weights. Accurate estimation of Ht is therefore essential for constructing the\n29\n\n\n--- Page 30 ---\nGMV portfolio. In this section, we evaluate the performance of the proposed LSTM-\nBEKK model by examining its resulting GMV portfolio.",
  "The GMV portfolio is defined as\nthe solution to the following optimization problem:\nmin\nw w\u2032Htw,\nsubject to\nw\u20321 = 1,\n(19)\nwhere w is the vector of portfolio weights, Ht is the conditional covariance matrix of asset\nreturns at time t, and 1 is a vector of ones ensuring that the portfolio is fully invested. The optimal weights for the GMV portfolio can be derived as:\nwGMV\nt\n= H\u22121\nt 1\n1\u2032H\u22121\nt 1. (20)\nHere, the inverse of the covariance matrix H\u22121\nt\nplays a critical role in determining the\nportfolio weights. Accurate estimation of Ht is therefore essential for constructing the\n29\n\n\n--- Page 30 ---\nGMV portfolio. In this section, we evaluate the performance of the proposed LSTM-\nBEKK model by examining its resulting GMV portfolio. 5.2\nPerformance Measures\nTo evaluate the performance of the GMV portfolios constructed using the three models\n(DCC, Scalar BEKK, and LSTM-BEKK), we use the following performance measures. Annualized Return (AR). The annualized return is calculated as:\nAR = \u00afr \u00d7 252,\n(21)\nwhere \u00afr represents the mean portfolio return of out-of-sample returns. Annualized Volatility (AV). The annualized volatility is given by:\nAV =\nv\nu\nu\nt\n1\nT \u22121\nT\nX\nt=1\n(rt \u2212\u00afr)2 \u00d7\n\u221a\n252,\n(22)\nMaximum Drawdown (MDD). The maximum drawdown measures the largest de-\ncline in the portfolio value from a peak to a trough:\nMDD = min\nt\u2208[0,T]\n\u0012Vt \u2212maxs\u2208[0,t] Vs\nmaxs\u2208[0,t] Vs\n\u0013\n,\n(23)\nwhere Vt is the portfolio value at time t.\nHigher values of AR are preferred as they indicate stronger portfolio growth, whereas\nlower AV and MDD values are desirable as they correspond to reduced risk exposure and\nenhanced drawdown resilience.",
  "Annualized Return (AR). The annualized return is calculated as:\nAR = \u00afr \u00d7 252,\n(21)\nwhere \u00afr represents the mean portfolio return of out-of-sample returns. Annualized Volatility (AV). The annualized volatility is given by:\nAV =\nv\nu\nu\nt\n1\nT \u22121\nT\nX\nt=1\n(rt \u2212\u00afr)2 \u00d7\n\u221a\n252,\n(22)\nMaximum Drawdown (MDD). The maximum drawdown measures the largest de-\ncline in the portfolio value from a peak to a trough:\nMDD = min\nt\u2208[0,T]\n\u0012Vt \u2212maxs\u2208[0,t] Vs\nmaxs\u2208[0,t] Vs\n\u0013\n,\n(23)\nwhere Vt is the portfolio value at time t.\nHigher values of AR are preferred as they indicate stronger portfolio growth, whereas\nlower AV and MDD values are desirable as they correspond to reduced risk exposure and\nenhanced drawdown resilience. In the Appendix, we further assess the performance of GMV portfolios, constructed\nbased on DCC, Scalar BEKK, and LSTM-BEKK, using the commonly used financial tail\nrisk measures Value-at-Risk and Expected Shortfall. 5.3\nPerformance Analysis of GMV Portfolios\nBuilding upon the high-dimensional evaluation in Section 4.5, we further assess model\nperformance from a portfolio construction perspective. Specifically, we examine the ef-\nfectiveness of the LSTM-BEKK model in generating GMV portfolios across three major\n30\n\n\n--- Page 31 ---\nfinancial markets: U.S., U.K., and Japan. For each market, we utilize the covariance ma-\ntrices estimated from the top 100, 175, and 250 market-capitalization equities to simulate\nhigh-dimensional portfolio settings. The equally weighted (EW) portfolio is used as a baseline due to its simplicity and\nstrong empirical performance. As discussed in DeMiguel et al. (2009), the 1/N alloca-\ntion strategy avoids estimation errors inherent in parametric optimization methods, thus\nproviding stable out-of-sample results. However, EW does not explicitly minimize risk,\nmaking it suboptimal for volatility-sensitive investors.",
  "The equally weighted (EW) portfolio is used as a baseline due to its simplicity and\nstrong empirical performance. As discussed in DeMiguel et al. (2009), the 1/N alloca-\ntion strategy avoids estimation errors inherent in parametric optimization methods, thus\nproviding stable out-of-sample results. However, EW does not explicitly minimize risk,\nmaking it suboptimal for volatility-sensitive investors. In contrast, GMV portfolios explicitly seek to minimize portfolio variance subject\nto budget constraints. Their effectiveness hinges critically on the quality of the input\ncovariance matrix. We therefore evaluate how each model\u2014DCC, Scalar BEKK, and\nLSTM-BEKK\u2014impacts GMV performance across three dimensions: AR, AV, and MDD. The AR is included for completeness but not emphasized, given its dependence on returns\nrather than risk control. To ensure robustness, all backtests are conducted using only out-of-sample data, i.e. test set. This mirrors real-world usage, where covariance estimates are based only on\nhistorical information and applied to future decisions. 5.3.1\nU.S. Market Analysis\nTable 11 presents the performance of GMV portfolios in the U.S. equity market based\non the top 100, 175, and 250 stocks by market capitalization. The EW portfolio delivers\nthe highest AR, particularly at N = 100 with 0.124, which supports its role as a strong\nbenchmark. However, its AV consistently exceeds that of all optimized GMV portfolios,\nindicating limited effectiveness in risk control. Among the GMV strategies, the LSTM-BEKK model demonstrates a clear advantage\nin minimizing volatility. It achieves the lowest AV across all portfolio sizes: 0.114 at\nN = 100, 0.112 at N = 175, and 0.111 at N = 250. These values are consistently lower\nthan those produced by both the DCC and Scalar BEKK models, underscoring LSTM-\nBEKK\u2019s robustness in modeling high-dimensional risk structures.",
  "Among the GMV strategies, the LSTM-BEKK model demonstrates a clear advantage\nin minimizing volatility. It achieves the lowest AV across all portfolio sizes: 0.114 at\nN = 100, 0.112 at N = 175, and 0.111 at N = 250. These values are consistently lower\nthan those produced by both the DCC and Scalar BEKK models, underscoring LSTM-\nBEKK\u2019s robustness in modeling high-dimensional risk structures. Notably, as portfolio\ndimensionality increases, the performance gap in AV widens in favor of LSTM-BEKK,\nhighlighting its scalability. A similar pattern emerges in maximum drawdown (MDD) performance. The LSTM-\nBEKK model consistently reduces downside exposure across most portfolio sizes, with\ntotal MDD values of \u22120.154, \u22120.104, and \u22120.161 for N = 100, 175, and 250, respectively. Compared to DCC (e.g., MDD as high as \u22120.260 at N = 250) and Scalar BEKK (e.g.,\n\u22120.194 at N = 250), LSTM-BEKK exhibits substantially greater resilience during market\ndownturns. It should be noted that at N = 100, the LSTM-BEKK model records an MDD\n31\n\n\n--- Page 32 ---\nof \u22120.154, which is marginally higher than the EW portfolio\u2019s \u22120.125. However, this\nisolated instance does not undermine the broader trend: LSTM-BEKK demonstrates\nstronger drawdown protection in larger portfolio configurations (N = 175 and N = 250),\nwhere controlling downside risk becomes increasingly challenging. This reinforces its\nutility in real-world portfolio management, particularly in high-dimensional settings where\ntraditional methods tend to deteriorate. Overall, these empirical results provide strong evidence that the LSTM-BEKK model\noffers superior risk-adjusted performance in high-dimensional GMV portfolio construction. Its consistent outperformance in both AV and MDD metrics suggests that integrating deep\nlearning structures into volatility modeling leads to more stable, resilient, and defensible\nportfolios under real-world market conditions.",
  "It should be noted that at N = 100, the LSTM-BEKK model records an MDD\n31\n\n\n--- Page 32 ---\nof \u22120.154, which is marginally higher than the EW portfolio\u2019s \u22120.125. However, this\nisolated instance does not undermine the broader trend: LSTM-BEKK demonstrates\nstronger drawdown protection in larger portfolio configurations (N = 175 and N = 250),\nwhere controlling downside risk becomes increasingly challenging. This reinforces its\nutility in real-world portfolio management, particularly in high-dimensional settings where\ntraditional methods tend to deteriorate. Overall, these empirical results provide strong evidence that the LSTM-BEKK model\noffers superior risk-adjusted performance in high-dimensional GMV portfolio construction. Its consistent outperformance in both AV and MDD metrics suggests that integrating deep\nlearning structures into volatility modeling leads to more stable, resilient, and defensible\nportfolios under real-world market conditions. Table 11: U.S.: Performance Comparison of GMV Portfolios: Return, Risk, and Draw-\ndown\nEW\nDCC\nScalar BEKK\nLSTM BEKK\nN=100\nAR\n0.124\n-0.057\n-0.084\n-0.052\nAV\n0.152\n0.131\n0.118\n0.114\nMDD\n-0.125\n-0.186\n-0.166\n-0.154\nN=175\nAR\n0.086\n-0.040\n-0.008\n-0.015\nAV\n0.168\n0.131\n0.120\n0.112\nMDD\n-0.171\n-0.158\n-0.124\n-0.104\nN=250\nAR\n-0.032\n-0.125\n-0.027\n-0.002\nAV\n0.185\n0.136\n0.115\n0.111\nMDD\n-0.244\n-0.260\n-0.194\n-0.161\nNote: Bold values represent the lowest AV and MDD for each portfolio size. 5.3.2\nU.K. Market Analysis\nTable 12 summarizes the performance of GMV portfolios in the U.K. equity market based\non the top 100, 175, and 250 stocks. The EW portfolio continues to exhibit the highest\nAR across all portfolio sizes; however, this is again accompanied by higher AV, reaffirming\nits limitations as a risk-agnostic strategy. Among the GMV portfolios, the LSTM-BEKK model demonstrates clear superiority\nin volatility minimization.",
  "Overall, these empirical results provide strong evidence that the LSTM-BEKK model\noffers superior risk-adjusted performance in high-dimensional GMV portfolio construction. Its consistent outperformance in both AV and MDD metrics suggests that integrating deep\nlearning structures into volatility modeling leads to more stable, resilient, and defensible\nportfolios under real-world market conditions. Table 11: U.S.: Performance Comparison of GMV Portfolios: Return, Risk, and Draw-\ndown\nEW\nDCC\nScalar BEKK\nLSTM BEKK\nN=100\nAR\n0.124\n-0.057\n-0.084\n-0.052\nAV\n0.152\n0.131\n0.118\n0.114\nMDD\n-0.125\n-0.186\n-0.166\n-0.154\nN=175\nAR\n0.086\n-0.040\n-0.008\n-0.015\nAV\n0.168\n0.131\n0.120\n0.112\nMDD\n-0.171\n-0.158\n-0.124\n-0.104\nN=250\nAR\n-0.032\n-0.125\n-0.027\n-0.002\nAV\n0.185\n0.136\n0.115\n0.111\nMDD\n-0.244\n-0.260\n-0.194\n-0.161\nNote: Bold values represent the lowest AV and MDD for each portfolio size. 5.3.2\nU.K. Market Analysis\nTable 12 summarizes the performance of GMV portfolios in the U.K. equity market based\non the top 100, 175, and 250 stocks. The EW portfolio continues to exhibit the highest\nAR across all portfolio sizes; however, this is again accompanied by higher AV, reaffirming\nits limitations as a risk-agnostic strategy. Among the GMV portfolios, the LSTM-BEKK model demonstrates clear superiority\nin volatility minimization. It achieves the lowest AV in every portfolio size: 0.097 at\nN = 100, 0.093 at N = 175, and 0.074 at N = 250, all of which are notably lower than\nthose achieved by DCC and Scalar BEKK. These results reflect the LSTM-BEKK model\u2019s\n32\n\n\n--- Page 33 ---\nenhanced capacity to adapt to complex volatility dynamics and provide stable covariance\nestimates, particularly in the presence of heavy-tailed return distributions observed in the\nU.K. market. In terms of downside risk, the LSTM-BEKK model also performs competitively in\nMDD reduction.",
  "5.3.2\nU.K. Market Analysis\nTable 12 summarizes the performance of GMV portfolios in the U.K. equity market based\non the top 100, 175, and 250 stocks. The EW portfolio continues to exhibit the highest\nAR across all portfolio sizes; however, this is again accompanied by higher AV, reaffirming\nits limitations as a risk-agnostic strategy. Among the GMV portfolios, the LSTM-BEKK model demonstrates clear superiority\nin volatility minimization. It achieves the lowest AV in every portfolio size: 0.097 at\nN = 100, 0.093 at N = 175, and 0.074 at N = 250, all of which are notably lower than\nthose achieved by DCC and Scalar BEKK. These results reflect the LSTM-BEKK model\u2019s\n32\n\n\n--- Page 33 ---\nenhanced capacity to adapt to complex volatility dynamics and provide stable covariance\nestimates, particularly in the presence of heavy-tailed return distributions observed in the\nU.K. market. In terms of downside risk, the LSTM-BEKK model also performs competitively in\nMDD reduction. It achieves the lowest MDD at both N = 175 (\u22120.150) and N =\n250 (\u22120.130), highlighting its robustness during adverse market periods. While Scalar\nBEKK demonstrates marginal strength at smaller portfolio sizes, the LSTM-BEKK model\nultimately offers the best balance between risk reduction and volatility control in high-\ndimensional settings. Overall, the empirical evidence from the U.K. market corroborates the results ob-\ntained in the U.S. case. The LSTM-BEKK model delivers more effective and consis-\ntent volatility management across all tested portfolio sizes, outperforming traditional\nMGARCH models in both AV and MDD. Table 12: U.K.: Performance Comparison of GMV Portfolios: Return, Risk, and Draw-\ndown.",
  "It achieves the lowest MDD at both N = 175 (\u22120.150) and N =\n250 (\u22120.130), highlighting its robustness during adverse market periods. While Scalar\nBEKK demonstrates marginal strength at smaller portfolio sizes, the LSTM-BEKK model\nultimately offers the best balance between risk reduction and volatility control in high-\ndimensional settings. Overall, the empirical evidence from the U.K. market corroborates the results ob-\ntained in the U.S. case. The LSTM-BEKK model delivers more effective and consis-\ntent volatility management across all tested portfolio sizes, outperforming traditional\nMGARCH models in both AV and MDD. Table 12: U.K.: Performance Comparison of GMV Portfolios: Return, Risk, and Draw-\ndown. EW\nDCC\nScalar BEKK\nLSTM BEKK\nN=100\nAR\n-0.013\n-0.049\n-0.073\n-0.075\nAV\n0.124\n0.113\n0.101\n0.097\nMDD\n-0.204\n-0.165\n-0.188\n-0.187\nN=175\nAR\n-0.020\n-0.087\n-0.022\n-0.035\nAV\n0.137\n0.107\n0.102\n0.093\nMDD\n-0.238\n-0.204\n-0.159\n-0.150\nN=250\nAR\n-0.027\n-0.080\n-0.026\n-0.037\nAV\n0.142\n0.076\n0.077\n0.074\nMDD\n-0.242\n-0.169\n-0.133\n-0.130\nNote: Bold values represent the lowest AV and MDD for each portfolio size. 5.3.3\nJapan Market Analysis\nThe empirical results for the Japan equity market, shown in Table 13, offer further insights\ninto the comparative performance of GMV models under a stable but moderately volatile\nmarket environment. As in previous markets, the EW portfolio achieves the highest AR\nacross most portfolio sizes, reaching 0.150 at N = 100. However, this performance comes\nat the cost of higher volatility, with an AV of 0.150, significantly above that of the GMV\nportfolios. 33\n\n\n--- Page 34 ---\nAmong the GMV models, LSTM-BEKK continues to lead in volatility reduction,\nachieving the lowest AV in 29 out of 50 portfolio combinations. Its average AV across\nthe three sizes\u20140.110, 0.097, and 0.099\u2014is consistently below both Scalar BEKK (0.119,\n0.104, 0.103) and DCC (0.128, 0.111, 0.108).",
  "5.3.3\nJapan Market Analysis\nThe empirical results for the Japan equity market, shown in Table 13, offer further insights\ninto the comparative performance of GMV models under a stable but moderately volatile\nmarket environment. As in previous markets, the EW portfolio achieves the highest AR\nacross most portfolio sizes, reaching 0.150 at N = 100. However, this performance comes\nat the cost of higher volatility, with an AV of 0.150, significantly above that of the GMV\nportfolios. 33\n\n\n--- Page 34 ---\nAmong the GMV models, LSTM-BEKK continues to lead in volatility reduction,\nachieving the lowest AV in 29 out of 50 portfolio combinations. Its average AV across\nthe three sizes\u20140.110, 0.097, and 0.099\u2014is consistently below both Scalar BEKK (0.119,\n0.104, 0.103) and DCC (0.128, 0.111, 0.108). This highlights its capacity to generalize\neffectively across different markets, including the relatively lower-volatility Japan market. Although Scalar BEKK shows stronger competitiveness here than in the U.S. or U.K.\nmarkets\u2014recording the lowest AV in 19 out of 50 portfolios\u2014LSTM-BEKK remains the\noverall leader. In the N = 25 and N = 30 configurations, the two models perform\nsimilarly, but LSTM-BEKK regains its advantage at higher dimensions such as N = 175\nand N = 250. In terms of MDD, LSTM-BEKK demonstrates robust downside risk control, outper-\nforming all other models at N = 175 and N = 250. The only exception appears at\nN = 100, where Scalar BEKK slightly outperforms with an MDD of \u22120.067 compared to\nLSTM-BEKK\u2019s \u22120.070. Despite this marginal difference, the overall trend indicates that\nLSTM-BEKK offers stronger drawdown resilience across larger portfolio dimensions. The results from the Japan market reinforce the consistent effectiveness of LSTM-\nBEKK in controlling volatility, even under less turbulent market conditions.",
  "In the N = 25 and N = 30 configurations, the two models perform\nsimilarly, but LSTM-BEKK regains its advantage at higher dimensions such as N = 175\nand N = 250. In terms of MDD, LSTM-BEKK demonstrates robust downside risk control, outper-\nforming all other models at N = 175 and N = 250. The only exception appears at\nN = 100, where Scalar BEKK slightly outperforms with an MDD of \u22120.067 compared to\nLSTM-BEKK\u2019s \u22120.070. Despite this marginal difference, the overall trend indicates that\nLSTM-BEKK offers stronger drawdown resilience across larger portfolio dimensions. The results from the Japan market reinforce the consistent effectiveness of LSTM-\nBEKK in controlling volatility, even under less turbulent market conditions. While Scalar\nBEKK exhibits increased competitiveness compared to other markets, LSTM-BEKK still\nrecords the lowest AV in the majority of cases and achieves superior drawdown protection\nat larger portfolio sizes. Taken together with the U.S. and U.K. findings, these results underscore the adapt-\nability and robustness of LSTM-enhanced volatility modeling frameworks. By dy-\nnamically adjusting to changing market regimes and capturing nonlinear dependencies,\nLSTM-BEKK continues to outperform traditional MGARCH models, especially in high-\ndimensional risk-sensitive applications. 34\n\n\n--- Page 35 ---\nTable 13: Japan: Performance Comparison of GMV Portfolios: Return, Risk, and Draw-\ndown. EW\nDCC\nScalar BEKK\nLSTM BEKK\nN=100\nAR\n0.150\n0.165\n0.157\n0.189\nAV\n0.150\n0.128\n0.119\n0.110\nMDD\n-0.090\n-0.086\n-0.067\n-0.070\nN=175\nAR\n0.141\n0.109\n0.119\n0.133\nAV\n0.143\n0.111\n0.104\n0.097\nMDD\n-0.088\n-0.090\n-0.057\n-0.046\nN=250\nAR\n0.127\n0.091\n0.150\n0.155\nAV\n0.137\n0.108\n0.103\n0.099\nMDD\n-0.086\n-0.088\n-0.055\n-0.049\nNote: Bold values represent the lowest AV and MDD for each portfolio size.",
  "While Scalar\nBEKK exhibits increased competitiveness compared to other markets, LSTM-BEKK still\nrecords the lowest AV in the majority of cases and achieves superior drawdown protection\nat larger portfolio sizes. Taken together with the U.S. and U.K. findings, these results underscore the adapt-\nability and robustness of LSTM-enhanced volatility modeling frameworks. By dy-\nnamically adjusting to changing market regimes and capturing nonlinear dependencies,\nLSTM-BEKK continues to outperform traditional MGARCH models, especially in high-\ndimensional risk-sensitive applications. 34\n\n\n--- Page 35 ---\nTable 13: Japan: Performance Comparison of GMV Portfolios: Return, Risk, and Draw-\ndown. EW\nDCC\nScalar BEKK\nLSTM BEKK\nN=100\nAR\n0.150\n0.165\n0.157\n0.189\nAV\n0.150\n0.128\n0.119\n0.110\nMDD\n-0.090\n-0.086\n-0.067\n-0.070\nN=175\nAR\n0.141\n0.109\n0.119\n0.133\nAV\n0.143\n0.111\n0.104\n0.097\nMDD\n-0.088\n-0.090\n-0.057\n-0.046\nN=250\nAR\n0.127\n0.091\n0.150\n0.155\nAV\n0.137\n0.108\n0.103\n0.099\nMDD\n-0.086\n-0.088\n-0.055\n-0.049\nNote: Bold values represent the lowest AV and MDD for each portfolio size. 5.4\nSummary of GMV Portfolio Performance\nThe above comprehensive evaluation of GMV portfolios across the U.S., U.K., and Japan\nequity markets confirms the superior performance of the LSTM-BEKK model in mini-\nmizing portfolio risk. Across all three markets and high-dimensional settings (N = 100,\n175, and 250), LSTM-BEKK consistently achieves the lowest annualized volatility (AV)\nin the majority of portfolio combinations, demonstrating its effectiveness in capturing dy-\nnamic, time-varying dependencies in asset returns. This robustness affirms its suitability\nfor investors seeking stable and risk-sensitive portfolio strategies. In the U.S. market, LSTM-BEKK dominates in volatility control and significantly im-\nproves MDD outcomes, especially as portfolio size increases. While its MDD at N = 100\nslightly exceeds that of the EW benchmark, this deviation is outweighed by its pronounced\nadvantages in larger, more volatile configurations.",
  "5.4\nSummary of GMV Portfolio Performance\nThe above comprehensive evaluation of GMV portfolios across the U.S., U.K., and Japan\nequity markets confirms the superior performance of the LSTM-BEKK model in mini-\nmizing portfolio risk. Across all three markets and high-dimensional settings (N = 100,\n175, and 250), LSTM-BEKK consistently achieves the lowest annualized volatility (AV)\nin the majority of portfolio combinations, demonstrating its effectiveness in capturing dy-\nnamic, time-varying dependencies in asset returns. This robustness affirms its suitability\nfor investors seeking stable and risk-sensitive portfolio strategies. In the U.S. market, LSTM-BEKK dominates in volatility control and significantly im-\nproves MDD outcomes, especially as portfolio size increases. While its MDD at N = 100\nslightly exceeds that of the EW benchmark, this deviation is outweighed by its pronounced\nadvantages in larger, more volatile configurations. In the U.K. market, LSTM-BEKK once\nagain leads in AV reduction across most configurations, clearly outperforming DCC and\nshowing broader stability than Scalar BEKK. These results reflect the model\u2019s adaptabil-\nity even in markets with heavier tails and higher tail-risk exposure. The Japan market presents a more competitive landscape, where Scalar BEKK\ndemonstrates stronger performance relative to other regions. Nevertheless, LSTM-BEKK\nremains the top-performing model overall, achieving the lowest AV in the majority of\ncases. Its ability to maintain both low AV and robust MDD\u2014despite Scalar BEKK\nachieving marginally lower drawdown at N = 100\u2014reinforces its practical value in man-\n35\n\n\n--- Page 36 ---\naging risk across heterogeneous environments. Taken together, the results highlight the limitations of traditional models, particularly\ntheir diminished performance in high-dimensional settings and under structural shifts. By\ncontrast, the LSTM-BEKK model integrates the flexibility of deep learning architectures\nwith the interpretability of econometric structures, yielding superior risk profiles under\nout-of-sample conditions.",
  "The Japan market presents a more competitive landscape, where Scalar BEKK\ndemonstrates stronger performance relative to other regions. Nevertheless, LSTM-BEKK\nremains the top-performing model overall, achieving the lowest AV in the majority of\ncases. Its ability to maintain both low AV and robust MDD\u2014despite Scalar BEKK\nachieving marginally lower drawdown at N = 100\u2014reinforces its practical value in man-\n35\n\n\n--- Page 36 ---\naging risk across heterogeneous environments. Taken together, the results highlight the limitations of traditional models, particularly\ntheir diminished performance in high-dimensional settings and under structural shifts. By\ncontrast, the LSTM-BEKK model integrates the flexibility of deep learning architectures\nwith the interpretability of econometric structures, yielding superior risk profiles under\nout-of-sample conditions. While some marginal trade-offs exist in specific instances, the\noverall dominance of LSTM-BEKK in both volatility and drawdown metrics underscores\nits generalizability and resilience. In summary, the LSTM-BEKK model offers a compelling advancement for GMV\nportfolio construction. It surpasses both the equally weighted benchmark and traditional\ncovariance estimators in risk control across a wide range of market conditions. These\nfindings advocate for the continued exploration of deep learning-based volatility models,\nparticularly in hybrid frameworks that balance statistical rigor with nonlinear predictive\npower in portfolio optimization. 6\nConclusion\nThis\npaper\nintroduces\na\nnovel\ndeep\nlearning\nenhanced\nmultivariate\nvolatility\nmodel\u2014LSTM-BEKK\u2014that integrates the structural interpretability of econometric\nmodels with the dynamic learning capability of recurrent neural networks. The model is\ndesigned to capture complex nonlinear dependencies and time-varying covariance struc-\ntures in financial markets. Through a comprehensive empirical study, we validate the\nrobustness and effectiveness of LSTM-BEKK across multiple dimensions. The first stage of our analysis focuses on low-dimensional in-sample visualization. Using a 4-asset portfolio from the U.S. market, we assess how well LSTM-BEKK es-\ntimates individual variances and covariances compared to traditional DCC and Scalar\nBEKK models.",
  "The model is\ndesigned to capture complex nonlinear dependencies and time-varying covariance struc-\ntures in financial markets. Through a comprehensive empirical study, we validate the\nrobustness and effectiveness of LSTM-BEKK across multiple dimensions. The first stage of our analysis focuses on low-dimensional in-sample visualization. Using a 4-asset portfolio from the U.S. market, we assess how well LSTM-BEKK es-\ntimates individual variances and covariances compared to traditional DCC and Scalar\nBEKK models. LSTM-BEKK closely tracks volatility during calm periods while adapt-\ning more promptly during stress episodes (e.g., COVID-19 outbreak), effectively balancing\nsmoothness and responsiveness. We then evaluate the model\u2019s generalization ability through repeated out-of-sample\nexperiments on 500 randomly sampled 50-asset portfolios across the U.S., U.K., and\nJapan equity markets. The LSTM-BEKK model consistently achieves the lowest average\ntest NLL in all markets. Paired t-tests confirm that these improvements are statistically\nsignificant, particularly in markets with heavier tails such as Japan. This underscores the\nmodel\u2019s robustness in heterogeneous return environments. To test high-dimensional scalability, we apply the model to market-wide portfolios of\nthe top 100, 175, and 250 equities by market capitalization in each region. LSTM-BEKK\nmaintains consistent superiority in predictive log-likelihood (NLL) over DCC and Scalar\nBEKK. Model Confidence Set analysis further supports these findings, with LSTM-BEKK\n36\n\n\n--- Page 37 ---\nbeing the only model retained across all nine settings at the 90% confidence level. Finally, we evaluate practical implications through global minimum variance portfo-\nlio backtests. Across all markets and portfolio sizes, LSTM-BEKK achieves the lowest\naverage volatility in most configurations and consistently delivers competitive or supe-\nrior performance in maximum drawdown. In high-dimensional settings, the model offers\nrobust tail risk mitigation and smoother risk estimates, essential for institutional asset\nmanagers. In conclusion, LSTM-BEKK offers a powerful and scalable solution to modern volatil-\nity modeling challenges.",
  "Finally, we evaluate practical implications through global minimum variance portfo-\nlio backtests. Across all markets and portfolio sizes, LSTM-BEKK achieves the lowest\naverage volatility in most configurations and consistently delivers competitive or supe-\nrior performance in maximum drawdown. In high-dimensional settings, the model offers\nrobust tail risk mitigation and smoother risk estimates, essential for institutional asset\nmanagers. In conclusion, LSTM-BEKK offers a powerful and scalable solution to modern volatil-\nity modeling challenges. It combines the theoretical grounding of MGARCH models with\nthe adaptability of deep learning, enabling better predictive accuracy and portfolio risk\nmanagement across diverse financial environments. Future research can extend this frame-\nwork to other deep architectures and explore its integration into broader asset pricing and\nrisk management systems.",
  "Finally, we evaluate practical implications through global minimum variance portfo-\nlio backtests. Across all markets and portfolio sizes, LSTM-BEKK achieves the lowest\naverage volatility in most configurations and consistently delivers competitive or supe-\nrior performance in maximum drawdown. In high-dimensional settings, the model offers\nrobust tail risk mitigation and smoother risk estimates, essential for institutional asset\nmanagers. In conclusion, LSTM-BEKK offers a powerful and scalable solution to modern volatil-\nity modeling challenges. It combines the theoretical grounding of MGARCH models with\nthe adaptability of deep learning, enabling better predictive accuracy and portfolio risk\nmanagement across diverse financial environments. Future research can extend this frame-\nwork to other deep architectures and explore its integration into broader asset pricing and\nrisk management systems. 37\n\n\n--- Page 38 ---\nAppendix\nAppendix A: Pseudocode for estimating the LSTM-BEKK\nThe following pseudocode outlines the parameter estimation process for the LSTM-BEKK\nmodel:\nAlgorithm 1 LSTM-BEKK Parameter Estimation Process\nRequire: Initialized parameters: C (static lower triangular matrix), a, b, LSTM weights,\nand Swish activation parameter \u03b2\nRequire: Hyperparameters: learning rate \u03b7, RMSprop settings, and maximum number\nof epochs (max_epochs)\n1: Split data into training, validation, and testing sets\n2: Initialize optimizer (RMSprop) with \u03b7 and regularization parameters\n3: for epoch = 1 to max_epochs do\n4:\nReset cumulative training loss to zero\n5:\nfor each training batch of returns r1:T do\n6:\nfor each time step t = 1 to T do\n7:\nGenerate dynamic component Ct using LSTM: \u02dcCt = LSTM( \u02dcCt\u22121, rt\u22121)\n8:\nCompute conditional covariance Ht:\nHt = CC\u2032 + CtC\u2032\nt + art\u22121r\u2032\nt\u22121 + bHt\u22121\n9:\nAccumulate negative log-likelihood (NLL) for batch:\nNLL = NLL +\n\u0000log |Ht| + r\u2032\ntH\u22121\nt rt\n\u0001\n10:\nend for\n11:\nCompute gradients of NLL with respect to all parameters\n12:\nUpdate parameters using RMSprop\n13:\nend for\n14:\nEvaluate validation loss\n15:\nif validation loss does not improve for patience epochs then\n16:\nApply learning rate scheduler and/or early stopping\n17:\nBreak\n18:\nend if\n19: end for\n20: Return optimized parameters: C, a, b, LSTM weights, and \u03b2\n38\n\n\n--- Page 39 ---\nAppendix B: Proof of Theorem 1\nLet Ft = \u03c3(ys, s \u2264t).",
  "Finally, we evaluate practical implications through global minimum variance portfo-\nlio backtests. Across all markets and portfolio sizes, LSTM-BEKK achieves the lowest\naverage volatility in most configurations and consistently delivers competitive or supe-\nrior performance in maximum drawdown. In high-dimensional settings, the model offers\nrobust tail risk mitigation and smoother risk estimates, essential for institutional asset\nmanagers. In conclusion, LSTM-BEKK offers a powerful and scalable solution to modern volatil-\nity modeling challenges. It combines the theoretical grounding of MGARCH models with\nthe adaptability of deep learning, enabling better predictive accuracy and portfolio risk\nmanagement across diverse financial environments. Future research can extend this frame-\nwork to other deep architectures and explore its integration into broader asset pricing and\nrisk management systems. 37\n\n\n--- Page 38 ---\nAppendix\nAppendix A: Pseudocode for estimating the LSTM-BEKK\nThe following pseudocode outlines the parameter estimation process for the LSTM-BEKK\nmodel:\nAlgorithm 1 LSTM-BEKK Parameter Estimation Process\nRequire: Initialized parameters: C (static lower triangular matrix), a, b, LSTM weights,\nand Swish activation parameter \u03b2\nRequire: Hyperparameters: learning rate \u03b7, RMSprop settings, and maximum number\nof epochs (max_epochs)\n1: Split data into training, validation, and testing sets\n2: Initialize optimizer (RMSprop) with \u03b7 and regularization parameters\n3: for epoch = 1 to max_epochs do\n4:\nReset cumulative training loss to zero\n5:\nfor each training batch of returns r1:T do\n6:\nfor each time step t = 1 to T do\n7:\nGenerate dynamic component Ct using LSTM: \u02dcCt = LSTM( \u02dcCt\u22121, rt\u22121)\n8:\nCompute conditional covariance Ht:\nHt = CC\u2032 + CtC\u2032\nt + art\u22121r\u2032\nt\u22121 + bHt\u22121\n9:\nAccumulate negative log-likelihood (NLL) for batch:\nNLL = NLL +\n\u0000log |Ht| + r\u2032\ntH\u22121\nt rt\n\u0001\n10:\nend for\n11:\nCompute gradients of NLL with respect to all parameters\n12:\nUpdate parameters using RMSprop\n13:\nend for\n14:\nEvaluate validation loss\n15:\nif validation loss does not improve for patience epochs then\n16:\nApply learning rate scheduler and/or early stopping\n17:\nBreak\n18:\nend if\n19: end for\n20: Return optimized parameters: C, a, b, LSTM weights, and \u03b2\n38\n\n\n--- Page 39 ---\nAppendix B: Proof of Theorem 1\nLet Ft = \u03c3(ys, s \u2264t). We have that Ct, Ht \u2208Ft\u22121, E(rtr\u2032\nt|Ft\u22121) = Ht, and that\nHt = CC\u2032 + CtC\u2032\nt + art\u22121r\u2032\nt\u22121 + bHt\u22121, \u2200t \u22651.",
  "Across all markets and portfolio sizes, LSTM-BEKK achieves the lowest\naverage volatility in most configurations and consistently delivers competitive or supe-\nrior performance in maximum drawdown. In high-dimensional settings, the model offers\nrobust tail risk mitigation and smoother risk estimates, essential for institutional asset\nmanagers. In conclusion, LSTM-BEKK offers a powerful and scalable solution to modern volatil-\nity modeling challenges. It combines the theoretical grounding of MGARCH models with\nthe adaptability of deep learning, enabling better predictive accuracy and portfolio risk\nmanagement across diverse financial environments. Future research can extend this frame-\nwork to other deep architectures and explore its integration into broader asset pricing and\nrisk management systems. 37\n\n\n--- Page 38 ---\nAppendix\nAppendix A: Pseudocode for estimating the LSTM-BEKK\nThe following pseudocode outlines the parameter estimation process for the LSTM-BEKK\nmodel:\nAlgorithm 1 LSTM-BEKK Parameter Estimation Process\nRequire: Initialized parameters: C (static lower triangular matrix), a, b, LSTM weights,\nand Swish activation parameter \u03b2\nRequire: Hyperparameters: learning rate \u03b7, RMSprop settings, and maximum number\nof epochs (max_epochs)\n1: Split data into training, validation, and testing sets\n2: Initialize optimizer (RMSprop) with \u03b7 and regularization parameters\n3: for epoch = 1 to max_epochs do\n4:\nReset cumulative training loss to zero\n5:\nfor each training batch of returns r1:T do\n6:\nfor each time step t = 1 to T do\n7:\nGenerate dynamic component Ct using LSTM: \u02dcCt = LSTM( \u02dcCt\u22121, rt\u22121)\n8:\nCompute conditional covariance Ht:\nHt = CC\u2032 + CtC\u2032\nt + art\u22121r\u2032\nt\u22121 + bHt\u22121\n9:\nAccumulate negative log-likelihood (NLL) for batch:\nNLL = NLL +\n\u0000log |Ht| + r\u2032\ntH\u22121\nt rt\n\u0001\n10:\nend for\n11:\nCompute gradients of NLL with respect to all parameters\n12:\nUpdate parameters using RMSprop\n13:\nend for\n14:\nEvaluate validation loss\n15:\nif validation loss does not improve for patience epochs then\n16:\nApply learning rate scheduler and/or early stopping\n17:\nBreak\n18:\nend if\n19: end for\n20: Return optimized parameters: C, a, b, LSTM weights, and \u03b2\n38\n\n\n--- Page 39 ---\nAppendix B: Proof of Theorem 1\nLet Ft = \u03c3(ys, s \u2264t). We have that Ct, Ht \u2208Ft\u22121, E(rtr\u2032\nt|Ft\u22121) = Ht, and that\nHt = CC\u2032 + CtC\u2032\nt + art\u22121r\u2032\nt\u22121 + bHt\u22121, \u2200t \u22651. Note that,\nE(Ht+1|Ft\u22121)\n=\nCC\u2032 + E(Ct+1C\u2032\nt+1|Ft\u22121) + aE(rtr\u2032\nt|Ft\u22121) + bHt\n=\nCC\u2032 + E(Ct+1C\u2032\nt+1|Ft\u22121) + (a + b)Ht.",
  "In high-dimensional settings, the model offers\nrobust tail risk mitigation and smoother risk estimates, essential for institutional asset\nmanagers. In conclusion, LSTM-BEKK offers a powerful and scalable solution to modern volatil-\nity modeling challenges. It combines the theoretical grounding of MGARCH models with\nthe adaptability of deep learning, enabling better predictive accuracy and portfolio risk\nmanagement across diverse financial environments. Future research can extend this frame-\nwork to other deep architectures and explore its integration into broader asset pricing and\nrisk management systems. 37\n\n\n--- Page 38 ---\nAppendix\nAppendix A: Pseudocode for estimating the LSTM-BEKK\nThe following pseudocode outlines the parameter estimation process for the LSTM-BEKK\nmodel:\nAlgorithm 1 LSTM-BEKK Parameter Estimation Process\nRequire: Initialized parameters: C (static lower triangular matrix), a, b, LSTM weights,\nand Swish activation parameter \u03b2\nRequire: Hyperparameters: learning rate \u03b7, RMSprop settings, and maximum number\nof epochs (max_epochs)\n1: Split data into training, validation, and testing sets\n2: Initialize optimizer (RMSprop) with \u03b7 and regularization parameters\n3: for epoch = 1 to max_epochs do\n4:\nReset cumulative training loss to zero\n5:\nfor each training batch of returns r1:T do\n6:\nfor each time step t = 1 to T do\n7:\nGenerate dynamic component Ct using LSTM: \u02dcCt = LSTM( \u02dcCt\u22121, rt\u22121)\n8:\nCompute conditional covariance Ht:\nHt = CC\u2032 + CtC\u2032\nt + art\u22121r\u2032\nt\u22121 + bHt\u22121\n9:\nAccumulate negative log-likelihood (NLL) for batch:\nNLL = NLL +\n\u0000log |Ht| + r\u2032\ntH\u22121\nt rt\n\u0001\n10:\nend for\n11:\nCompute gradients of NLL with respect to all parameters\n12:\nUpdate parameters using RMSprop\n13:\nend for\n14:\nEvaluate validation loss\n15:\nif validation loss does not improve for patience epochs then\n16:\nApply learning rate scheduler and/or early stopping\n17:\nBreak\n18:\nend if\n19: end for\n20: Return optimized parameters: C, a, b, LSTM weights, and \u03b2\n38\n\n\n--- Page 39 ---\nAppendix B: Proof of Theorem 1\nLet Ft = \u03c3(ys, s \u2264t). We have that Ct, Ht \u2208Ft\u22121, E(rtr\u2032\nt|Ft\u22121) = Ht, and that\nHt = CC\u2032 + CtC\u2032\nt + art\u22121r\u2032\nt\u22121 + bHt\u22121, \u2200t \u22651. Note that,\nE(Ht+1|Ft\u22121)\n=\nCC\u2032 + E(Ct+1C\u2032\nt+1|Ft\u22121) + aE(rtr\u2032\nt|Ft\u22121) + bHt\n=\nCC\u2032 + E(Ct+1C\u2032\nt+1|Ft\u22121) + (a + b)Ht. By the assumption on the bounded norm of CtC\u2032\nt, there exists a finite constant M > 0\nsuch that\n\u2225E(Ht+1|Ft\u22121)\u2225\u2264M + (a + b)\u2225Ht\u2225, a.s.\n(24)\nNow, observe that\nE(rt+1r\u2032\nt+1|Ft\u22121) = E\n\u0000E(rt+1r\u2032\nt+1|Ft)|Ft\u22121\n\u0001\n= E(Ht+1|Ft\u22121).",
  "In conclusion, LSTM-BEKK offers a powerful and scalable solution to modern volatil-\nity modeling challenges. It combines the theoretical grounding of MGARCH models with\nthe adaptability of deep learning, enabling better predictive accuracy and portfolio risk\nmanagement across diverse financial environments. Future research can extend this frame-\nwork to other deep architectures and explore its integration into broader asset pricing and\nrisk management systems. 37\n\n\n--- Page 38 ---\nAppendix\nAppendix A: Pseudocode for estimating the LSTM-BEKK\nThe following pseudocode outlines the parameter estimation process for the LSTM-BEKK\nmodel:\nAlgorithm 1 LSTM-BEKK Parameter Estimation Process\nRequire: Initialized parameters: C (static lower triangular matrix), a, b, LSTM weights,\nand Swish activation parameter \u03b2\nRequire: Hyperparameters: learning rate \u03b7, RMSprop settings, and maximum number\nof epochs (max_epochs)\n1: Split data into training, validation, and testing sets\n2: Initialize optimizer (RMSprop) with \u03b7 and regularization parameters\n3: for epoch = 1 to max_epochs do\n4:\nReset cumulative training loss to zero\n5:\nfor each training batch of returns r1:T do\n6:\nfor each time step t = 1 to T do\n7:\nGenerate dynamic component Ct using LSTM: \u02dcCt = LSTM( \u02dcCt\u22121, rt\u22121)\n8:\nCompute conditional covariance Ht:\nHt = CC\u2032 + CtC\u2032\nt + art\u22121r\u2032\nt\u22121 + bHt\u22121\n9:\nAccumulate negative log-likelihood (NLL) for batch:\nNLL = NLL +\n\u0000log |Ht| + r\u2032\ntH\u22121\nt rt\n\u0001\n10:\nend for\n11:\nCompute gradients of NLL with respect to all parameters\n12:\nUpdate parameters using RMSprop\n13:\nend for\n14:\nEvaluate validation loss\n15:\nif validation loss does not improve for patience epochs then\n16:\nApply learning rate scheduler and/or early stopping\n17:\nBreak\n18:\nend if\n19: end for\n20: Return optimized parameters: C, a, b, LSTM weights, and \u03b2\n38\n\n\n--- Page 39 ---\nAppendix B: Proof of Theorem 1\nLet Ft = \u03c3(ys, s \u2264t). We have that Ct, Ht \u2208Ft\u22121, E(rtr\u2032\nt|Ft\u22121) = Ht, and that\nHt = CC\u2032 + CtC\u2032\nt + art\u22121r\u2032\nt\u22121 + bHt\u22121, \u2200t \u22651. Note that,\nE(Ht+1|Ft\u22121)\n=\nCC\u2032 + E(Ct+1C\u2032\nt+1|Ft\u22121) + aE(rtr\u2032\nt|Ft\u22121) + bHt\n=\nCC\u2032 + E(Ct+1C\u2032\nt+1|Ft\u22121) + (a + b)Ht. By the assumption on the bounded norm of CtC\u2032\nt, there exists a finite constant M > 0\nsuch that\n\u2225E(Ht+1|Ft\u22121)\u2225\u2264M + (a + b)\u2225Ht\u2225, a.s.\n(24)\nNow, observe that\nE(rt+1r\u2032\nt+1|Ft\u22121) = E\n\u0000E(rt+1r\u2032\nt+1|Ft)|Ft\u22121\n\u0001\n= E(Ht+1|Ft\u22121). Hence,\nE(Ht+2|Ft\u22121)\n=\nCC\u2032 + E(Ct+2C\u2032\nt+2|Ft\u22121) + aE(rt+1r\u2032\nt+1|Ft\u22121) + bE(Ht+1|Ft\u22121)\n=\nCC\u2032 + E(Ct+2C\u2032\nt+2|Ft\u22121) + (a + b)E(Ht+1|Ft\u22121),\nand thus\n\u2225E(Ht+2|Ft\u22121)\u2225\n\u2264\nM + (a + b)\u2225E(Ht+1|Ft\u22121)\u2225\n\u2264\n(1 + (a + b))M + (a + b)2\u2225Ht\u2225, a.s.\n(25)\nBy induction, it can be seen that, for any k \u22651,\n\u2225E(Ht+k|Ft\u22121)\u2225\n\u2264\n\u00001 + (a + b) + ... + (a + b)k\u22121\u0001\nM + (a + b)k\u2225Ht\u2225\n(26)\n=\n1 \u2212(a + b)k\n1 \u2212a \u2212b M + (a + b)k\u2225Ht\u2225a.s.",
  "It combines the theoretical grounding of MGARCH models with\nthe adaptability of deep learning, enabling better predictive accuracy and portfolio risk\nmanagement across diverse financial environments. Future research can extend this frame-\nwork to other deep architectures and explore its integration into broader asset pricing and\nrisk management systems. 37\n\n\n--- Page 38 ---\nAppendix\nAppendix A: Pseudocode for estimating the LSTM-BEKK\nThe following pseudocode outlines the parameter estimation process for the LSTM-BEKK\nmodel:\nAlgorithm 1 LSTM-BEKK Parameter Estimation Process\nRequire: Initialized parameters: C (static lower triangular matrix), a, b, LSTM weights,\nand Swish activation parameter \u03b2\nRequire: Hyperparameters: learning rate \u03b7, RMSprop settings, and maximum number\nof epochs (max_epochs)\n1: Split data into training, validation, and testing sets\n2: Initialize optimizer (RMSprop) with \u03b7 and regularization parameters\n3: for epoch = 1 to max_epochs do\n4:\nReset cumulative training loss to zero\n5:\nfor each training batch of returns r1:T do\n6:\nfor each time step t = 1 to T do\n7:\nGenerate dynamic component Ct using LSTM: \u02dcCt = LSTM( \u02dcCt\u22121, rt\u22121)\n8:\nCompute conditional covariance Ht:\nHt = CC\u2032 + CtC\u2032\nt + art\u22121r\u2032\nt\u22121 + bHt\u22121\n9:\nAccumulate negative log-likelihood (NLL) for batch:\nNLL = NLL +\n\u0000log |Ht| + r\u2032\ntH\u22121\nt rt\n\u0001\n10:\nend for\n11:\nCompute gradients of NLL with respect to all parameters\n12:\nUpdate parameters using RMSprop\n13:\nend for\n14:\nEvaluate validation loss\n15:\nif validation loss does not improve for patience epochs then\n16:\nApply learning rate scheduler and/or early stopping\n17:\nBreak\n18:\nend if\n19: end for\n20: Return optimized parameters: C, a, b, LSTM weights, and \u03b2\n38\n\n\n--- Page 39 ---\nAppendix B: Proof of Theorem 1\nLet Ft = \u03c3(ys, s \u2264t). We have that Ct, Ht \u2208Ft\u22121, E(rtr\u2032\nt|Ft\u22121) = Ht, and that\nHt = CC\u2032 + CtC\u2032\nt + art\u22121r\u2032\nt\u22121 + bHt\u22121, \u2200t \u22651. Note that,\nE(Ht+1|Ft\u22121)\n=\nCC\u2032 + E(Ct+1C\u2032\nt+1|Ft\u22121) + aE(rtr\u2032\nt|Ft\u22121) + bHt\n=\nCC\u2032 + E(Ct+1C\u2032\nt+1|Ft\u22121) + (a + b)Ht. By the assumption on the bounded norm of CtC\u2032\nt, there exists a finite constant M > 0\nsuch that\n\u2225E(Ht+1|Ft\u22121)\u2225\u2264M + (a + b)\u2225Ht\u2225, a.s.\n(24)\nNow, observe that\nE(rt+1r\u2032\nt+1|Ft\u22121) = E\n\u0000E(rt+1r\u2032\nt+1|Ft)|Ft\u22121\n\u0001\n= E(Ht+1|Ft\u22121). Hence,\nE(Ht+2|Ft\u22121)\n=\nCC\u2032 + E(Ct+2C\u2032\nt+2|Ft\u22121) + aE(rt+1r\u2032\nt+1|Ft\u22121) + bE(Ht+1|Ft\u22121)\n=\nCC\u2032 + E(Ct+2C\u2032\nt+2|Ft\u22121) + (a + b)E(Ht+1|Ft\u22121),\nand thus\n\u2225E(Ht+2|Ft\u22121)\u2225\n\u2264\nM + (a + b)\u2225E(Ht+1|Ft\u22121)\u2225\n\u2264\n(1 + (a + b))M + (a + b)2\u2225Ht\u2225, a.s.\n(25)\nBy induction, it can be seen that, for any k \u22651,\n\u2225E(Ht+k|Ft\u22121)\u2225\n\u2264\n\u00001 + (a + b) + ... + (a + b)k\u22121\u0001\nM + (a + b)k\u2225Ht\u2225\n(26)\n=\n1 \u2212(a + b)k\n1 \u2212a \u2212b M + (a + b)k\u2225Ht\u2225a.s. (27)\nLet t = 0 we obtain (14).",
  "Future research can extend this frame-\nwork to other deep architectures and explore its integration into broader asset pricing and\nrisk management systems. 37\n\n\n--- Page 38 ---\nAppendix\nAppendix A: Pseudocode for estimating the LSTM-BEKK\nThe following pseudocode outlines the parameter estimation process for the LSTM-BEKK\nmodel:\nAlgorithm 1 LSTM-BEKK Parameter Estimation Process\nRequire: Initialized parameters: C (static lower triangular matrix), a, b, LSTM weights,\nand Swish activation parameter \u03b2\nRequire: Hyperparameters: learning rate \u03b7, RMSprop settings, and maximum number\nof epochs (max_epochs)\n1: Split data into training, validation, and testing sets\n2: Initialize optimizer (RMSprop) with \u03b7 and regularization parameters\n3: for epoch = 1 to max_epochs do\n4:\nReset cumulative training loss to zero\n5:\nfor each training batch of returns r1:T do\n6:\nfor each time step t = 1 to T do\n7:\nGenerate dynamic component Ct using LSTM: \u02dcCt = LSTM( \u02dcCt\u22121, rt\u22121)\n8:\nCompute conditional covariance Ht:\nHt = CC\u2032 + CtC\u2032\nt + art\u22121r\u2032\nt\u22121 + bHt\u22121\n9:\nAccumulate negative log-likelihood (NLL) for batch:\nNLL = NLL +\n\u0000log |Ht| + r\u2032\ntH\u22121\nt rt\n\u0001\n10:\nend for\n11:\nCompute gradients of NLL with respect to all parameters\n12:\nUpdate parameters using RMSprop\n13:\nend for\n14:\nEvaluate validation loss\n15:\nif validation loss does not improve for patience epochs then\n16:\nApply learning rate scheduler and/or early stopping\n17:\nBreak\n18:\nend if\n19: end for\n20: Return optimized parameters: C, a, b, LSTM weights, and \u03b2\n38\n\n\n--- Page 39 ---\nAppendix B: Proof of Theorem 1\nLet Ft = \u03c3(ys, s \u2264t). We have that Ct, Ht \u2208Ft\u22121, E(rtr\u2032\nt|Ft\u22121) = Ht, and that\nHt = CC\u2032 + CtC\u2032\nt + art\u22121r\u2032\nt\u22121 + bHt\u22121, \u2200t \u22651. Note that,\nE(Ht+1|Ft\u22121)\n=\nCC\u2032 + E(Ct+1C\u2032\nt+1|Ft\u22121) + aE(rtr\u2032\nt|Ft\u22121) + bHt\n=\nCC\u2032 + E(Ct+1C\u2032\nt+1|Ft\u22121) + (a + b)Ht. By the assumption on the bounded norm of CtC\u2032\nt, there exists a finite constant M > 0\nsuch that\n\u2225E(Ht+1|Ft\u22121)\u2225\u2264M + (a + b)\u2225Ht\u2225, a.s.\n(24)\nNow, observe that\nE(rt+1r\u2032\nt+1|Ft\u22121) = E\n\u0000E(rt+1r\u2032\nt+1|Ft)|Ft\u22121\n\u0001\n= E(Ht+1|Ft\u22121). Hence,\nE(Ht+2|Ft\u22121)\n=\nCC\u2032 + E(Ct+2C\u2032\nt+2|Ft\u22121) + aE(rt+1r\u2032\nt+1|Ft\u22121) + bE(Ht+1|Ft\u22121)\n=\nCC\u2032 + E(Ct+2C\u2032\nt+2|Ft\u22121) + (a + b)E(Ht+1|Ft\u22121),\nand thus\n\u2225E(Ht+2|Ft\u22121)\u2225\n\u2264\nM + (a + b)\u2225E(Ht+1|Ft\u22121)\u2225\n\u2264\n(1 + (a + b))M + (a + b)2\u2225Ht\u2225, a.s.\n(25)\nBy induction, it can be seen that, for any k \u22651,\n\u2225E(Ht+k|Ft\u22121)\u2225\n\u2264\n\u00001 + (a + b) + ... + (a + b)k\u22121\u0001\nM + (a + b)k\u2225Ht\u2225\n(26)\n=\n1 \u2212(a + b)k\n1 \u2212a \u2212b M + (a + b)k\u2225Ht\u2225a.s. (27)\nLet t = 0 we obtain (14). Appendix C: Tail Risk Forecast of GMV Portfolios\nIn this section, we assess the performance of Global Minimum Variance portfolios, gen-\nerated by Scalar BEKK, DCC and LSTM-BEKK in terms of tail risk measures, Value\nat Risk (VaR) and Expected Shortfall (ES).",
  "37\n\n\n--- Page 38 ---\nAppendix\nAppendix A: Pseudocode for estimating the LSTM-BEKK\nThe following pseudocode outlines the parameter estimation process for the LSTM-BEKK\nmodel:\nAlgorithm 1 LSTM-BEKK Parameter Estimation Process\nRequire: Initialized parameters: C (static lower triangular matrix), a, b, LSTM weights,\nand Swish activation parameter \u03b2\nRequire: Hyperparameters: learning rate \u03b7, RMSprop settings, and maximum number\nof epochs (max_epochs)\n1: Split data into training, validation, and testing sets\n2: Initialize optimizer (RMSprop) with \u03b7 and regularization parameters\n3: for epoch = 1 to max_epochs do\n4:\nReset cumulative training loss to zero\n5:\nfor each training batch of returns r1:T do\n6:\nfor each time step t = 1 to T do\n7:\nGenerate dynamic component Ct using LSTM: \u02dcCt = LSTM( \u02dcCt\u22121, rt\u22121)\n8:\nCompute conditional covariance Ht:\nHt = CC\u2032 + CtC\u2032\nt + art\u22121r\u2032\nt\u22121 + bHt\u22121\n9:\nAccumulate negative log-likelihood (NLL) for batch:\nNLL = NLL +\n\u0000log |Ht| + r\u2032\ntH\u22121\nt rt\n\u0001\n10:\nend for\n11:\nCompute gradients of NLL with respect to all parameters\n12:\nUpdate parameters using RMSprop\n13:\nend for\n14:\nEvaluate validation loss\n15:\nif validation loss does not improve for patience epochs then\n16:\nApply learning rate scheduler and/or early stopping\n17:\nBreak\n18:\nend if\n19: end for\n20: Return optimized parameters: C, a, b, LSTM weights, and \u03b2\n38\n\n\n--- Page 39 ---\nAppendix B: Proof of Theorem 1\nLet Ft = \u03c3(ys, s \u2264t). We have that Ct, Ht \u2208Ft\u22121, E(rtr\u2032\nt|Ft\u22121) = Ht, and that\nHt = CC\u2032 + CtC\u2032\nt + art\u22121r\u2032\nt\u22121 + bHt\u22121, \u2200t \u22651. Note that,\nE(Ht+1|Ft\u22121)\n=\nCC\u2032 + E(Ct+1C\u2032\nt+1|Ft\u22121) + aE(rtr\u2032\nt|Ft\u22121) + bHt\n=\nCC\u2032 + E(Ct+1C\u2032\nt+1|Ft\u22121) + (a + b)Ht. By the assumption on the bounded norm of CtC\u2032\nt, there exists a finite constant M > 0\nsuch that\n\u2225E(Ht+1|Ft\u22121)\u2225\u2264M + (a + b)\u2225Ht\u2225, a.s.\n(24)\nNow, observe that\nE(rt+1r\u2032\nt+1|Ft\u22121) = E\n\u0000E(rt+1r\u2032\nt+1|Ft)|Ft\u22121\n\u0001\n= E(Ht+1|Ft\u22121). Hence,\nE(Ht+2|Ft\u22121)\n=\nCC\u2032 + E(Ct+2C\u2032\nt+2|Ft\u22121) + aE(rt+1r\u2032\nt+1|Ft\u22121) + bE(Ht+1|Ft\u22121)\n=\nCC\u2032 + E(Ct+2C\u2032\nt+2|Ft\u22121) + (a + b)E(Ht+1|Ft\u22121),\nand thus\n\u2225E(Ht+2|Ft\u22121)\u2225\n\u2264\nM + (a + b)\u2225E(Ht+1|Ft\u22121)\u2225\n\u2264\n(1 + (a + b))M + (a + b)2\u2225Ht\u2225, a.s.\n(25)\nBy induction, it can be seen that, for any k \u22651,\n\u2225E(Ht+k|Ft\u22121)\u2225\n\u2264\n\u00001 + (a + b) + ... + (a + b)k\u22121\u0001\nM + (a + b)k\u2225Ht\u2225\n(26)\n=\n1 \u2212(a + b)k\n1 \u2212a \u2212b M + (a + b)k\u2225Ht\u2225a.s. (27)\nLet t = 0 we obtain (14). Appendix C: Tail Risk Forecast of GMV Portfolios\nIn this section, we assess the performance of Global Minimum Variance portfolios, gen-\nerated by Scalar BEKK, DCC and LSTM-BEKK in terms of tail risk measures, Value\nat Risk (VaR) and Expected Shortfall (ES). VaR represents the quantile of the return\ndistribution at a specified confidence level \u03b1, while ES quantifies the conditional expec-\ntation of losses exceeding the VaR threshold, offering a more comprehensive view of tail\nrisk.",
  "We have that Ct, Ht \u2208Ft\u22121, E(rtr\u2032\nt|Ft\u22121) = Ht, and that\nHt = CC\u2032 + CtC\u2032\nt + art\u22121r\u2032\nt\u22121 + bHt\u22121, \u2200t \u22651. Note that,\nE(Ht+1|Ft\u22121)\n=\nCC\u2032 + E(Ct+1C\u2032\nt+1|Ft\u22121) + aE(rtr\u2032\nt|Ft\u22121) + bHt\n=\nCC\u2032 + E(Ct+1C\u2032\nt+1|Ft\u22121) + (a + b)Ht. By the assumption on the bounded norm of CtC\u2032\nt, there exists a finite constant M > 0\nsuch that\n\u2225E(Ht+1|Ft\u22121)\u2225\u2264M + (a + b)\u2225Ht\u2225, a.s.\n(24)\nNow, observe that\nE(rt+1r\u2032\nt+1|Ft\u22121) = E\n\u0000E(rt+1r\u2032\nt+1|Ft)|Ft\u22121\n\u0001\n= E(Ht+1|Ft\u22121). Hence,\nE(Ht+2|Ft\u22121)\n=\nCC\u2032 + E(Ct+2C\u2032\nt+2|Ft\u22121) + aE(rt+1r\u2032\nt+1|Ft\u22121) + bE(Ht+1|Ft\u22121)\n=\nCC\u2032 + E(Ct+2C\u2032\nt+2|Ft\u22121) + (a + b)E(Ht+1|Ft\u22121),\nand thus\n\u2225E(Ht+2|Ft\u22121)\u2225\n\u2264\nM + (a + b)\u2225E(Ht+1|Ft\u22121)\u2225\n\u2264\n(1 + (a + b))M + (a + b)2\u2225Ht\u2225, a.s.\n(25)\nBy induction, it can be seen that, for any k \u22651,\n\u2225E(Ht+k|Ft\u22121)\u2225\n\u2264\n\u00001 + (a + b) + ... + (a + b)k\u22121\u0001\nM + (a + b)k\u2225Ht\u2225\n(26)\n=\n1 \u2212(a + b)k\n1 \u2212a \u2212b M + (a + b)k\u2225Ht\u2225a.s. (27)\nLet t = 0 we obtain (14). Appendix C: Tail Risk Forecast of GMV Portfolios\nIn this section, we assess the performance of Global Minimum Variance portfolios, gen-\nerated by Scalar BEKK, DCC and LSTM-BEKK in terms of tail risk measures, Value\nat Risk (VaR) and Expected Shortfall (ES). VaR represents the quantile of the return\ndistribution at a specified confidence level \u03b1, while ES quantifies the conditional expec-\ntation of losses exceeding the VaR threshold, offering a more comprehensive view of tail\nrisk. This section analyzes the performance of DCC, Scalar BEKK, and LSTM BEKK\nmodels in forecasting these measures, leveraging theoretical advancements in elicitable\nrisk measures and robust regression.",
  "Note that,\nE(Ht+1|Ft\u22121)\n=\nCC\u2032 + E(Ct+1C\u2032\nt+1|Ft\u22121) + aE(rtr\u2032\nt|Ft\u22121) + bHt\n=\nCC\u2032 + E(Ct+1C\u2032\nt+1|Ft\u22121) + (a + b)Ht. By the assumption on the bounded norm of CtC\u2032\nt, there exists a finite constant M > 0\nsuch that\n\u2225E(Ht+1|Ft\u22121)\u2225\u2264M + (a + b)\u2225Ht\u2225, a.s.\n(24)\nNow, observe that\nE(rt+1r\u2032\nt+1|Ft\u22121) = E\n\u0000E(rt+1r\u2032\nt+1|Ft)|Ft\u22121\n\u0001\n= E(Ht+1|Ft\u22121). Hence,\nE(Ht+2|Ft\u22121)\n=\nCC\u2032 + E(Ct+2C\u2032\nt+2|Ft\u22121) + aE(rt+1r\u2032\nt+1|Ft\u22121) + bE(Ht+1|Ft\u22121)\n=\nCC\u2032 + E(Ct+2C\u2032\nt+2|Ft\u22121) + (a + b)E(Ht+1|Ft\u22121),\nand thus\n\u2225E(Ht+2|Ft\u22121)\u2225\n\u2264\nM + (a + b)\u2225E(Ht+1|Ft\u22121)\u2225\n\u2264\n(1 + (a + b))M + (a + b)2\u2225Ht\u2225, a.s.\n(25)\nBy induction, it can be seen that, for any k \u22651,\n\u2225E(Ht+k|Ft\u22121)\u2225\n\u2264\n\u00001 + (a + b) + ... + (a + b)k\u22121\u0001\nM + (a + b)k\u2225Ht\u2225\n(26)\n=\n1 \u2212(a + b)k\n1 \u2212a \u2212b M + (a + b)k\u2225Ht\u2225a.s. (27)\nLet t = 0 we obtain (14). Appendix C: Tail Risk Forecast of GMV Portfolios\nIn this section, we assess the performance of Global Minimum Variance portfolios, gen-\nerated by Scalar BEKK, DCC and LSTM-BEKK in terms of tail risk measures, Value\nat Risk (VaR) and Expected Shortfall (ES). VaR represents the quantile of the return\ndistribution at a specified confidence level \u03b1, while ES quantifies the conditional expec-\ntation of losses exceeding the VaR threshold, offering a more comprehensive view of tail\nrisk. This section analyzes the performance of DCC, Scalar BEKK, and LSTM BEKK\nmodels in forecasting these measures, leveraging theoretical advancements in elicitable\nrisk measures and robust regression. 39\n\n\n--- Page 40 ---\nQuantile Loss and Joint Loss Framework\nThe evaluation of VaR forecasts is commonly conducted using the quantile loss function,\nwhich assesses the accuracy of predicted quantiles against observed returns.",
  "By the assumption on the bounded norm of CtC\u2032\nt, there exists a finite constant M > 0\nsuch that\n\u2225E(Ht+1|Ft\u22121)\u2225\u2264M + (a + b)\u2225Ht\u2225, a.s.\n(24)\nNow, observe that\nE(rt+1r\u2032\nt+1|Ft\u22121) = E\n\u0000E(rt+1r\u2032\nt+1|Ft)|Ft\u22121\n\u0001\n= E(Ht+1|Ft\u22121). Hence,\nE(Ht+2|Ft\u22121)\n=\nCC\u2032 + E(Ct+2C\u2032\nt+2|Ft\u22121) + aE(rt+1r\u2032\nt+1|Ft\u22121) + bE(Ht+1|Ft\u22121)\n=\nCC\u2032 + E(Ct+2C\u2032\nt+2|Ft\u22121) + (a + b)E(Ht+1|Ft\u22121),\nand thus\n\u2225E(Ht+2|Ft\u22121)\u2225\n\u2264\nM + (a + b)\u2225E(Ht+1|Ft\u22121)\u2225\n\u2264\n(1 + (a + b))M + (a + b)2\u2225Ht\u2225, a.s.\n(25)\nBy induction, it can be seen that, for any k \u22651,\n\u2225E(Ht+k|Ft\u22121)\u2225\n\u2264\n\u00001 + (a + b) + ... + (a + b)k\u22121\u0001\nM + (a + b)k\u2225Ht\u2225\n(26)\n=\n1 \u2212(a + b)k\n1 \u2212a \u2212b M + (a + b)k\u2225Ht\u2225a.s. (27)\nLet t = 0 we obtain (14). Appendix C: Tail Risk Forecast of GMV Portfolios\nIn this section, we assess the performance of Global Minimum Variance portfolios, gen-\nerated by Scalar BEKK, DCC and LSTM-BEKK in terms of tail risk measures, Value\nat Risk (VaR) and Expected Shortfall (ES). VaR represents the quantile of the return\ndistribution at a specified confidence level \u03b1, while ES quantifies the conditional expec-\ntation of losses exceeding the VaR threshold, offering a more comprehensive view of tail\nrisk. This section analyzes the performance of DCC, Scalar BEKK, and LSTM BEKK\nmodels in forecasting these measures, leveraging theoretical advancements in elicitable\nrisk measures and robust regression. 39\n\n\n--- Page 40 ---\nQuantile Loss and Joint Loss Framework\nThe evaluation of VaR forecasts is commonly conducted using the quantile loss function,\nwhich assesses the accuracy of predicted quantiles against observed returns. VaR, as a key\nrisk measure, captures the maximum potential loss over a given time horizon at a specified\nconfidence level \u03b1.",
  "Hence,\nE(Ht+2|Ft\u22121)\n=\nCC\u2032 + E(Ct+2C\u2032\nt+2|Ft\u22121) + aE(rt+1r\u2032\nt+1|Ft\u22121) + bE(Ht+1|Ft\u22121)\n=\nCC\u2032 + E(Ct+2C\u2032\nt+2|Ft\u22121) + (a + b)E(Ht+1|Ft\u22121),\nand thus\n\u2225E(Ht+2|Ft\u22121)\u2225\n\u2264\nM + (a + b)\u2225E(Ht+1|Ft\u22121)\u2225\n\u2264\n(1 + (a + b))M + (a + b)2\u2225Ht\u2225, a.s.\n(25)\nBy induction, it can be seen that, for any k \u22651,\n\u2225E(Ht+k|Ft\u22121)\u2225\n\u2264\n\u00001 + (a + b) + ... + (a + b)k\u22121\u0001\nM + (a + b)k\u2225Ht\u2225\n(26)\n=\n1 \u2212(a + b)k\n1 \u2212a \u2212b M + (a + b)k\u2225Ht\u2225a.s. (27)\nLet t = 0 we obtain (14). Appendix C: Tail Risk Forecast of GMV Portfolios\nIn this section, we assess the performance of Global Minimum Variance portfolios, gen-\nerated by Scalar BEKK, DCC and LSTM-BEKK in terms of tail risk measures, Value\nat Risk (VaR) and Expected Shortfall (ES). VaR represents the quantile of the return\ndistribution at a specified confidence level \u03b1, while ES quantifies the conditional expec-\ntation of losses exceeding the VaR threshold, offering a more comprehensive view of tail\nrisk. This section analyzes the performance of DCC, Scalar BEKK, and LSTM BEKK\nmodels in forecasting these measures, leveraging theoretical advancements in elicitable\nrisk measures and robust regression. 39\n\n\n--- Page 40 ---\nQuantile Loss and Joint Loss Framework\nThe evaluation of VaR forecasts is commonly conducted using the quantile loss function,\nwhich assesses the accuracy of predicted quantiles against observed returns. VaR, as a key\nrisk measure, captures the maximum potential loss over a given time horizon at a specified\nconfidence level \u03b1. The quantile regression framework, introduced by Koenker and Bassett\n(1978), provides a robust method for estimating VaR by minimizing deviations at the true\nquantile level.",
  "(27)\nLet t = 0 we obtain (14). Appendix C: Tail Risk Forecast of GMV Portfolios\nIn this section, we assess the performance of Global Minimum Variance portfolios, gen-\nerated by Scalar BEKK, DCC and LSTM-BEKK in terms of tail risk measures, Value\nat Risk (VaR) and Expected Shortfall (ES). VaR represents the quantile of the return\ndistribution at a specified confidence level \u03b1, while ES quantifies the conditional expec-\ntation of losses exceeding the VaR threshold, offering a more comprehensive view of tail\nrisk. This section analyzes the performance of DCC, Scalar BEKK, and LSTM BEKK\nmodels in forecasting these measures, leveraging theoretical advancements in elicitable\nrisk measures and robust regression. 39\n\n\n--- Page 40 ---\nQuantile Loss and Joint Loss Framework\nThe evaluation of VaR forecasts is commonly conducted using the quantile loss function,\nwhich assesses the accuracy of predicted quantiles against observed returns. VaR, as a key\nrisk measure, captures the maximum potential loss over a given time horizon at a specified\nconfidence level \u03b1. The quantile regression framework, introduced by Koenker and Bassett\n(1978), provides a robust method for estimating VaR by minimizing deviations at the true\nquantile level. The quantile loss function is formally defined as:\nQloss\u03b1 =\nT\nX\nt=1\n(\u03b1 \u2212I(yt < Q\u03b1\nt ))(yt \u2212Q\u03b1\nt ),\n(28)\nwhere Q\u03b1\nt represents the forecast \u03b1-quantile VaR of the return series yt, and I(\u00b7) is an\nindicator function that takes the value 1 if yt < Q\u03b1\nt , and 0 otherwise. This loss function\npenalizes deviations proportionally, ensuring that the expected loss is minimized when\nthe forecast aligns with the true quantile. While VaR provides a single quantile-based measure of risk, it does not account for\nlosses exceeding this threshold.",
  "VaR, as a key\nrisk measure, captures the maximum potential loss over a given time horizon at a specified\nconfidence level \u03b1. The quantile regression framework, introduced by Koenker and Bassett\n(1978), provides a robust method for estimating VaR by minimizing deviations at the true\nquantile level. The quantile loss function is formally defined as:\nQloss\u03b1 =\nT\nX\nt=1\n(\u03b1 \u2212I(yt < Q\u03b1\nt ))(yt \u2212Q\u03b1\nt ),\n(28)\nwhere Q\u03b1\nt represents the forecast \u03b1-quantile VaR of the return series yt, and I(\u00b7) is an\nindicator function that takes the value 1 if yt < Q\u03b1\nt , and 0 otherwise. This loss function\npenalizes deviations proportionally, ensuring that the expected loss is minimized when\nthe forecast aligns with the true quantile. While VaR provides a single quantile-based measure of risk, it does not account for\nlosses exceeding this threshold. To address this limitation, ES has been proposed as a\ncomplementary metric, representing the average loss conditional on exceeding VaR. The\njoint evaluation of VaR and ES forecasts is facilitated by the Asymmetric Laplace (AL)\nloss function, which is strictly consistent for both measures, as demonstrated by Fissler\nand Ziegel (2016). This joint loss function, introduced in Taylor (2019), is given by:\nJointLoss\u03b1 = 1\nT\nT\nX\nt=1\n\u0014\n\u2212log\n\u0012\u03b1 \u22121\nES\u03b1\nt\n\u0013\n\u2212(yt \u2212Q\u03b1\nt )(\u03b1 \u2212I(yt \u2264Q\u03b1\nt ))\n\u03b1 \u00b7 ES\u03b1\nt\n\u0015\n,\n(29)\nwhere ES\u03b1\nt denotes the forecast Expected Shortfall at time t.\nThe AL loss function offers several advantages. First, it enables the simultaneous\nevaluation of VaR and ES, which are jointly elicitable, ensuring that the forecasts align\nwith their theoretical definitions. Second, it penalizes deviations in a manner consistent\nwith the relative importance of VaR and ES in risk management.",
  "To address this limitation, ES has been proposed as a\ncomplementary metric, representing the average loss conditional on exceeding VaR. The\njoint evaluation of VaR and ES forecasts is facilitated by the Asymmetric Laplace (AL)\nloss function, which is strictly consistent for both measures, as demonstrated by Fissler\nand Ziegel (2016). This joint loss function, introduced in Taylor (2019), is given by:\nJointLoss\u03b1 = 1\nT\nT\nX\nt=1\n\u0014\n\u2212log\n\u0012\u03b1 \u22121\nES\u03b1\nt\n\u0013\n\u2212(yt \u2212Q\u03b1\nt )(\u03b1 \u2212I(yt \u2264Q\u03b1\nt ))\n\u03b1 \u00b7 ES\u03b1\nt\n\u0015\n,\n(29)\nwhere ES\u03b1\nt denotes the forecast Expected Shortfall at time t.\nThe AL loss function offers several advantages. First, it enables the simultaneous\nevaluation of VaR and ES, which are jointly elicitable, ensuring that the forecasts align\nwith their theoretical definitions. Second, it penalizes deviations in a manner consistent\nwith the relative importance of VaR and ES in risk management. Together, the quantile\nloss and joint loss functions provide a comprehensive framework for assessing tail risk\nmeasures. Empirical Analysis of Tail Risk Measures\nAs highlighted by Fissler and Ziegel (2016), the joint elicitation of Value-at-Risk (VaR)\nand Expected Shortfall (ES) offers a coherent framework for evaluating tail risk forecasts. Table 16 reports quantile loss and joint loss metrics across three markets and various\nportfolio sizes. At the 5% risk level, the LSTM-BEKK model consistently achieves the\nlowest QLoss5% and JointLoss5% across nearly all settings, underscoring its effectiveness\nin modeling moderate tail risk under complex market dynamics. 40\n\n\n--- Page 41 ---\nAt the more extreme 1% level, however, the picture is more nuanced.",
  "Together, the quantile\nloss and joint loss functions provide a comprehensive framework for assessing tail risk\nmeasures. Empirical Analysis of Tail Risk Measures\nAs highlighted by Fissler and Ziegel (2016), the joint elicitation of Value-at-Risk (VaR)\nand Expected Shortfall (ES) offers a coherent framework for evaluating tail risk forecasts. Table 16 reports quantile loss and joint loss metrics across three markets and various\nportfolio sizes. At the 5% risk level, the LSTM-BEKK model consistently achieves the\nlowest QLoss5% and JointLoss5% across nearly all settings, underscoring its effectiveness\nin modeling moderate tail risk under complex market dynamics. 40\n\n\n--- Page 41 ---\nAt the more extreme 1% level, however, the picture is more nuanced. While LSTM-\nBEKK continues to perform well, particularly in the U.S. and U.K. markets, the DCC\nmodel occasionally records the lowest QLoss1% (e.g., JP-100), suggesting that its parsimo-\nnious, shock-driven specification may retain advantages when predicting rare tail events. In contrast, LSTM-BEKK appears better suited for managing broader risk exposures by\ncapturing richer temporal dependencies and nonlinearities in return distributions. Overall, the LSTM-BEKK model offers a favorable balance between flexibility and\ntail sensitivity, yielding consistently strong performance in joint loss metrics\u2014particularly\nat the 5% level\u2014across diverse portfolio configurations and international markets. Table 14: U.S.:Performance Comparison of GMV Portfolios: Quantile Loss and Joint\nLoss. Portfolio Size\nQLoss1%\nQLoss5%\nJointLoss1%\nJointLoss5%\n100\nDCC\n8.955\n34.853\n2.374\n1.867\nScalar BEKK\n7.249\n26.332\n2.580\n1.763\nLSTM-BEKK\n6.291\n24.355\n2.417\n1.646\n175\nDCC\n16.032\n49.509\n2.591\n2.194\nScalar BEKK\n9.145\n30.339\n2.454\n1.562\nLSTM-BEKK\n7.114\n28.445\n2.167\n1.529\n250\nDCC\n33.408\n77.311\n3.259\n2.710\nScalar BEKK\n15.142\n49.291\n2.199\n1.778\nLSTM-BEKK\n11.344\n41.198\n2.127\n1.581\nTable 15: U.K.:Performance Comparison of GMV Portfolios: Quantile Loss and Joint\nLoss.",
  "While LSTM-\nBEKK continues to perform well, particularly in the U.S. and U.K. markets, the DCC\nmodel occasionally records the lowest QLoss1% (e.g., JP-100), suggesting that its parsimo-\nnious, shock-driven specification may retain advantages when predicting rare tail events. In contrast, LSTM-BEKK appears better suited for managing broader risk exposures by\ncapturing richer temporal dependencies and nonlinearities in return distributions. Overall, the LSTM-BEKK model offers a favorable balance between flexibility and\ntail sensitivity, yielding consistently strong performance in joint loss metrics\u2014particularly\nat the 5% level\u2014across diverse portfolio configurations and international markets. Table 14: U.S.:Performance Comparison of GMV Portfolios: Quantile Loss and Joint\nLoss. Portfolio Size\nQLoss1%\nQLoss5%\nJointLoss1%\nJointLoss5%\n100\nDCC\n8.955\n34.853\n2.374\n1.867\nScalar BEKK\n7.249\n26.332\n2.580\n1.763\nLSTM-BEKK\n6.291\n24.355\n2.417\n1.646\n175\nDCC\n16.032\n49.509\n2.591\n2.194\nScalar BEKK\n9.145\n30.339\n2.454\n1.562\nLSTM-BEKK\n7.114\n28.445\n2.167\n1.529\n250\nDCC\n33.408\n77.311\n3.259\n2.710\nScalar BEKK\n15.142\n49.291\n2.199\n1.778\nLSTM-BEKK\n11.344\n41.198\n2.127\n1.581\nTable 15: U.K.:Performance Comparison of GMV Portfolios: Quantile Loss and Joint\nLoss. Portfolio Size\nQLoss1%\nQLoss5%\nJointLoss1%\nJointLoss5%\n100\nDCC\n5.922\n23.222\n2.414\n1.595\nScalar BEKK\n8.811\n30.392\n2.440\n1.636\nLSTM-BEKK\n8.646\n29.371\n2.434\n1.607\n175\nDCC\n10.431\n33.960\n2.390\n1.585\nScalar BEKK\n9.145\n30.339\n2.454\n1.562\nLSTM-BEKK\n9.039\n29.099\n2.445\n1.541\n250\nDCC\n11.148\n29.411\n1.964\n1.442\nScalar BEKK\n8.971\n25.320\n1.898\n1.270\nLSTM-BEKK\n8.223\n24.337\n1.922\n1.237\n41\n\n\n--- Page 42 ---\nTable 16: Japan:Performance Comparison of GMV Portfolios: Quantile Loss and Joint\nLoss.",
  "While LSTM-\nBEKK continues to perform well, particularly in the U.S. and U.K. markets, the DCC\nmodel occasionally records the lowest QLoss1% (e.g., JP-100), suggesting that its parsimo-\nnious, shock-driven specification may retain advantages when predicting rare tail events. In contrast, LSTM-BEKK appears better suited for managing broader risk exposures by\ncapturing richer temporal dependencies and nonlinearities in return distributions. Overall, the LSTM-BEKK model offers a favorable balance between flexibility and\ntail sensitivity, yielding consistently strong performance in joint loss metrics\u2014particularly\nat the 5% level\u2014across diverse portfolio configurations and international markets. Table 14: U.S.:Performance Comparison of GMV Portfolios: Quantile Loss and Joint\nLoss. Portfolio Size\nQLoss1%\nQLoss5%\nJointLoss1%\nJointLoss5%\n100\nDCC\n8.955\n34.853\n2.374\n1.867\nScalar BEKK\n7.249\n26.332\n2.580\n1.763\nLSTM-BEKK\n6.291\n24.355\n2.417\n1.646\n175\nDCC\n16.032\n49.509\n2.591\n2.194\nScalar BEKK\n9.145\n30.339\n2.454\n1.562\nLSTM-BEKK\n7.114\n28.445\n2.167\n1.529\n250\nDCC\n33.408\n77.311\n3.259\n2.710\nScalar BEKK\n15.142\n49.291\n2.199\n1.778\nLSTM-BEKK\n11.344\n41.198\n2.127\n1.581\nTable 15: U.K.:Performance Comparison of GMV Portfolios: Quantile Loss and Joint\nLoss. Portfolio Size\nQLoss1%\nQLoss5%\nJointLoss1%\nJointLoss5%\n100\nDCC\n5.922\n23.222\n2.414\n1.595\nScalar BEKK\n8.811\n30.392\n2.440\n1.636\nLSTM-BEKK\n8.646\n29.371\n2.434\n1.607\n175\nDCC\n10.431\n33.960\n2.390\n1.585\nScalar BEKK\n9.145\n30.339\n2.454\n1.562\nLSTM-BEKK\n9.039\n29.099\n2.445\n1.541\n250\nDCC\n11.148\n29.411\n1.964\n1.442\nScalar BEKK\n8.971\n25.320\n1.898\n1.270\nLSTM-BEKK\n8.223\n24.337\n1.922\n1.237\n41\n\n\n--- Page 42 ---\nTable 16: Japan:Performance Comparison of GMV Portfolios: Quantile Loss and Joint\nLoss. Portfolio Size\nQLoss1%\nQLoss5%\nJointLoss1%\nJointLoss5%\n100\nDCC\n7.725\n31.698\n2.397\n1.676\nScalar BEKK\n10.992\n33.243\n3.107\n2.014\nLSTM-BEKK\n12.328\n35.190\n3.333\n2.147\n175\nDCC\n9.019\n30.624\n2.186\n1.617\nScalar BEKK\n7.414\n25.543\n2.346\n1.544\nLSTM-BEKK\n7.865\n25.180\n2.491\n1.605\n250\nDCC\n9.935\n30.143\n2.131\n1.608\nScalar BEKK\n6.485\n25.712\n2.083\n1.466\nLSTM-BEKK\n7.341\n24.794\n2.168\n1.488\nCross-Market Comparison and Implications\nAcross all three markets, the LSTM-BEKK model consistently outperforms traditional\nMGARCH models in terms of predictive accuracy and adaptability to high-dimensional\nsettings.",
  "While LSTM-\nBEKK continues to perform well, particularly in the U.S. and U.K. markets, the DCC\nmodel occasionally records the lowest QLoss1% (e.g., JP-100), suggesting that its parsimo-\nnious, shock-driven specification may retain advantages when predicting rare tail events. In contrast, LSTM-BEKK appears better suited for managing broader risk exposures by\ncapturing richer temporal dependencies and nonlinearities in return distributions. Overall, the LSTM-BEKK model offers a favorable balance between flexibility and\ntail sensitivity, yielding consistently strong performance in joint loss metrics\u2014particularly\nat the 5% level\u2014across diverse portfolio configurations and international markets. Table 14: U.S.:Performance Comparison of GMV Portfolios: Quantile Loss and Joint\nLoss. Portfolio Size\nQLoss1%\nQLoss5%\nJointLoss1%\nJointLoss5%\n100\nDCC\n8.955\n34.853\n2.374\n1.867\nScalar BEKK\n7.249\n26.332\n2.580\n1.763\nLSTM-BEKK\n6.291\n24.355\n2.417\n1.646\n175\nDCC\n16.032\n49.509\n2.591\n2.194\nScalar BEKK\n9.145\n30.339\n2.454\n1.562\nLSTM-BEKK\n7.114\n28.445\n2.167\n1.529\n250\nDCC\n33.408\n77.311\n3.259\n2.710\nScalar BEKK\n15.142\n49.291\n2.199\n1.778\nLSTM-BEKK\n11.344\n41.198\n2.127\n1.581\nTable 15: U.K.:Performance Comparison of GMV Portfolios: Quantile Loss and Joint\nLoss. Portfolio Size\nQLoss1%\nQLoss5%\nJointLoss1%\nJointLoss5%\n100\nDCC\n5.922\n23.222\n2.414\n1.595\nScalar BEKK\n8.811\n30.392\n2.440\n1.636\nLSTM-BEKK\n8.646\n29.371\n2.434\n1.607\n175\nDCC\n10.431\n33.960\n2.390\n1.585\nScalar BEKK\n9.145\n30.339\n2.454\n1.562\nLSTM-BEKK\n9.039\n29.099\n2.445\n1.541\n250\nDCC\n11.148\n29.411\n1.964\n1.442\nScalar BEKK\n8.971\n25.320\n1.898\n1.270\nLSTM-BEKK\n8.223\n24.337\n1.922\n1.237\n41\n\n\n--- Page 42 ---\nTable 16: Japan:Performance Comparison of GMV Portfolios: Quantile Loss and Joint\nLoss. Portfolio Size\nQLoss1%\nQLoss5%\nJointLoss1%\nJointLoss5%\n100\nDCC\n7.725\n31.698\n2.397\n1.676\nScalar BEKK\n10.992\n33.243\n3.107\n2.014\nLSTM-BEKK\n12.328\n35.190\n3.333\n2.147\n175\nDCC\n9.019\n30.624\n2.186\n1.617\nScalar BEKK\n7.414\n25.543\n2.346\n1.544\nLSTM-BEKK\n7.865\n25.180\n2.491\n1.605\n250\nDCC\n9.935\n30.143\n2.131\n1.608\nScalar BEKK\n6.485\n25.712\n2.083\n1.466\nLSTM-BEKK\n7.341\n24.794\n2.168\n1.488\nCross-Market Comparison and Implications\nAcross all three markets, the LSTM-BEKK model consistently outperforms traditional\nMGARCH models in terms of predictive accuracy and adaptability to high-dimensional\nsettings. This is reflected in its uniformly lower out-of-sample negative log-likelihood\n(NLL) values across all portfolio sizes in the U.S., U.K., and Japan, confirming its superior\nability to model time-varying covariance structures more effectively than both the DCC\nand Scalar BEKK models.",
  "In contrast, LSTM-BEKK appears better suited for managing broader risk exposures by\ncapturing richer temporal dependencies and nonlinearities in return distributions. Overall, the LSTM-BEKK model offers a favorable balance between flexibility and\ntail sensitivity, yielding consistently strong performance in joint loss metrics\u2014particularly\nat the 5% level\u2014across diverse portfolio configurations and international markets. Table 14: U.S.:Performance Comparison of GMV Portfolios: Quantile Loss and Joint\nLoss. Portfolio Size\nQLoss1%\nQLoss5%\nJointLoss1%\nJointLoss5%\n100\nDCC\n8.955\n34.853\n2.374\n1.867\nScalar BEKK\n7.249\n26.332\n2.580\n1.763\nLSTM-BEKK\n6.291\n24.355\n2.417\n1.646\n175\nDCC\n16.032\n49.509\n2.591\n2.194\nScalar BEKK\n9.145\n30.339\n2.454\n1.562\nLSTM-BEKK\n7.114\n28.445\n2.167\n1.529\n250\nDCC\n33.408\n77.311\n3.259\n2.710\nScalar BEKK\n15.142\n49.291\n2.199\n1.778\nLSTM-BEKK\n11.344\n41.198\n2.127\n1.581\nTable 15: U.K.:Performance Comparison of GMV Portfolios: Quantile Loss and Joint\nLoss. Portfolio Size\nQLoss1%\nQLoss5%\nJointLoss1%\nJointLoss5%\n100\nDCC\n5.922\n23.222\n2.414\n1.595\nScalar BEKK\n8.811\n30.392\n2.440\n1.636\nLSTM-BEKK\n8.646\n29.371\n2.434\n1.607\n175\nDCC\n10.431\n33.960\n2.390\n1.585\nScalar BEKK\n9.145\n30.339\n2.454\n1.562\nLSTM-BEKK\n9.039\n29.099\n2.445\n1.541\n250\nDCC\n11.148\n29.411\n1.964\n1.442\nScalar BEKK\n8.971\n25.320\n1.898\n1.270\nLSTM-BEKK\n8.223\n24.337\n1.922\n1.237\n41\n\n\n--- Page 42 ---\nTable 16: Japan:Performance Comparison of GMV Portfolios: Quantile Loss and Joint\nLoss. Portfolio Size\nQLoss1%\nQLoss5%\nJointLoss1%\nJointLoss5%\n100\nDCC\n7.725\n31.698\n2.397\n1.676\nScalar BEKK\n10.992\n33.243\n3.107\n2.014\nLSTM-BEKK\n12.328\n35.190\n3.333\n2.147\n175\nDCC\n9.019\n30.624\n2.186\n1.617\nScalar BEKK\n7.414\n25.543\n2.346\n1.544\nLSTM-BEKK\n7.865\n25.180\n2.491\n1.605\n250\nDCC\n9.935\n30.143\n2.131\n1.608\nScalar BEKK\n6.485\n25.712\n2.083\n1.466\nLSTM-BEKK\n7.341\n24.794\n2.168\n1.488\nCross-Market Comparison and Implications\nAcross all three markets, the LSTM-BEKK model consistently outperforms traditional\nMGARCH models in terms of predictive accuracy and adaptability to high-dimensional\nsettings. This is reflected in its uniformly lower out-of-sample negative log-likelihood\n(NLL) values across all portfolio sizes in the U.S., U.K., and Japan, confirming its superior\nability to model time-varying covariance structures more effectively than both the DCC\nand Scalar BEKK models. The LSTM-BEKK model demonstrates notable robustness across market-specific con-\nditions.",
  "Overall, the LSTM-BEKK model offers a favorable balance between flexibility and\ntail sensitivity, yielding consistently strong performance in joint loss metrics\u2014particularly\nat the 5% level\u2014across diverse portfolio configurations and international markets. Table 14: U.S.:Performance Comparison of GMV Portfolios: Quantile Loss and Joint\nLoss. Portfolio Size\nQLoss1%\nQLoss5%\nJointLoss1%\nJointLoss5%\n100\nDCC\n8.955\n34.853\n2.374\n1.867\nScalar BEKK\n7.249\n26.332\n2.580\n1.763\nLSTM-BEKK\n6.291\n24.355\n2.417\n1.646\n175\nDCC\n16.032\n49.509\n2.591\n2.194\nScalar BEKK\n9.145\n30.339\n2.454\n1.562\nLSTM-BEKK\n7.114\n28.445\n2.167\n1.529\n250\nDCC\n33.408\n77.311\n3.259\n2.710\nScalar BEKK\n15.142\n49.291\n2.199\n1.778\nLSTM-BEKK\n11.344\n41.198\n2.127\n1.581\nTable 15: U.K.:Performance Comparison of GMV Portfolios: Quantile Loss and Joint\nLoss. Portfolio Size\nQLoss1%\nQLoss5%\nJointLoss1%\nJointLoss5%\n100\nDCC\n5.922\n23.222\n2.414\n1.595\nScalar BEKK\n8.811\n30.392\n2.440\n1.636\nLSTM-BEKK\n8.646\n29.371\n2.434\n1.607\n175\nDCC\n10.431\n33.960\n2.390\n1.585\nScalar BEKK\n9.145\n30.339\n2.454\n1.562\nLSTM-BEKK\n9.039\n29.099\n2.445\n1.541\n250\nDCC\n11.148\n29.411\n1.964\n1.442\nScalar BEKK\n8.971\n25.320\n1.898\n1.270\nLSTM-BEKK\n8.223\n24.337\n1.922\n1.237\n41\n\n\n--- Page 42 ---\nTable 16: Japan:Performance Comparison of GMV Portfolios: Quantile Loss and Joint\nLoss. Portfolio Size\nQLoss1%\nQLoss5%\nJointLoss1%\nJointLoss5%\n100\nDCC\n7.725\n31.698\n2.397\n1.676\nScalar BEKK\n10.992\n33.243\n3.107\n2.014\nLSTM-BEKK\n12.328\n35.190\n3.333\n2.147\n175\nDCC\n9.019\n30.624\n2.186\n1.617\nScalar BEKK\n7.414\n25.543\n2.346\n1.544\nLSTM-BEKK\n7.865\n25.180\n2.491\n1.605\n250\nDCC\n9.935\n30.143\n2.131\n1.608\nScalar BEKK\n6.485\n25.712\n2.083\n1.466\nLSTM-BEKK\n7.341\n24.794\n2.168\n1.488\nCross-Market Comparison and Implications\nAcross all three markets, the LSTM-BEKK model consistently outperforms traditional\nMGARCH models in terms of predictive accuracy and adaptability to high-dimensional\nsettings. This is reflected in its uniformly lower out-of-sample negative log-likelihood\n(NLL) values across all portfolio sizes in the U.S., U.K., and Japan, confirming its superior\nability to model time-varying covariance structures more effectively than both the DCC\nand Scalar BEKK models. The LSTM-BEKK model demonstrates notable robustness across market-specific con-\nditions. In the U.K. market, where extreme return events are more frequent, traditional\nmodels suffer from underestimating tail risks.",
  "Table 14: U.S.:Performance Comparison of GMV Portfolios: Quantile Loss and Joint\nLoss. Portfolio Size\nQLoss1%\nQLoss5%\nJointLoss1%\nJointLoss5%\n100\nDCC\n8.955\n34.853\n2.374\n1.867\nScalar BEKK\n7.249\n26.332\n2.580\n1.763\nLSTM-BEKK\n6.291\n24.355\n2.417\n1.646\n175\nDCC\n16.032\n49.509\n2.591\n2.194\nScalar BEKK\n9.145\n30.339\n2.454\n1.562\nLSTM-BEKK\n7.114\n28.445\n2.167\n1.529\n250\nDCC\n33.408\n77.311\n3.259\n2.710\nScalar BEKK\n15.142\n49.291\n2.199\n1.778\nLSTM-BEKK\n11.344\n41.198\n2.127\n1.581\nTable 15: U.K.:Performance Comparison of GMV Portfolios: Quantile Loss and Joint\nLoss. Portfolio Size\nQLoss1%\nQLoss5%\nJointLoss1%\nJointLoss5%\n100\nDCC\n5.922\n23.222\n2.414\n1.595\nScalar BEKK\n8.811\n30.392\n2.440\n1.636\nLSTM-BEKK\n8.646\n29.371\n2.434\n1.607\n175\nDCC\n10.431\n33.960\n2.390\n1.585\nScalar BEKK\n9.145\n30.339\n2.454\n1.562\nLSTM-BEKK\n9.039\n29.099\n2.445\n1.541\n250\nDCC\n11.148\n29.411\n1.964\n1.442\nScalar BEKK\n8.971\n25.320\n1.898\n1.270\nLSTM-BEKK\n8.223\n24.337\n1.922\n1.237\n41\n\n\n--- Page 42 ---\nTable 16: Japan:Performance Comparison of GMV Portfolios: Quantile Loss and Joint\nLoss. Portfolio Size\nQLoss1%\nQLoss5%\nJointLoss1%\nJointLoss5%\n100\nDCC\n7.725\n31.698\n2.397\n1.676\nScalar BEKK\n10.992\n33.243\n3.107\n2.014\nLSTM-BEKK\n12.328\n35.190\n3.333\n2.147\n175\nDCC\n9.019\n30.624\n2.186\n1.617\nScalar BEKK\n7.414\n25.543\n2.346\n1.544\nLSTM-BEKK\n7.865\n25.180\n2.491\n1.605\n250\nDCC\n9.935\n30.143\n2.131\n1.608\nScalar BEKK\n6.485\n25.712\n2.083\n1.466\nLSTM-BEKK\n7.341\n24.794\n2.168\n1.488\nCross-Market Comparison and Implications\nAcross all three markets, the LSTM-BEKK model consistently outperforms traditional\nMGARCH models in terms of predictive accuracy and adaptability to high-dimensional\nsettings. This is reflected in its uniformly lower out-of-sample negative log-likelihood\n(NLL) values across all portfolio sizes in the U.S., U.K., and Japan, confirming its superior\nability to model time-varying covariance structures more effectively than both the DCC\nand Scalar BEKK models. The LSTM-BEKK model demonstrates notable robustness across market-specific con-\nditions. In the U.K. market, where extreme return events are more frequent, traditional\nmodels suffer from underestimating tail risks. LSTM-BEKK, by contrast, accommodates\nthese dynamics through its flexible architecture and achieves better tail-sensitive metrics\nsuch as joint loss at the 5% level.",
  "Portfolio Size\nQLoss1%\nQLoss5%\nJointLoss1%\nJointLoss5%\n100\nDCC\n8.955\n34.853\n2.374\n1.867\nScalar BEKK\n7.249\n26.332\n2.580\n1.763\nLSTM-BEKK\n6.291\n24.355\n2.417\n1.646\n175\nDCC\n16.032\n49.509\n2.591\n2.194\nScalar BEKK\n9.145\n30.339\n2.454\n1.562\nLSTM-BEKK\n7.114\n28.445\n2.167\n1.529\n250\nDCC\n33.408\n77.311\n3.259\n2.710\nScalar BEKK\n15.142\n49.291\n2.199\n1.778\nLSTM-BEKK\n11.344\n41.198\n2.127\n1.581\nTable 15: U.K.:Performance Comparison of GMV Portfolios: Quantile Loss and Joint\nLoss. Portfolio Size\nQLoss1%\nQLoss5%\nJointLoss1%\nJointLoss5%\n100\nDCC\n5.922\n23.222\n2.414\n1.595\nScalar BEKK\n8.811\n30.392\n2.440\n1.636\nLSTM-BEKK\n8.646\n29.371\n2.434\n1.607\n175\nDCC\n10.431\n33.960\n2.390\n1.585\nScalar BEKK\n9.145\n30.339\n2.454\n1.562\nLSTM-BEKK\n9.039\n29.099\n2.445\n1.541\n250\nDCC\n11.148\n29.411\n1.964\n1.442\nScalar BEKK\n8.971\n25.320\n1.898\n1.270\nLSTM-BEKK\n8.223\n24.337\n1.922\n1.237\n41\n\n\n--- Page 42 ---\nTable 16: Japan:Performance Comparison of GMV Portfolios: Quantile Loss and Joint\nLoss. Portfolio Size\nQLoss1%\nQLoss5%\nJointLoss1%\nJointLoss5%\n100\nDCC\n7.725\n31.698\n2.397\n1.676\nScalar BEKK\n10.992\n33.243\n3.107\n2.014\nLSTM-BEKK\n12.328\n35.190\n3.333\n2.147\n175\nDCC\n9.019\n30.624\n2.186\n1.617\nScalar BEKK\n7.414\n25.543\n2.346\n1.544\nLSTM-BEKK\n7.865\n25.180\n2.491\n1.605\n250\nDCC\n9.935\n30.143\n2.131\n1.608\nScalar BEKK\n6.485\n25.712\n2.083\n1.466\nLSTM-BEKK\n7.341\n24.794\n2.168\n1.488\nCross-Market Comparison and Implications\nAcross all three markets, the LSTM-BEKK model consistently outperforms traditional\nMGARCH models in terms of predictive accuracy and adaptability to high-dimensional\nsettings. This is reflected in its uniformly lower out-of-sample negative log-likelihood\n(NLL) values across all portfolio sizes in the U.S., U.K., and Japan, confirming its superior\nability to model time-varying covariance structures more effectively than both the DCC\nand Scalar BEKK models. The LSTM-BEKK model demonstrates notable robustness across market-specific con-\nditions. In the U.K. market, where extreme return events are more frequent, traditional\nmodels suffer from underestimating tail risks. LSTM-BEKK, by contrast, accommodates\nthese dynamics through its flexible architecture and achieves better tail-sensitive metrics\nsuch as joint loss at the 5% level. In the U.S. market, the model achieves the lowest average\nvolatility and maximum drawdown in GMV portfolio tests, supporting its effectiveness\nin minimizing downside risk.",
  "Portfolio Size\nQLoss1%\nQLoss5%\nJointLoss1%\nJointLoss5%\n100\nDCC\n5.922\n23.222\n2.414\n1.595\nScalar BEKK\n8.811\n30.392\n2.440\n1.636\nLSTM-BEKK\n8.646\n29.371\n2.434\n1.607\n175\nDCC\n10.431\n33.960\n2.390\n1.585\nScalar BEKK\n9.145\n30.339\n2.454\n1.562\nLSTM-BEKK\n9.039\n29.099\n2.445\n1.541\n250\nDCC\n11.148\n29.411\n1.964\n1.442\nScalar BEKK\n8.971\n25.320\n1.898\n1.270\nLSTM-BEKK\n8.223\n24.337\n1.922\n1.237\n41\n\n\n--- Page 42 ---\nTable 16: Japan:Performance Comparison of GMV Portfolios: Quantile Loss and Joint\nLoss. Portfolio Size\nQLoss1%\nQLoss5%\nJointLoss1%\nJointLoss5%\n100\nDCC\n7.725\n31.698\n2.397\n1.676\nScalar BEKK\n10.992\n33.243\n3.107\n2.014\nLSTM-BEKK\n12.328\n35.190\n3.333\n2.147\n175\nDCC\n9.019\n30.624\n2.186\n1.617\nScalar BEKK\n7.414\n25.543\n2.346\n1.544\nLSTM-BEKK\n7.865\n25.180\n2.491\n1.605\n250\nDCC\n9.935\n30.143\n2.131\n1.608\nScalar BEKK\n6.485\n25.712\n2.083\n1.466\nLSTM-BEKK\n7.341\n24.794\n2.168\n1.488\nCross-Market Comparison and Implications\nAcross all three markets, the LSTM-BEKK model consistently outperforms traditional\nMGARCH models in terms of predictive accuracy and adaptability to high-dimensional\nsettings. This is reflected in its uniformly lower out-of-sample negative log-likelihood\n(NLL) values across all portfolio sizes in the U.S., U.K., and Japan, confirming its superior\nability to model time-varying covariance structures more effectively than both the DCC\nand Scalar BEKK models. The LSTM-BEKK model demonstrates notable robustness across market-specific con-\nditions. In the U.K. market, where extreme return events are more frequent, traditional\nmodels suffer from underestimating tail risks. LSTM-BEKK, by contrast, accommodates\nthese dynamics through its flexible architecture and achieves better tail-sensitive metrics\nsuch as joint loss at the 5% level. In the U.S. market, the model achieves the lowest average\nvolatility and maximum drawdown in GMV portfolio tests, supporting its effectiveness\nin minimizing downside risk. Even in scenarios where DCC performs competitively in\nextreme quantile loss (e.g., at 1% thresholds), LSTM-BEKK maintains stronger overall\njoint performance across broader risk metrics.",
  "Portfolio Size\nQLoss1%\nQLoss5%\nJointLoss1%\nJointLoss5%\n100\nDCC\n7.725\n31.698\n2.397\n1.676\nScalar BEKK\n10.992\n33.243\n3.107\n2.014\nLSTM-BEKK\n12.328\n35.190\n3.333\n2.147\n175\nDCC\n9.019\n30.624\n2.186\n1.617\nScalar BEKK\n7.414\n25.543\n2.346\n1.544\nLSTM-BEKK\n7.865\n25.180\n2.491\n1.605\n250\nDCC\n9.935\n30.143\n2.131\n1.608\nScalar BEKK\n6.485\n25.712\n2.083\n1.466\nLSTM-BEKK\n7.341\n24.794\n2.168\n1.488\nCross-Market Comparison and Implications\nAcross all three markets, the LSTM-BEKK model consistently outperforms traditional\nMGARCH models in terms of predictive accuracy and adaptability to high-dimensional\nsettings. This is reflected in its uniformly lower out-of-sample negative log-likelihood\n(NLL) values across all portfolio sizes in the U.S., U.K., and Japan, confirming its superior\nability to model time-varying covariance structures more effectively than both the DCC\nand Scalar BEKK models. The LSTM-BEKK model demonstrates notable robustness across market-specific con-\nditions. In the U.K. market, where extreme return events are more frequent, traditional\nmodels suffer from underestimating tail risks. LSTM-BEKK, by contrast, accommodates\nthese dynamics through its flexible architecture and achieves better tail-sensitive metrics\nsuch as joint loss at the 5% level. In the U.S. market, the model achieves the lowest average\nvolatility and maximum drawdown in GMV portfolio tests, supporting its effectiveness\nin minimizing downside risk. Even in scenarios where DCC performs competitively in\nextreme quantile loss (e.g., at 1% thresholds), LSTM-BEKK maintains stronger overall\njoint performance across broader risk metrics. Overall, these results affirm the advantages of integrating deep learning with struc-\ntured econometric modeling. The LSTM-BEKK framework not only offers superior sta-\ntistical fit and predictive performance, but also generalizes well across heterogeneous\nmarket regimes. Its ability to balance responsiveness to market shocks with long-run\nstability makes it a promising tool for risk management, volatility forecasting, and high-\ndimensional portfolio construction.",
  "In the U.S. market, the model achieves the lowest average\nvolatility and maximum drawdown in GMV portfolio tests, supporting its effectiveness\nin minimizing downside risk. Even in scenarios where DCC performs competitively in\nextreme quantile loss (e.g., at 1% thresholds), LSTM-BEKK maintains stronger overall\njoint performance across broader risk metrics. Overall, these results affirm the advantages of integrating deep learning with struc-\ntured econometric modeling. The LSTM-BEKK framework not only offers superior sta-\ntistical fit and predictive performance, but also generalizes well across heterogeneous\nmarket regimes. Its ability to balance responsiveness to market shocks with long-run\nstability makes it a promising tool for risk management, volatility forecasting, and high-\ndimensional portfolio construction. 42\n\n\n--- Page 43 ---\nConclusion\nOverall, the LSTM-BEKK model demonstrates its effectiveness in capturing multivariate\nvolatility dynamics across different financial markets. Its ability to incorporate deep\nlearning techniques enables superior predictive accuracy, making it a valuable tool for risk\nmanagement, portfolio optimization, and stress testing. By integrating both econometric\nand deep learning methodologies, the LSTM-BEKK model provides a more flexible and\naccurate representation of financial market volatility, paving the way for further research\ninto hybrid modeling approaches. References\nAielli, G. P. (2013). Dynamic conditional correlation: On properties and estimation. Journal of Business & Economic Statistics, 31(3):282\u2013299. Asai, M., McAleer, M., and Yu, J. (2006). Multivariate stochastic volatility: A review. Econometric Reviews, 25(2-3):145\u2013175. Bauwens, L., Laurent, S., and Rombouts, J. V. K. (2006). Multivariate GARCH models:\nA survey. Journal of Applied Econometrics, 21(1):79\u2013109. Bauwens, L. and Otranto, E. (2020). Nonlinearities and regimes in conditional correlations\nwith different dynamics. Journal of Econometrics, 217(2):496\u2013522. Bollerslev, T. (1986). Generalized autoregressive conditional heteroskedasticity. Journal\nof Econometrics, 31(3):307\u2013327. Bollerslev, T., Engle, R. F., and Wooldridge, J. M. (1988). A capital asset pricing model\nwith time-varying covariances. Journal of Political Economy, 96(1):116\u2013131.",
  "A capital asset pricing model\nwith time-varying covariances. Journal of Political Economy, 96(1):116\u2013131. Caporin, M. and McAleer, M. (2008). Scalar BEKK and indirect DCC. Journal of\nForecasting, 27(6):537\u2013549. DeMiguel, V., Garlappi, L., and Uppal, R. (2009). Optimal versus naive diversifica-\ntion: How inefficient is the 1/n portfolio strategy? The Review of Financial Studies,\n22(5):1915\u20131953. Engle, R. F. (1982). Autoregressive Conditional Heteroscedasticity with Estimates of the\nVariance of United Kingdom Inflation. Econometrica, 50(4):987\u20131007. Engle, R. F. (2002). Dynamic conditional correlation: A simple class of multivariate\nGARCH models. Journal of Business & Economic Statistics, 20(3):339\u2013350. Engle, R. F. and Kelly, B. (2012). Dynamic equicorrelation. Journal of Business &\nEconomic Statistics, 30(4):384\u2013397. 43\n\n\n--- Page 44 ---\nEngle, R. F. and Kroner, K. F. (1995). Multivariate simultaneous Generalized ARCH. Econometric Theory, 11(1):122\u2013150. Fang, Y., Liu, L., and Liu, J. (2015). A dynamic double asymmetric copula generalized\nautoregressive conditional heteroskedasticity model: application to China\u2019s and US\nstock market. Journal of Applied Statistics, 42(2):327\u2013346. Fissler, T. and Ziegel, J. F. (2016). Higher order elicitability and Osband\u2019s principle. The\nAnnals of Statistics, 44(4):1680\u20131707. Francq, C. and Zakoian, J.-M. (2019). GARCH Models: Structure, Statistical Inference,\nand Financial Applications. John Wiley & Sons, Hoboken, NJ, 2nd edition. Francq, C. and Zako\u00efan, J.-M. (2012). QML estimation of a class of multivariate asym-\nmetric GARCH models. Econometric Theory, 28(1):179\u2013206. Goodfellow, I., Bengio, Y., and Courville, A. (2016). Deep Learning. MIT Press. Hafner, C. M., Laurent, S., and Violante, F. (2017). Weak diffusion limits of dynamic\nconditional correlation models. Econometric Theory, 33(3):691\u2013716. Hafner, C. M. and Preminger, A. (2009). Asymptotic theory for a factor GARCH model. Econometric Theory, 25(2):336\u2013363. Hafner, C. M. and Rombouts, J. V. (2007). Semiparametric multivariate volatility models. Econometric Theory, 23(2):251\u2013280. Hansen, P. R., Lunde, A., and Nason, J. M. (2011). The Model Confidence Set. Econo-\nmetrica, 79(2):453\u2013497.",
  "Econo-\nmetrica, 79(2):453\u2013497. Hochreiter, S. and Schmidhuber, J. (1997). Long short-term memory. Neural Computa-\ntion, 9(8):1735\u20131780. Koenker, R. and Bassett, G. (1978). Regression quantiles. Econometrica: journal of the\nEconometric Society, pages 33\u201350. Ku, Y.-H. H. (2008). Student-t distribution based VAR-MGARCH: an application of\nthe DCC model on international portfolio risk management. Applied Economics,\n40(13):1685\u20131697. Lai, Y.-S. and Sheu, H.-J. (2011). On the importance of asymmetries for dynamic hedging\nduring the subprime crisis. Applied Financial Economics, 21(11):801\u2013813. Ledoit, O. and Wolf, M. (2012). Nonlinear shrinkage estimation of large-dimensional\ncovariance matrices. Annals of Statistics, 40(2):1024\u20131060. Ledoit, O. and Wolf, M. (2015). Spectrum estimation: A unified framework for covariance\nmatrix estimation and PCA in large dimensions. Journal of Multivariate Analysis,\n139:360\u2013384. 44\n\n\n--- Page 45 ---\nLiu, Y. (2019). Novel volatility forecasting using deep learning\u2013long short term memory\nrecurrent neural networks. Expert Systems with Applications, 132:99\u2013109. Matsui, M. and Pedersen, R. S. (2022). Characterization of the tail behavior of a class\nof BEKK processes: A stochastic recurrence equation approach. Econometric Theory,\n38(1):1\u201334. McAleer, M., Chan, F., Hoti, S., and Lieberman, O. (2008). Generalized autoregressive\nconditional correlation. Econometric Theory, 24(6):1554\u20131583. Nguyen, T.-N., Tran, M.-N., and Kohn, R. (2022). Recurrent Conditional Heteroskedas-\nticity. Journal of Applied Econometrics, 37(5):1031\u20131054. Scherrer, W. and Ribarits, E. (2007). On the parametrization of multivariate GARCH\nmodels. Econometric Theory, 23(3):464\u2013484. Silvennoinen, A. and Ter\u00e4svirta, T. (2009). Multivariate GARCH models. Handbook of\nFinancial Time Series, pages 201\u2013229. Taylor, J. W. (2019). Forecasting value at risk and expected shortfall using a semipara-\nmetric approach based on the asymmetric Laplace distribution. Journal of Business &\nEconomic Statistics, 37(1):121\u2013133. Taylor, S. J. (1994). Modeling stochastic volatility: A review and comparative study. Mathematical Finance, 4(2):183\u2013204. 45"
]